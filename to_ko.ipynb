{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def extract_info(file_path):\n",
    "    # Use regex to match the first two digits and the title\n",
    "    match = re.match(r\"(\\d{2})-([\\w-]+)\", file_path)\n",
    "\n",
    "    # If a match is found, extract the digits and the title\n",
    "    if match:\n",
    "        digits = int(match.group(1))  # Convert digits to integer\n",
    "        title = match.group(2)\n",
    "        return digits, title\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# 1. 각 파일을 읽고\n",
    "def read_readme_from_directories():\n",
    "    dir_pattern = r\"^\\d{2}-\"\n",
    "\n",
    "    result = {}\n",
    "    for dir_name in os.listdir():\n",
    "        if os.path.isdir(os.path.join(dir_name)) and re.match(dir_pattern, dir_name):\n",
    "            readme_path = os.path.join(dir_name, \"translations/ko/README.md\")\n",
    "            if os.path.exists(readme_path):\n",
    "                with open(readme_path, \"r\", encoding=\"utf-8\") as readme_file:\n",
    "                    content = readme_file.read()\n",
    "                digits, title = extract_info(dir_name)\n",
    "                result[digits] = {\"title\": title, \"sections\": split_markdown(content)}\n",
    "    return result\n",
    "\n",
    "\n",
    "# 2. 헤딩 (#, ##, ### …) 별로 나눈 뒤\n",
    "def split_markdown(content):\n",
    "    pattern = r\"^(#+\\s)\"\n",
    "    sections = re.split(pattern, content, flags=re.MULTILINE)[1:]\n",
    "    return [sections[i] + sections[i + 1] for i in range(0, len(sections), 2)]\n",
    "\n",
    "\n",
    "readme_files = read_readme_from_directories()\n",
    "pprint(readme_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.48.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.23.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading openai-1.48.0-py3-none-any.whl (376 kB)\n",
      "Downloading anyio-4.6.0-py3-none-any.whl (89 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading jiter-0.5.0-cp312-cp312-macosx_11_0_arm64.whl (296 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, python-dotenv, jiter, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.0 certifi-2024.8.30 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 idna-3.10 jiter-0.5.0 openai-1.48.0 pydantic-2.9.2 pydantic-core-2.23.4 python-dotenv-1.0.1 sniffio-1.3.1 tqdm-4.66.5 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(file_path, content):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-ABcR3AXCXNFzdqsQBRXERwAh7iDDK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# LLM 미세 조정하기\\n\\n대규모 언어 모델을 사용하여 생성적 AI 애플리케이션을 구축하는 데에는 새로운 도전 과제가 따릅니다. 주요 문제는 주어진 사용자 요청에 대해 모델이 생성한 콘텐츠의 응답 품질(정확도 및 관련성)을 보장하는 것입니다. 이전 수업에서는 기존 모델에 대한 프롬프트 입력을 _수정하는_ 프롬프트 엔지니어링 및 검색 증강 생성과 같은 기술에 대해 논의했습니다.\\n\\n오늘 수업에서는 세 번째 기술인, **미세 조정**에 대해 논의합니다. 이는 추가 데이터를 사용하여 _모델 자체를 다시 학습_ 시킴으로써 문제를 해결하려고 합니다. 자세히 알아보도록 하겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332717, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=169, prompt_tokens=149, total_tokens=318, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcR6oWRT7MWNLg6QM5YaNndZeEtU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의에서는 사전 학습된 언어 모델의 미세 조정 개념을 소개하고, 이 접근 방식의 이점과 도전 과제를 탐구하며, 생성형 AI 모델의 성능을 향상시키기 위해 언제 그리고 어떻게 미세 조정을 사용할지에 대한 지침을 제공합니다.\\n\\n이 강의가 끝나면 다음 질문들에 답할 수 있어야 합니다:\\n\\n- 언어 모델에 대한 미세 조정이란 무엇인가요?\\n- 미세 조정이 언제, 그리고 왜 유용한가요?\\n- 사전 학습된 모델을 어떻게 미세 조정할 수 있나요?\\n- 미세 조정의 제한 사항은 무엇인가요?\\n\\n준비됐나요? 시작해봅시다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332720, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=165, prompt_tokens=143, total_tokens=308, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcR8Y4TBurnvKy4ovkb5fuDG0UiV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 일러스트 가이드\\n\\n본격적으로 시작하기 전에 우리가 다룰 내용의 큰 그림을 보고 싶으신가요? 이 일러스트 가이드를 확인해보세요. 이 수업에서 다룰 학습 여정을 설명합니다. 핵심 개념과 파인 튜닝의 동기부터 파인 튜닝 작업을 실행하는 과정 및 모범 사례에 이르기까지 다룹니다. 탐구하기에 흥미로운 주제이니, [자원](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) 페이지에서 추가 링크를 확인해보세요. 이 링크들은 여러분의 자율 학습 여정을 지원합니다!\\n\\n![언어 모델 파인 튜닝을 위한 일러스트 가이드](./img/18-fine-tuning-sketchnote.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332722, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=193, prompt_tokens=173, total_tokens=366, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRB8uTJy6bR05TiTMiu43IpVNVD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 언어 모델에 대한 파인 튜닝이란 무엇입니까?\\n\\n대형 언어 모델은 정의상 인터넷을 포함한 다양한 소스에서 얻은 대량의 텍스트로 _사전 학습_ 됩니다. 이전 수업에서 배운 것처럼 사용자의 질문(“프롬프트”)에 대한 모델 응답의 품질을 향상시키기 위해서는 _프롬프트 엔지니어링_ 및 _검색 증강 생성_ 같은 기술이 필요합니다.\\n\\n인기 있는 프롬프트 엔지니어링 기법에는 모델에 적절한 응답에 대한 안내를 더 많이 제공하는 방법이 포함됩니다. 이를 위해 _설명서_ (명시적 안내)를 제공하거나 _몇 가지 예를 제공_ (암시적 안내)하는 방법이 있습니다. 이를 _소수 샷 학습_(few-shot learning)이라고 하지만 두 가지 제한이 있습니다:\\n\\n- 모델 토큰 제한으로 인해 제공할 수 있는 예제 수가 제한되고 효과가 감소할 수 있습니다.\\n- 모델 토큰 비용으로 인해 모든 프롬프트에 예제를 추가하는 것이 비쌀 수 있으며 유연성이 제한됩니다.\\n\\n파인 튜닝은 사전 학습된 모델을 가져와 새로운 데이터로 재학습시켜 특정 작업의 성능을 향상시키는 기계 학습 시스템의 일반적인 관행입니다. 언어 모델의 경우 사전 학습된 모델을 _특정 작업 또는 애플리케이션 도메인에 대한 큐레이션 된 예제 세트로_ 파인 튜닝하여 해당 특정 작업이나 도메인에 더 정확하고 관련성이 높은 **맞춤형 모델**을 만들 수 있습니다. 파인 튜닝의 부가적인 이점은 소수 샷 학습에 필요한 예제 수를 줄여 토큰 사용량과 관련 비용을 줄일 수 있다는 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332725, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=403, prompt_tokens=315, total_tokens=718, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRHYO969t1Q3BhLm3eo3wCo2gIs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 언제 그리고 왜 모델을 미세 조정해야 하는가?\\n\\n_이_ 문맥에서 우리가 미세 조정을 이야기할 때, **새로운 데이터**를 추가하여 원래의 훈련 데이터셋에 포함되지 않은 데이터를 통해 재훈련하는 **지도 학습** 미세 조정을 의미합니다. 이는 원래 데이터를 사용하지만 다른 하이퍼파라미터로 모델을 재훈련하는 비지도 학습 미세 조정 접근법과는 다릅니다.\\n\\n기억해야 할 중요한 점은, 미세 조정은 원하는 결과를 얻기 위해 어느 정도의 전문 지식이 필요한 고급 기술이라는 것입니다. 잘못 수행될 경우 기대한 개선이 이루어지지 않을 수 있으며, 심지어 목표로 하는 도메인에서 모델 성능을 저하시킬 수도 있습니다.\\n\\n따라서 언어 모델을 \"어떻게\" 미세 조정할 것인지를 배우기 전에, \"왜\" 이 방법을 선택해야 하는지, 그리고 \"언제\" 미세 조정 과정을 시작해야 하는지 알아야 합니다. 다음 질문들을 통해 시작해 보세요:\\n\\n- **사용 사례**: 미세 조정의 _사용 사례_는 무엇입니까? 현재 미리 학습된 모델에서 어떤 측면을 개선하고 싶습니까?\\n- **대체 방법**: 원하는 결과를 얻기 위해 _다른 기술들_을 시도해 보았습니까? 이들을 사용하여 비교 기준을 만드세요.\\n  - 프롬프트 엔지니어링: 관련 프롬프트 응답의 예시로 몇 샷 프롬프트 기법을 사용해 보세요. 응답의 품질을 평가하세요.\\n  - 검색 강화 생성: 데이터를 검색하여 얻은 쿼리 결과로 프롬프트를 보강하는 방법을 시도해 보세요. 응답의 품질을 평가하세요.\\n- **비용**: 미세 조정의 비용을 식별했습니까?\\n  - 조정 가능성 - 미세 조정을 위해 미리 학습된 모델이 사용 가능한가?\\n  - 노력 - 훈련 데이터 준비, 모델 평가 및 수정에 필요한 노력.\\n  - 컴퓨팅 - 미세 조정 작업을 실행하고 미세 조정된 모델을 배포하는 데 필요한 컴퓨팅 자원.\\n  - 데이터 - 미세 조정의 효과를 위해 충분한 품질의 예제에 접근할 수 있는가?\\n- **혜택**: 미세 조정의 혜택을 확인했습니까?\\n  - 품질 - 미세 조정된 모델이 기준보다 더 나은 성능을 보였습니까?\\n  - 비용 - 프롬프트를 단순화하여 토큰 사용량을 줄일 수 있습니까?\\n  - 확장성 - 기본 모델을 새 도메인에 재사용할 수 있습니까?\\n\\n이 질문들에 답함으로써 미세 조정이 특정 사용 사례에 적합한 접근법인지 결정할 수 있습니다. 이상적으로는 혜택이 비용을 상회하는 경우에만 유효한 접근법입니다. 진행하기로 결정했다면, 미리 학습된 모델을 _어떻게_ 미세 조정할 수 있을지를 생각할 때입니다.\\n\\n결정 과정에 대한 더 많은 인사이트를 원하시나요? [미세 조정을 할지 말지](https://www.youtube.com/watch?v=0Jo-z-MFxJs) 동영상을 시청하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332731, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=735, prompt_tokens=562, total_tokens=1297, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRQxeQ3i3tWluODlJfRjNeOKikG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 사전 학습된 모델을 미세 조정하려면 어떻게 해야 하나요?\\n\\n사전 학습된 모델을 미세 조정하려면 다음과 같은 항목이 필요합니다:\\n\\n- 미세 조정할 사전 학습된 모델\\n- 미세 조정에 사용할 데이터셋\\n- 미세 조정 작업을 실행할 교육 환경\\n- 미세 조정된 모델을 배포할 호스팅 환경', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332740, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=92, prompt_tokens=97, total_tokens=189, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRRS3TJWrEzvEOvn5FoXtdU3Dx8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 세부 조정 실행\\n\\n다음 자원들은 엄선된 데이터셋을 사용하여 선택된 모델을 실제로 예제로 다루는 단계별 튜토리얼을 제공합니다. 이 튜토리얼을 진행하려면 특정 제공업체의 계정과 관련 모델 및 데이터셋에 대한 액세스 권한이 필요합니다.\\n\\n| 제공업체     | 튜토리얼 링크                                                                                                                                                                 | 설명                                                                                                                                                                                                                                                                                                                                                                                                                                 |\\n| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\\n| OpenAI       | [챗 모델 세부 조정 방법](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                        | 훈련 데이터 준비, 세부 조정 작업 실행, 그리고 조정된 모델을 추론에 사용하는 방법을 통해 `gpt-35-turbo`를 특정 도메인(\"요리 도우미\")에 맞추어 세부 조정하는 방법을 배워봅니다.                                                                                                                                                                                                               |\\n| Azure OpenAI | [GPT 3.5 Turbo 세부 조정 튜토리얼](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | 훈련 데이터를 생성하여 업로드하고, 세부 조정 작업을 실행하는 단계를 통해 **Azure에서** `gpt-35-turbo-0613` 모델을 세부 조정하는 방법을 배웁니다. 새로운 모델을 배포하고 사용하는 방법도 다룹니다.                                                                                                                                                                                       |\\n| Hugging Face | [Hugging Face로 LLM 세부 조정](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                                   | 이 블로그 포스트는 [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) 라이브러리와 [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst)을 사용하여 [Hugging Face의 공개 데이터셋](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst)과 함께 _오픈 LLM_ (예: `CodeLlama 7B`)을 세부 조정하는 방법을 알려줍니다. |\\n|              |                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                      |\\n| 🤗 AutoTrain | [AutoTrain로 LLM 세부 조정](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                               | AutoTrain(또는 AutoTrain Advanced)는 Hugging Face에서 개발한 Python 라이브러리로, 다양한 작업에 대한 세부 조정을 지원합니다. AutoTrain은 코드 없는 솔루션이며, Hugging Face Spaces, 로컬 또는 사용자의 클라우드에서 세부 조정을 수행할 수 있습니다. 웹 기반 GUI, 명령줄 인터페이스(CLI), 그리고 YAML 구성 파일을 통한 훈련을 지원합니다.                                                                                     |\\n|              |                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                      |', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332741, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=721, prompt_tokens=645, total_tokens=1366, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRYm7J0dX3F8H95VUHif2RQTrxf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n위의 튜토리얼 중 하나를 선택하고 따라가 보세요. _참고용으로만 이 저장소의 Jupyter 노트북에서 이러한 튜토리얼의 버전을 복제할 수 있습니다. 최신 버전을 얻으려면 원본 소스를 직접 사용하십시오_.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332748, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=67, prompt_tokens=76, total_tokens=143, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRaIazWr77CCQ1o2QMItGHBU00w', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 학습을 계속하세요.\\n\\n이 수업을 완료한 후 [Generative AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 Generative AI 지식을 계속 향상시키세요!\\n\\n축하합니다!! 이 과정의 v2 시리즈의 마지막 수업을 완료하셨습니다! 학습과 빌딩을 멈추지 마세요. \\\\*\\\\*[리소스](RESOURCES.md?WT.mc_id=academic-105485-koreyst) 페이지에서 이 주제에 대한 추가 제안을 확인하세요.\\n\\nv1 시리즈의 수업도 더 많은 과제와 개념으로 업데이트되었습니다. 잠시 시간을 내어 지식을 재정비하고, 이 수업들을 개선하기 위해 [질문과 피드백](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst)을 공유해주세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332750, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=212, prompt_tokens=214, total_tokens=426, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRdpugr1KoBcScEmX0MkQQA8y99', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 저코드 AI 애플리케이션 구축\\n\\n[![저코드 AI 애플리케이션 구축](./images/10-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson10-gh?WT.mc_id=academic-105485-koreyst)\\n\\n> _(이 강의의 영상을 보려면 위 이미지를 클릭하세요)_', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332753, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=87, prompt_tokens=102, total_tokens=189, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRfzc9iGyHNAccQen1Vl9cKeo2D', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이제 이미지를 생성하는 애플리케이션을 만드는 방법을 배웠으니, 로우 코드에 대해 이야기해 봅시다. 생성형 인공지능은 로우 코드 등 다양한 영역에서 사용될 수 있습니다. 하지만 로우 코드란 무엇이며, 여기에 AI를 어떻게 추가할 수 있을까요?\\n\\n로우 코드 개발 플랫폼(Low Code Development Platforms)을 사용하면 전통적인 개발자와 비개발자 모두 앱과 솔루션을 더 쉽게 만들 수 있습니다. 로우 코드 개발 플랫폼은 시각적 개발 환경을 제공하여 코드를 거의 또는 전혀 작성하지 않고도 앱과 솔루션을 만들 수 있도록 해줍니다. 이를 통해 컴포넌트를 드래그 앤 드롭하여 앱과 솔루션을 빠르고 적은 자원으로 만들 수 있습니다. 이 강의에서는 로우 코드를 사용하는 방법과 Power Platform을 사용하여 AI를 통해 로우 코드 개발을 향상시키는 방법에 대해 깊이 탐구합니다.\\n\\nPower Platform은 직관적인 로우 코드 또는 노 코드 환경을 통해 팀이 자신들의 솔루션을 만들 수 있도록 권한을 부여합니다. 이 환경은 솔루션을 만드는 과정을 간소화합니다. Power Platform을 사용하면 솔루션을 수개월 또는 수년이 아닌 며칠 또는 몇 주 만에 만들 수 있습니다. Power Platform은 파워 앱스(Power Apps), 파워 오토메이트(Power Automate), 파워 BI(Power BI), 파워 페이지(Power Pages), 코파일럿 스튜디오(Copilot Studio)의 다섯 가지 주요 제품으로 구성됩니다.\\n\\n이 강의에서는 다음 내용을 다룹니다:\\n\\n- Power Platform에서의 생성형 AI 소개\\n- 코파일럿 소개 및 사용 방법\\n- Power Platform에서 앱과 플로우를 구축하는 데 생성형 AI 사용하기\\n- AI 빌더와 함께 Power Platform의 AI 모델 이해하기', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332755, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=412, prompt_tokens=314, total_tokens=726, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRk3jc3cU6VfpYs9Owc6OOMQIAW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의가 끝나면 다음을 할 수 있습니다:\\n\\n- Power Platform에서 Copilot이 어떻게 작동하는지 이해합니다.\\n\\n- 우리 교육 스타트업을 위한 학생 과제 추적 앱을 구축합니다.\\n\\n- AI를 사용하여 청구서에서 정보를 추출하는 청구서 처리 흐름을 구축합니다.\\n\\n- GPT AI 모델로 텍스트 작성 시 모범 사례를 적용합니다.\\n\\n이 강의에서 사용될 도구 및 기술은 다음과 같습니다:\\n\\n- **Power Apps**: 학생 과제 추적 앱을 위한 것으로, 데이터를 추적, 관리 및 상호작용할 수 있는 저코드 개발 환경을 제공합니다.\\n\\n- **Dataverse**: 학생 과제 추적 앱의 데이터를 저장하기 위한 것으로, 앱의 데이터를 저장하기 위한 저코드 데이터 플랫폼을 제공합니다.\\n\\n- **Power Automate**: 청구서 처리 프로세스를 자동화하기 위한 워크플로를 구축할 수 있는 저코드 개발 환경을 제공합니다.\\n\\n- **AI Builder**: 스타트업을 위한 청구서를 처리하는 사전 구축된 AI 모델을 사용할 수 있습니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332760, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=238, prompt_tokens=228, total_tokens=466, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRn3uoICvkT4yQ9YI7RZHv23pQl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Power Platform의 생성형 AI\\n\\n저코드 개발 및 애플리케이션을 생성형 AI로 강화하는 것은 Power Platform의 주요 초점 분야입니다. 목표는 _데이터 과학 전문 지식 없이도_ 모든 사람들이 AI 기반 앱, 사이트, 대시보드 등의 생성 및 프로세스 자동화를 가능하게 하는 것입니다. 이 목표는 Copilot과 AI Builder의 형태로 Power Platform의 저코드 개발 환경에 생성형 AI를 통합하여 달성됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332763, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=104, prompt_tokens=113, total_tokens=217, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRpf0noMFGpL22WNCIbZGJtZHXk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 어떻게 작동하나요?\\n\\nCopilot은 자연어를 사용하여 일련의 대화 단계에서 요구사항을 설명함으로써 Power Platform 솔루션을 구축할 수 있게 하는 AI 어시스턴트입니다. 예를 들어, AI 어시스턴트에게 앱에서 사용할 필드를 지시하면, 앱과 그 기반 데이터 모델을 모두 생성할 수 있으며, Power Automate에서 흐름을 설정하는 방법을 지정할 수도 있습니다.\\n\\nCopilot 구동 기능을 앱 화면에서 기능으로 사용하여 사용자가 대화식 상호작용을 통해 인사이트를 발견할 수 있도록 할 수 있습니다.\\n\\nAI Builder는 Power Platform에서 사용할 수 있는 로우 코드 AI 기능으로, AI 모델을 사용하여 프로세스를 자동화하고 결과를 예측할 수 있도록 도와줍니다. AI Builder를 사용하면 Dataverse나 SharePoint, OneDrive 또는 Azure와 같은 다양한 클라우드 데이터 소스의 데이터에 연결된 앱 및 흐름에 AI를 도입할 수 있습니다.\\n\\nCopilot은 모든 Power Platform 제품에서 사용할 수 있습니다: Power Apps, Power Automate, Power BI, Power Pages, Power Virtual Agents. AI Builder는 Power Apps와 Power Automate에서 사용할 수 있습니다. 이번 수업에서는 Power Apps와 Power Automate에서 Copilot과 AI Builder를 사용하여 교육 스타트업을 위한 솔루션을 구축하는 방법에 대해 집중적으로 다뤄보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332765, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=299, prompt_tokens=268, total_tokens=567, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRtMYJoQGoK544iqqoXDtcfrft4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Power Apps의 Copilot\\n\\nPower Platform의 일부인 Power Apps는 데이터를 추적, 관리 및 상호작용할 수 있는 앱을 구축하기 위한 로우코드 개발 환경을 제공합니다. 이는 확장 가능한 데이터 플랫폼과 클라우드 서비스 및 온프레미스 데이터를 연결할 수 있는 기능을 갖춘 앱 개발 서비스의 모음입니다. Power Apps를 사용하면 브라우저, 태블릿 및 휴대폰에서 실행되는 앱을 구축하고 동료와 공유할 수 있습니다. Power Apps는 간단한 인터페이스로 사용자를 앱 개발에 쉽게 접근할 수 있도록 하여 모든 비즈니스 사용자 또는 프로 개발자가 맞춤형 앱을 구축할 수 있도록 합니다. Copilot을 통한 생성적 AI는 앱 개발 경험을 더욱 향상시킵니다.\\n\\nPower Apps의 Copilot AI 어시스턴트 기능을 통해 어떤 종류의 앱이 필요한지, 앱이 추적, 수집 또는 표시할 정보를 설명하면 됩니다. 그러면 Copilot은 설명에 따라 반응형 캔버스 앱을 생성합니다. 그런 다음 필요에 맞게 앱을 커스터마이즈할 수 있습니다. AI Copilot은 또한 추적하고자 하는 데이터를 저장하기 위해 필요한 필드와 샘플 데이터를 포함된 Dataverse Table을 생성하고 제안합니다. 이후의 수업에서 Dataverse가 무엇이며, 이를 Power Apps에서 어떻게 사용할 수 있는지 살펴보겠습니다. 대화형 단계를 통해 AI Copilot 어시스턴트 기능을 사용하여 테이블을 필요에 맞게 커스터마이즈할 수 있습니다. 이 기능은 Power Apps 홈 화면에서 쉽게 이용할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332769, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=350, prompt_tokens=297, total_tokens=647, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcRxag1IQEzElxa3UfFfLNb1jYKN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Power Automate의 Copilot\\n\\nPower Platform의 일부인 Power Automate는 사용자가 애플리케이션과 서비스 간에 자동화된 워크플로를 만들 수 있게 해줍니다. 이를 통해 커뮤니케이션, 데이터 수집 및 승인 결정과 같은 반복적인 비즈니스 프로세스를 자동화할 수 있습니다. 간단한 인터페이스를 통해 초보자부터 숙련된 개발자에 이르기까지 다양한 기술 역량을 가진 사용자들이 작업을 자동화할 수 있습니다. Copilot을 통해 생성형 AI를 사용하여 워크플로 개발 경험이 향상됩니다.\\n\\nPower Automate의 Copilot AI 보조 기능을 사용하면 필요한 흐름의 종류와 수행하고자 하는 작업을 설명할 수 있습니다. 그러면 Copilot이 설명을 기반으로 흐름을 생성합니다. 그런 다음 필요에 따라 흐름을 맞춤 설정할 수 있습니다. AI Copilot은 자동화하려는 작업을 수행하기 위해 필요한 작업도 생성하고 제안합니다. 이번 레슨에서는 흐름이 무엇인지 및 Power Automate에서 이를 사용하는 방법을 살펴보겠습니다. 그런 다음 대화형 단계를 통해 AI Copilot 보조 기능을 사용하여 필요에 맞게 작업을 맞춤 설정할 수 있습니다. 이 기능은 Power Automate 홈 화면에서 쉽게 사용할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332773, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=281, prompt_tokens=238, total_tokens=519, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcS1DgveI6p3GENM6o00SJR5lJll', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제: 학생 과제 및 송장을 관리하는 솔루션 구축, Copilot 사용\\n\\n우리 스타트업은 학생들에게 온라인 강좌를 제공합니다. 회사는 급속도로 성장하고 있으며, 강좌 수요를 따라잡기 힘들어 하고 있습니다. 따라서 학생 과제와 송장을 관리할 수 있는 저코드 솔루션을 구축하기 위해 여러분을 파워 플랫폼 개발자로 고용했습니다. 이 솔루션은 학생 과제를 앱을 통해 추적 및 관리하고, 워크플로를 통해 송장 처리 과정을 자동화할 수 있어야 합니다. 여러분은 이 솔루션을 개발하기 위해 생성형 AI를 사용하도록 요청받았습니다.\\n\\nCopilot을 사용 시작할 때, [파워 플랫폼 Copilot 프롬프트 라이브러리](https://github.com/pnp/powerplatform-prompts?WT.mc_id=academic-109639-somelezediko)를 사용할 수 있습니다. 이 라이브러리에는 Copilot을 사용하여 앱과 플로우를 구축할 수 있는 다양한 프롬프트 목록이 포함되어 있습니다. 또한 라이브러리의 프롬프트를 사용하여 Copilot에게 요구 사항을 설명하는 방법에 대한 아이디어를 얻을 수도 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332777, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=262, prompt_tokens=237, total_tokens=499, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcS5kWttJoPlTeI8c8TVQ2J3Z9AG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 스타트업을 위한 학생 과제 추적 앱 만들기\\n\\n우리 스타트업의 교육자들은 학생 과제를 추적하는 데 어려움을 겪고 있습니다. 그들은 스프레드시트를 사용하여 과제를 추적해왔으나, 학생 수가 증가함에 따라 관리가 어려워졌습니다. 이에 따라 교육자들은 새로운 과제를 추가하고, 과제를 조회하며, 과제를 업데이트하고 삭제할 수 있는 앱을 만들 것을 요청했습니다. 또한 교육자와 학생이 채점된 과제와 채점되지 않은 과제를 조회할 수 있어야 합니다.\\n\\n다음 단계에 따라 Power Apps에서 Copilot을 사용하여 앱을 만듭니다:\\n\\n1. [Power Apps](https://make.powerapps.com?WT.mc_id=academic-105485-koreyst) 홈 화면으로 이동합니다.\\n\\n1. 홈 화면의 텍스트 영역에 만들고자 하는 앱을 설명합니다. 예를 들어, **_학생 과제를 추적하고 관리하는 앱을 만들고 싶습니다_**라고 입력한 후 **전송** 버튼을 클릭하여 AI Copilot에 프롬프트를 보냅니다.\\n\\n![Describe the app you want to build](./images/copilot-chat-prompt-powerapps.png?WT.mc_id=academic-105485-koreyst)\\n\\n1. AI Copilot은 데이터를 저장하기 위해 필요한 필드와 몇 가지 샘플 데이터가 포함된 Dataverse 테이블을 제안합니다. 이후 AI Copilot 도우미 기능을 통해 대화형 단계로 테이블을 사용자 맞춤화할 수 있습니다.\\n\\n   > **중요**: Dataverse는 Power Platform의 기본 데이터 플랫폼입니다. 이는 앱의 데이터를 저장하기 위한 로우 코드 데이터 플랫폼으로, Microsoft Cloud에서 안전하게 데이터를 저장하는 완전 관리형 서비스입니다. 데이터 분류, 데이터 계보, 세밀한 접근 권한 제어 등 빌트인 데이터 거버넌스 기능이 제공됩니다. Dataverse에 대해 더 알고 싶다면 [여기를 클릭](https://docs.microsoft.com/powerapps/maker/data-platform/data-platform-intro?WT.mc_id=academic-109639-somelezediko)하세요.\\n\\n   ![Suggested fields in your new table](./images/copilot-dataverse-table-powerapps.png?WT.mc_id=academic-105485-koreyst)\\n\\n1. 교육자들은 과제를 제출한 학생들에게 이메일을 보내 진행 상황을 업데이트하고자 합니다. 이를 위해 AI Copilot에 새 필드를 추가하도록 지시할 수 있습니다. 예를 들어, **_학생 이메일을 저장할 열을 추가하고 싶습니다_**라고 프롬프트를 입력한 후 **전송** 버튼을 클릭합니다.\\n\\n![Adding a new field](./images/copilot-new-column.png?WT.mc_id=academic-105485-koreyst)\\n\\n1. AI Copilot은 새 필드를 생성하며, 이를 필요에 맞게 사용자 정의할 수 있습니다.\\n\\n1. 테이블 설정이 완료되면 **앱 만들기** 버튼을 클릭하여 앱을 만드세요.\\n\\n1. AI Copilot은 설명을 기반으로 반응형 캔버스 앱을 생성합니다. 이후 필요에 따라 앱을 사용자 정의할 수 있습니다.\\n\\n1. 교육자가 학생에게 이메일을 보내기 위해, Copilot을 사용해 앱에 새 화면을 추가할 수 있습니다. 예를 들어, **_학생에게 이메일을 보내는 화면을 추가하고 싶습니다_**라고 프롬프트를 입력한 후 **전송** 버튼을 클릭합니다.\\n\\n![Adding a new screen via a prompt instruction](./images/copilot-new-screen.png?WT.mc_id=academic-105485-koreyst)\\n\\n1. AI Copilot은 새 화면을 생성하며, 이를 필요에 맞게 사용자 정의할 수 있습니다.\\n\\n1. 앱 설정이 완료되면 **저장** 버튼을 클릭하여 앱을 저장하세요.\\n\\n1. 교육자와 앱을 공유하려면 **공유** 버튼을 클릭하고 다시 **공유** 버튼을 클릭합니다. 그런 다음 교육자의 이메일 주소를 입력하여 앱을 공유할 수 있습니다.\\n\\n> **당신의 과제**: 만든 앱은 좋은 출발점입니다. 하지만 이메일 기능의 경우 교육자가 학생의 이메일을 수동으로 입력해야 합니다. Power Automate의 Copilot을 사용하여 교육자가 학생이 과제를 제출할 때 자동으로 이메일을 보낼 수 있는 자동화 기능을 구축할 수 있습니까? 힌트: 올바른 프롬프트를 사용하면 Copilot을 통해 이를 구현할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332781, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=954, prompt_tokens=956, total_tokens=1910, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcSS2QMxb2qvdBV7MWIA4IUvUGwx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 우리 스타트업을 위한 송장 정보 표 만들기\\n\\n우리 스타트업의 재무팀은 송장을 추적하는 데 어려움을 겪고 있습니다. 그들은 송장을 추적하기 위해 스프레드시트를 사용해 왔지만 송장 수가 증가하면서 관리하기 어려워졌습니다. 이들은 수신한 송장의 정보를 저장, 추적, 관리할 수 있는 테이블을 만들어 달라고 요청했습니다. 이 테이블은 모든 송장 정보를 추출하여 저장할 수 있는 자동화 시스템을 구축하는 데 사용되어야 합니다. 또한, 재무팀이 지불된 송장과 지불되지 않은 송장을 확인할 수 있게 해야 합니다.\\n\\nPower Platform에는 앱과 솔루션의 데이터를 저장할 수 있는 Dataverse라는 기본 데이터 플랫폼이 있습니다. Dataverse는 앱의 데이터를 저장할 수 있는 로우 코드 데이터 플랫폼을 제공합니다. 이는 Microsoft Cloud에 안전하게 데이터를 저장하는 완전 관리형 서비스이며, Power Platform 환경 내에서 프로비저닝됩니다. 데이터 분류, 데이터 계보, 세분화된 접근 제어 등과 같은 내장 데이터 거버넌스 기능을 제공합니다. Dataverse에 대해 더 알아보려면 [여기에서 자세히 알아보세요](https://docs.microsoft.com/powerapps/maker/data-platform/data-platform-intro?WT.mc_id=academic-109639-somelezediko).\\n\\n우리 스타트업이 왜 Dataverse를 사용해야 할까요? Dataverse의 표준 및 사용자 정의 테이블은 데이터에 대해 안전하고 클라우드 기반의 저장 옵션을 제공합니다. 테이블을 사용하면 여러 Excel 워크북의 여러 워크시트처럼 다양한 유형의 데이터를 저장할 수 있습니다. 테이블을 사용하여 여러분의 조직이나 비즈니스 요구에 맞는 데이터를 저장할 수 있습니다. Dataverse를 사용하면 우리 스타트업이 얻게 될 혜택은 다음과 같습니다:\\n\\n- **관리 용이**: 메타데이터와 데이터 모두 클라우드에 저장되므로 저장되거나 관리되는 방법에 대해 걱정할 필요가 없습니다. 앱과 솔루션 개발에 집중할 수 있습니다.\\n\\n- **안전성**: Dataverse는 데이터에 대해 안전하고 클라우드 기반의 저장 옵션을 제공합니다. 역할 기반 보안을 사용하여 테이블 데이터에 대한 접근 권한과 접근 방법을 제어할 수 있습니다.\\n\\n- **풍부한 메타데이터**: 데이터 유형 및 관계가 Power Apps 내에서 직접 사용됩니다.\\n\\n- **로직 및 검증**: 비즈니스 규칙, 계산된 필드, 검증 규칙을 사용하여 비즈니스 로직을 적용하고 데이터 정확성을 유지할 수 있습니다.\\n\\n이제 Dataverse가 무엇인지, 왜 사용해야 하는지 알았으니 Copilot을 사용해 재무팀의 요구에 맞는 테이블을 만드는 방법을 알아보겠습니다.\\n\\n> **노트**: 이 테이블은 다음 섹션에서 모든 송장 정보를 추출하고 테이블에 저장하는 자동화를 구축하는 데 사용됩니다.\\n\\nCopilot을 사용하여 Dataverse에서 테이블을 만들려면 다음 단계를 따르세요:\\n\\n1. [Power Apps](https://make.powerapps.com?WT.mc_id=academic-105485-koreyst) 홈 화면으로 이동합니다.\\n\\n2. 왼쪽 탐색 막대에서 **테이블**을 선택한 다음 **새 테이블 설명**을 클릭합니다.\\n\\n![새 테이블 선택](./images/describe-new-table.png?WT.mc_id=academic-105485-koreyst)\\n\\n3. **새 테이블 설명** 화면에서 텍스트 영역에 만들고자 하는 테이블을 설명합니다. 예를 들어, **_송장 정보를 저장할 테이블을 생성하고 싶습니다_**라고 입력합니다. **보내기** 버튼을 클릭하여 AI Copilot에 메시지를 보냅니다.\\n\\n![테이블 설명](./images/copilot-chat-prompt-dataverse.png?WT.mc_id=academic-105485-koreyst)\\n\\n4. AI Copilot은 추적하려는 데이터를 저장할 수 있는 Dataverse 테이블과 일부 샘플 데이터를 제안합니다. 이후 대화형으로 테이블을 사용자 정의할 수 있습니다.\\n\\n![추천 Dataverse 테이블](./images/copilot-dataverse-table.png?WT.mc_id=academic-105485-koreyst)\\n\\n5. 재무팀은 송장 상태를 공급업체에게 업데이트해주기 위해 이메일을 보내고 싶어 합니다. Copilot을 사용하여 테이블에 공급업체 이메일을 저장하는 새 필드를 추가할 수 있습니다. 예를 들어, **_공급업체 이메일을 저장할 열을 추가하고 싶습니다_**라는 메시지를 사용해 필드를 추가할 수 있습니다. **보내기** 버튼을 클릭하여 AI Copilot에 메시지를 보냅니다.\\n\\n6. AI Copilot은 새 필드를 생성하며, 이후 필요에 맞게 필드를 사용자 정의할 수 있습니다.\\n\\n7. 테이블 설정이 완료되면 **생성** 버튼을 클릭하여 테이블을 만듭니다.\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332804, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=1070, prompt_tokens=976, total_tokens=2046, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcSiuJb4U4ZaIlzhCVJGUsMWLWIH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## AI Builder를 사용한 Power Platform의 AI 모델\\n\\nAI Builder는 Power Platform에서 제공하는 로우코드 AI 기능으로, 프로세스를 자동화하고 결과를 예측하는 데 도움을 주는 AI 모델을 사용할 수 있게 해줍니다. AI Builder를 사용하면 Dataverse나 SharePoint, OneDrive 또는 Azure와 같은 다양한 클라우드 데이터 소스에 있는 데이터에 연결되는 앱과 흐름에 AI를 도입할 수 있습니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332820, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=98, prompt_tokens=104, total_tokens=202, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcSjyZE5y50UHnjN1VsKblV9R5T8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 사전 제작된 AI 모델 vs 사용자 정의 AI 모델\\n\\nAI 빌더는 두 가지 유형의 AI 모델을 제공합니다: 사전 제작된 AI 모델과 사용자 정의 AI 모델. 사전 제작된 AI 모델은 Microsoft가 훈련하고 Power Platform에서 사용할 수 있는 준비된 AI 모델입니다. 이 모델들은 데이터를 수집하지 않고도 직접 모델을 구축, 훈련, 게시할 필요 없이 애플리케이션과 흐름에 인텔리전스를 추가할 수 있게 도와줍니다. 이러한 모델을 사용하여 프로세스를 자동화하고 결과를 예측할 수 있습니다.\\n\\nPower Platform에서 사용할 수 있는 일부 사전 제작된 AI 모델은 다음과 같습니다:\\n\\n- **핵심 구절 추출**: 이 모델은 텍스트에서 핵심 구절을 추출합니다.\\n- **언어 감지**: 이 모델은 텍스트의 언어를 감지합니다.\\n- **감정 분석**: 이 모델은 텍스트의 긍정적, 부정적, 중립적 또는 혼합된 감정을 감지합니다.\\n- **명함 리더**: 이 모델은 명함에서 정보를 추출합니다.\\n- **텍스트 인식**: 이 모델은 이미지에서 텍스트를 추출합니다.\\n- **객체 감지**: 이 모델은 이미지에서 객체를 감지하고 추출합니다.\\n- **문서 처리**: 이 모델은 양식에서 정보를 추출합니다.\\n- **송장 처리**: 이 모델은 송장에서 정보를 추출합니다.\\n\\n사용자 정의 AI 모델을 사용하면 AI 빌더에 자신의 모델을 추가할 수 있으며, 이 모델은 AI 빌더의 사용자 정의 모델처럼 작동하게 됩니다. 자신의 데이터를 사용하여 모델을 훈련시킬 수 있으며, 이를 통해 Power Apps 및 Power Automate에서 프로세스를 자동화하고 결과를 예측할 수 있습니다. 사용자의 모델을 사용할 때는 제한 사항이 존재합니다. 이러한 제한 사항에 대해 더 자세히 알아보려면 [여기](https://learn.microsoft.com/ai-builder/byo-model#limitations?WT.mc_id=academic-105485-koreyst)를 클릭하세요.\\n\\n![AI builder models](./images/ai-builder-models.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332821, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=488, prompt_tokens=375, total_tokens=863, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTAeQmsFEvk7DystSZ8OMpd349V', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제 #2 - 스타트업을 위한 청구서 처리 흐름 구축하기\\n\\n재무 팀은 청구서를 처리하는 데 어려움을 겪고 있습니다. 그들은 청구서를 추적하기 위해 스프레드시트를 사용하고 있지만 청구서의 수가 증가함에 따라 관리가 어려워졌습니다. 그들은 AI를 사용하여 청구서를 처리할 수 있는 워크플로우를 구축해달라고 요청했습니다. 워크플로우는 청구서에서 정보를 추출하여 Dataverse 테이블에 저장하고, 재무 팀에게 추출된 정보를 이메일로 보낼 수 있어야 합니다.\\n\\n이제 AI Builder가 무엇이고 왜 사용해야 하는지 알아보았으므로, AI Builder에서 이전에 다룬 청구서 처리 AI 모델을 사용하여 재무 팀이 청구서를 처리할 수 있도록 돕는 워크플로우를 구축하는 방법을 알아봅시다.\\n\\n청구서 처리 AI 모델을 사용하여 재무 팀이 청구서를 처리할 수 있도록 돕는 워크플로우를 구축하려면 다음 단계를 따르십시오:\\n\\n1. [Power Automate](https://make.powerautomate.com?WT.mc_id=academic-105485-koreyst) 홈 화면으로 이동합니다.\\n\\n2. 홈 화면의 텍스트 영역을 사용하여 구축하려는 워크플로우를 설명합니다. 예를 들어, **_내 메일함에 도착하는 청구서를 처리합니다_**. **보내기** 버튼을 클릭하여 AI Copilot에 프롬프트를 전송합니다.\\n\\n   ![Copilot power automate](./images/copilot-chat-prompt-powerautomate.png?WT.mc_id=academic-105485-koreyst)\\n\\n3. AI Copilot는 자동화하려는 작업을 수행하는 데 필요한 작업을 제안합니다. **다음** 버튼을 클릭하여 다음 단계를 진행합니다.\\n\\n4. 다음 단계에서는 Power Automate가 흐름에 필요한 연결을 설정하도록 요청합니다. 완료되면 **흐름 생성** 버튼을 클릭하여 흐름을 만듭니다.\\n\\n5. AI Copilot에서 흐름을 생성하면 이를 필요에 따라 커스터마이즈합니다.\\n\\n6. 흐름의 트리거를 업데이트하고 **폴더**를 청구서가 저장될 폴더로 설정합니다. 예를 들어, 폴더를 **받은 편지함**으로 설정할 수 있습니다. **고급 옵션 표시**를 클릭하고 **첨부 파일만**을 **예**로 설정합니다. 이는 첨부 파일이 있는 이메일이 해당 폴더에 수신될 때만 흐름이 실행되도록 합니다.\\n\\n7. 흐름에서 **HTML을 텍스트로**, **작성**, **작성 2**, **작성 3** 및 **작성 4** 작업을 제거합니다. 이는 사용하지 않기 때문입니다.\\n\\n8. **조건** 작업을 흐름에서 제거합니다. 이는 사용하지 않기 때문입니다. 다음 스크린샷과 같이 보여야 합니다:\\n\\n   ![power automate, remove actions](./images/powerautomate-remove-actions.png?WT.mc_id=academic-105485-koreyst)\\n\\n9. **작업 추가** 버튼을 클릭하고 **Dataverse**를 검색합니다. **새 행 추가** 작업을 선택합니다.\\n\\n10. **청구서에서 정보 추출** 작업에서 **청구서 파일**을 이메일의 **첨부 파일 내용**을 가리키도록 업데이트합니다. 이는 흐름이 청구서 첨부 파일에서 정보를 추출하도록 합니다.\\n\\n11. 이전에 생성한 **테이블**을 선택합니다. 예를 들어, **청구서 정보** 테이블을 선택할 수 있습니다. 이전 작업에서 동적 콘텐츠를 선택하여 다음 필드를 채웁니다:\\n\\n    - ID\\n    - 금액\\n    - 날짜\\n    - 이름\\n    - 상태 - **상태**를 **보류 중**으로 설정합니다.\\n    - 공급업체 이메일 - **새 이메일 도착 시** 트리거의 **발신자** 동적 콘텐츠를 사용합니다.\\n\\n    ![power automate add row](./images/powerautomate-add-row.png?WT.mc_id=academic-105485-koreyst)\\n\\n12. 흐름이 완료되면 **저장** 버튼을 클릭하여 흐름을 저장합니다. 지정한 트리거 폴더에 청구서를 첨부한 이메일을 보내 흐름을 테스트할 수 있습니다.\\n\\n> **숙제**: 방금 구축한 흐름은 좋은 시작입니다. 이제 재무 팀이 청구서의 현재 상태를 업데이트하기 위해 공급업체에게 이메일을 보낼 수 있도록 하는 자동화를 구축하는 방법을 생각해 보세요. 힌트: 흐름은 청구서의 상태가 변경될 때 실행되어야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332848, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=1032, prompt_tokens=911, total_tokens=1943, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTKHAe7HlDjkFi6izzFQnmxHATQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Power Automate에서 텍스트 생성 AI 모델 사용\\n\\nAI Builder의 GPT AI 모델로 텍스트 생성 기능은 Microsoft Azure OpenAI 서비스를 통해 제공되며, 프롬프트를 기반으로 텍스트를 생성할 수 있습니다. 이 기능을 사용하여 앱과 흐름에 GPT(Generative Pre-Trained Transformer) 기술을 통합하고 다양한 자동화된 흐름과 유용한 애플리케이션을 구축할 수 있습니다.\\n\\nGPT 모델은 방대한 데이터로 광범위하게 학습되어 프롬프트를 제공하면 사람의 언어와 유사한 텍스트를 생성할 수 있습니다. 워크플로우 자동화와 통합되면, GPT와 같은 AI 모델을 활용하여 다양한 작업을 간소화하고 자동화할 수 있습니다.\\n\\n예를 들어, 이메일 초안, 제품 설명 등 다양한 용도로 텍스트를 자동 생성하는 흐름을 구축할 수 있습니다. 또한, 챗봇과 고객 서비스 애플리케이션 등 다양한 앱에서 텍스트를 생성하도록 모델을 활용하여, 고객 서비스 요원이 고객 문의에 효과적으로 그리고 효율적으로 응답할 수 있도록 도울 수 있습니다.\\n\\n![프롬프트 생성](./images/create-prompt-gpt.png?WT.mc_id=academic-105485-koreyst)\\n\\nPower Automate에서 이 AI 모델을 사용하는 방법을 배우려면, [AI Builder와 GPT로 지능 추가](https://learn.microsoft.com/training/modules/ai-builder-text-generation/?WT.mc_id=academic-109639-somelezediko) 모듈을 확인해 보세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332858, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=340, prompt_tokens=303, total_tokens=643, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTOyFhL1c0wIzKu92SoHlk3YlKZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 멋진 작업! 학습을 계속하세요\\n\\n이 강의를 마친 후, [Generative AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 Generative AI 지식을 계속 쌓아보세요!\\n\\nLesson 11으로 이동하여 [Function Calling과 Generative AI 통합](../11-integrating-with-function-calling/README.md?WT.mc_id=academic-105485-koreyst)에 대해 알아보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332862, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=109, prompt_tokens=129, total_tokens=238, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTP42zWKcybyokewwQkmq9eHDq6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 생성형 AI 애플리케이션 수명 주기\\n\\n모든 AI 애플리케이션의 중요한 질문은 AI 기능의 관련성입니다. AI는 빠르게 진화하는 분야이므로 애플리케이션이 관련성, 신뢰성, 견고성을 유지하기 위해 지속적으로 모니터링, 평가 및 개선해야 합니다. 여기서 생성형 AI 수명 주기가 중요한 역할을 합니다.\\n\\n생성형 AI 수명 주기는 생성형 AI 애플리케이션을 개발, 배포 및 유지 관리하는 단계를 안내하는 프레임워크입니다. 이를 통해 목표를 정의하고 성과를 측정하며 도전 과제를 식별하고 솔루션을 구현할 수 있습니다. 또한 도메인 및 이해관계자의 윤리적 및 법적 기준에 애플리케이션을 정렬하는 데 도움을 줍니다. 생성형 AI 수명 주기를 따름으로써 애플리케이션이 항상 가치를 제공하고 사용자 만족을 실현할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332863, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=216, prompt_tokens=186, total_tokens=402, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTRTtjcIBkQf7BOycPgot6DgQtA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 장에서는 다음을 다룰 것입니다:\\n\\n- MLOps에서 LLMOps로의 패러다임 전환 이해하기\\n- LLM 생애 주기\\n- 생애 주기 도구\\n- 생애 주기 지표화 및 평가', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332865, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=58, prompt_tokens=72, total_tokens=130, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTTHqTK7Ap7EB0qWqOxdQMEpdtL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## MLOps에서 LLMOps로의 패러다임 전환 이해하기\\n\\nLLM(대규모 언어 모델)은 인공지능 무기고의 새로운 도구로, 응용 프로그램을 위한 분석 및 생성 작업에서 매우 강력합니다. 그러나 이러한 강력함은 AI 및 고전적인 머신 러닝 작업을 효율화하는 방식에 몇 가지 영향을 미칩니다.\\n\\n이를 위해, 우리는 이 도구를 동적으로 적응시키기 위한 새로운 패러다임이 필요합니다. 우리는 과거의 AI 앱을 \"ML 앱\"으로, 새로운 AI 앱을 \"GenAI 앱\" 또는 단순히 \"AI 앱\"으로 분류할 수 있으며, 이는 당시 사용된 주류 기술과 기법을 반영합니다. 이로 인해 여러 방식으로 우리의 이야기가 변화합니다. 다음 비교를 살펴보십시오.\\n\\n![LLMOps vs. MLOps 비교](./images/01-llmops-shift.png?WT.mc_id=academic-105485-koreys)\\n\\nLLMOps에서는 통합을 주요 지점으로 사용하여 앱 개발자에게 더 집중하고, \"서비스로서의 모델\"을 사용하며 다음과 같은 지점에서 메트릭스를 고려합니다.\\n\\n- 품질: 응답 품질\\n- 피해: 책임 있는 AI\\n- 정직: 응답의 근거 (말이 되는가? 정확한가?)\\n- 비용: 솔루션 예산\\n- 지연: 토큰 응답 평균 시간', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332867, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=314, prompt_tokens=276, total_tokens=590, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTXnKxXvRuMN61kmkrdEifkTcHs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## LLM 라이프사이클\\n\\n먼저, 라이프사이클과 그 변화를 이해하려면 다음 인포그래픽을 참고하세요.\\n\\n![LLMOps 인포그래픽](./images/02-llmops.png?WT.mc_id=academic-105485-koreys)\\n\\n보시다시피 이것은 일반적인 MLOps의 라이프사이클과는 다릅니다. LLMs는 프롬프트, 품질 개선 기술(미세조정, RAG, 메타 프롬프트), 책임 있는 AI를 위한 평가와 책임, 마지막으로 새로운 평가 지표(품질, 해악, 정직, 비용 및 지연 시간)와 같은 많은 새로운 요구 사항을 가지고 있습니다.\\n\\n예를 들어, 우리는 프롬프트 엔지니어링을 사용하여 다양한 LLM을 실험해 가설이 맞는지 테스트할 수 있는 방법을 고안합니다.\\n\\n이것은 선형적이지 않고 통합된 루프, 반복적이고 포괄적인 사이클로 이루어져 있습니다.\\n\\n이 단계들을 어떻게 탐구할 수 있을까요? 라이프사이클을 구축하는 방법에 대해 자세히 알아보겠습니다.\\n\\n![LLMOps 워크플로우](./images/03-llm-stage-flows.png?WT.mc_id=academic-105485-koreys)\\n\\n이것은 다소 복잡해 보일 수 있지만, 먼저 세 가지 주요 단계에 집중해 봅시다.\\n\\n1. 아이디어 구상/탐색: 탐색 단계에서는 비즈니스 필요에 따라 탐색할 수 있습니다. 프로토타입을 만들고 [PromptFlow](https://microsoft.github.io/promptflow/index.html?WT.mc_id=academic-105485-koreyst)를 생성하여 가설이 충분히 효율적인지 테스트합니다.\\n1. 구축/증강: 구현 단계에서는 더 큰 데이터 세트를 평가하고 미세조정과 RAG와 같은 기술을 도입하여 솔루션의 강건성을 확인합니다. 만약 그렇지 않다면, 새로운 단계를 추가하거나 데이터를 재구조화하여 재구현할 수 있습니다. 플로우와 규모를 테스트하고 지표를 확인한 후 다음 단계로 넘어갑니다.\\n1. 운영화: 통합 단계에서는 시스템에 모니터링 및 알림 시스템을 추가하고 배포와 애플리케이션 통합을 수행합니다.\\n\\n그런 다음 보안, 컴플라이언스 및 거버넌스를 중점으로 관리하는 포괄적인 사이클이 있습니다.\\n\\n축하합니다. 이제 AI 앱이 준비되었고 운영 준비가 되었습니다. 실습을 위해 [Contoso Chat Demo](https://nitya.github.io/contoso-chat/?WT.mc_id=academic-105485-koreys)를 참고하세요.\\n\\n이제 어떤 도구를 사용할 수 있을까요?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332871, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=610, prompt_tokens=531, total_tokens=1141, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTdbnxGSfDeLLXoiOQqSK5nahg9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 라이프사이클 도구\\n\\n도구에 있어 Microsoft는 [Azure AI 플랫폼](https://azure.microsoft.com/solutions/ai/?WT.mc_id=academic-105485-koreys)과 [PromptFlow](https://microsoft.github.io/promptflow/index.html?WT.mc_id=academic-105485-koreyst)를 제공하여 당신의 사이클 구현을 쉽게 하고 바로 시작할 수 있도록 돕습니다.\\n\\n[Azure AI 플랫폼](https://azure.microsoft.com/solutions/ai/?WT.mc_id=academic-105485-koreys)은 [AI 스튜디오](https://ai.azure.com/?WT.mc_id=academic-105485-koreys)를 사용하게 합니다. AI 스튜디오는 웹 포털로, 모델, 샘플 및 도구를 탐색할 수 있게 합니다. 자원을 관리하고, UI 개발 흐름과 코드-우선 개발을 위한 SDK/CLI 옵션을 제공합니다.\\n\\n![Azure AI 가능성](./images/04-azure-ai-platform.png?WT.mc_id=academic-105485-koreys)\\n\\nAzure AI는 여러 자원을 사용하여 운영, 서비스, 프로젝트, 벡터 검색 및 데이터베이스 요구 사항을 관리할 수 있도록 합니다.\\n\\n![Azure AI를 통한 LLMOps](./images/05-llm-azure-ai-prompt.png?WT.mc_id=academic-105485-koreys)\\n\\nProof-of-Concept(POC)부터 대규모 애플리케이션까지 PromptFlow로 구성하십시오:\\n\\n- 시각적이고 기능적인 도구를 사용하여 VS Code에서 앱을 디자인하고 빌드하십시오.\\n- 품질 높은 AI를 위해 앱을 테스트하고 미세 조정하십시오.\\n- Azure AI 스튜디오를 사용하여 클라우드와 통합하고, 푸시 및 배포를 통해 빠른 통합을 수행하십시오.\\n\\n![PromptFlow를 통한 LLMOps](./images/06-llm-promptflow.png?WT.mc_id=academic-105485-koreys)\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332877, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=420, prompt_tokens=384, total_tokens=804, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTkAXfcDqKr411BWxT6Y6yDRUHd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭해요! 학습을 계속하세요!\\n\\n놀랍습니다! 이제 [Contoso Chat App](https://nitya.github.io/contoso-chat/?WT.mc_id=academic-105485-koreyst)를 통해 애플리케이션을 구조화하고 개념을 사용하는 방법을 학습하세요. 이를 통해 클라우드 옹호가 시연에서 어떻게 이러한 개념을 추가하는지 확인할 수 있습니다. 더 많은 콘텐츠는 우리의 [Ignite breakout session!](https://www.youtube.com/watch?v=DdOylyrTOWg)을 확인하세요.\\n\\n이제 15강을 확인하여 [Retrieval Augmented Generation and Vector Databases](../15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst)가 생성 AI에 미치는 영향과 더 매력적인 애플리케이션을 만드는 방법을 이해하세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332884, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=191, prompt_tokens=178, total_tokens=369, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTnICuVhsMyVsISJHZPitlIzbAV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 고급 프롬프트 생성\\n\\n[![고급 프롬프트 생성](./images/05-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst?WT.mc_id=academic-105485-koreyst)\\n\\n지난 챕터에서 배운 내용을 요약해 봅시다:\\n\\n> 프롬프트 _엔지니어링_은 더 유용한 지시 사항이나 컨텍스트를 제공하여 모델을 **더 관련성 있는 응답으로 안내하는** 과정입니다.\\n\\n프롬프트를 작성하는 데는 두 가지 단계가 있습니다. 첫 번째는 관련 컨텍스트를 제공하는 프롬프트 생성이고, 두 번째는 프롬프트를 점진적으로 개선하는 _최적화_ 단계입니다.\\n\\n이 시점에서 우리는 프롬프트를 작성하는 기본적인 이해를 가지고 있지만, 더 깊이 들어가야 합니다. 이 챕터에서는 다양한 프롬프트를 시도해 보고 왜 특정 프롬프트가 다른 것보다 더 나은지 이해하는 과정을 거치게 됩니다. 또한, 모든 LLM(대형 언어 모델)에 적용할 수 있는 몇 가지 기본 기술을 활용하여 프롬프트를 구성하는 방법을 배우게 됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332887, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=289, prompt_tokens=231, total_tokens=520, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTsfz19wYUX6KBmXkPtlpCe88Dx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이번 장에서는 다음 주제를 다룰 것입니다:\\n\\n- 다양한 기법을 프롬프트에 적용하여 프롬프트 엔지니어링에 대한 지식을 확장합니다.\\n- 출력을 다양하게 하기 위해 프롬프트를 구성합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332892, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=58, prompt_tokens=67, total_tokens=125, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTtRUFXTN5CRgw2cPDU9OWH0v4K', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 수업을 완료한 후 다음을 할 수 있습니다:\\n\\n- 프롬프트 결과를 개선하는 프롬프트 엔지니어링 기술을 적용합니다.\\n- 다양하거나 결정론적인 프롬프팅을 수행합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332893, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=56, prompt_tokens=65, total_tokens=121, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTv1NZlEltfqO8Hw3w5S7Ao2ykl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 프롬프트 엔지니어링\\n\\n프롬프트 엔지니어링은 원하는 결과를 도출하기 위해 프롬프트를 생성하는 과정입니다. 프롬프트 엔지니어링에는 단순히 텍스트 프롬프트를 작성하는 것 이상의 것이 포함됩니다. 프롬프트 엔지니어링은 공학 분야라기보다는 원하는 결과를 얻기 위해 적용할 수 있는 다양한 기법들의 집합입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332895, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=102, prompt_tokens=83, total_tokens=185, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTxBXGFSoIatmKhUY0KuJ3JPStM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 프롬프트의 예시\\n\\n다음과 같은 기본적인 프롬프트를 살펴보겠습니다:\\n\\n> 지리에 관한 질문 10개를 생성하세요.\\n\\n이 프롬프트에서는 실제로 여러 프롬프트 기법을 적용하고 있습니다.\\n\\n이를 분석해 봅시다.\\n\\n- **컨텍스트(맥락)**, \"지리\"에 관한 것임을 명시합니다.\\n- **출력 제한**, 10개 이상의 질문을 원하지 않습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332897, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=104, prompt_tokens=102, total_tokens=206, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcTzwdwZH7vtlPq8GXWYjUNa222j', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 간단한 프롬프트의 한계\\n\\n원하는 결과를 얻을 수도, 얻지 못할 수도 있습니다. 질문이 생성되긴 하겠지만, 지리학은 방대한 주제로 다음과 같은 이유로 원하는 것을 얻지 못할 수 있습니다:\\n\\n- **방대한 주제**: 주제가 국가, 수도, 강 등 무엇에 관한 것인지 알 수 없습니다.\\n- **형식**: 질문이 특정 형식으로 포맷되기를 원하는 경우는 어떻게 할까요?\\n\\n보시다시피, 프롬프트를 생성할 때 고려해야 할 사항이 많습니다.\\n\\n지금까지 간단한 프롬프트 예제를 보았지만, 생성형 인공지능은 다양한 역할과 산업의 사람들을 돕기 위해 훨씬 더 많은 일을 수행할 수 있습니다. 다음으로 몇 가지 기본 기법을 살펴보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332899, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=186, prompt_tokens=164, total_tokens=350, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcU3sueMMpsUZjnfImp0IpgKCea8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 프롬프트 생성 기법\\n\\n먼저, 프롬프트 생성은 LLM의 _출현적_ 특성이라는 것을 이해해야 합니다. 이는 모델에 내장된 기능이 아니라 모델을 사용하는 과정에서 발견되는 특성입니다.\\n\\nLLM을 프롬프트하는 데 사용할 수 있는 몇 가지 기본 기법이 있습니다. 함께 살펴보겠습니다.\\n\\n- **제로샷 프롬프트**: 이것은 가장 기본적인 형태의 프롬프트입니다. 단일 프롬프트를 사용하여 LLM의 학습 데이터만을 기반으로 응답을 요청합니다.\\n- **퓨샷 프롬프트**: 이 유형의 프롬프트는 LLM이 응답을 생성할 때 참고할 수 있는 1개 이상의 예를 제공하여 안내합니다.\\n- **사고의 연쇄**: 이 유형의 프롬프트는 LLM에게 문제를 단계별로 나누어 해결하는 방법을 알려줍니다.\\n- **생성된 지식**: 프롬프트의 응답을 개선하기 위해 생성된 사실이나 지식을 추가로 제공할 수 있습니다.\\n- **가장 적은 단계에서 가장 많은 단계로**: 사고의 연쇄와 비슷하게, 이 기법은 문제를 일련의 단계로 나누고 차례로 이러한 단계를 수행하도록 요청하는 것입니다.\\n- **자체 정제**: 이 기법은 LLM의 출력을 비평하고 개선하도록 요청하는 것입니다.\\n- **산파적 프롬프트**: 여기서 원하는 것은 LLM의 응답이 정확한지 확인하고, 응답의 다양한 부분을 설명하도록 요청하는 것입니다. 이것은 자체 정제의 한 형태입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332903, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=366, prompt_tokens=312, total_tokens=678, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUDcwSYHj9AUtbdLABzr96z2Aa8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 제로샷 프롬프트\\n\\n이 스타일의 프롬프트는 매우 간단하며, 단일 프롬프트로 구성됩니다. 이 기술은 아마도 여러분이 대형 언어 모델(LLM)에 대해 배우기 시작할 때 사용하고 있을 것입니다. 다음은 예시입니다:\\n\\n- 프롬프트: \"대수학이란 무엇인가?\"\\n- 답변: \"대수학은 수학의 한 분야로, 수학적 기호와 이 기호들을 조작하는 규칙을 연구합니다.\"', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332913, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=117, prompt_tokens=100, total_tokens=217, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUFpLkkC2ii7vNke9KY3YBUa3uj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Few-shot prompting\\n\\n이 스타일의 프롬프트는 요청과 함께 몇 가지 예시를 제공하여 모델을 도와줍니다. 단일 프롬프트에 추가적인 작업 특정 데이터를 포함합니다. 다음은 예시입니다:\\n\\n- 프롬프트: \"셰익스피어 스타일로 시를 써 주세요. 다음은 셰익스피어의 소네트 몇 가지 예시입니다:\\n  소네트 18: \\'내가 너를 여름날에 비유해야 할까? 너는 더 사랑스럽고 온화한데...\\'\\n  소네트 116: \\'진정한 마음의 결혼에 방해가 없도록 하게. 사랑은 변하지 않는 것이니 변화를 찾아도...\\'\\n  소네트 132: \\'내가 사랑하는 너의 눈은, 내 마음의 괴로움 알기에 나를 멸시하는 듯,...\\'\\n  이제, 달의 아름다움에 대한 소네트를 써주세요.\"\\n- 답변: \"하늘 위에 떠오른 달은 부드럽게 빛나네, 은빛의 빛이 그 온화한 은혜를 드리우네,...\"\\n\\n예시들은 LLM에게 원하는 출력물의 문맥, 형식 또는 스타일을 제공합니다. 이러한 예시들은 모델이 특정 작업을 이해하고 더 정확하고 관련성 높은 응답을 생성하도록 도와줍니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332915, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=304, prompt_tokens=257, total_tokens=561, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcULac5KiOHPJXYyoNHgaa2oMbMD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 사고 사슬\\n\\n사고 사슬은 LLM을 여러 단계로 안내하는 매우 흥미로운 기법입니다. 이 아이디어는 LLM이 어떤 일을 수행하는 방법을 이해하도록 지시하는 것입니다. 사고 사슬을 사용하지 않은 예시와 사용한 예시를 고려해 보세요:\\n\\n    - 프롬프트: \"Alice는 사과 5개가 있는데 사과 3개를 던지고, 2개를 Bob에게 주었으며, Bob이 하나를 다시 돌려줬습니다. Alice에게 몇 개의 사과가 남아 있습니까?\"\\n    - 답변: 5\\n\\nLLM은 5라고 답하지만, 이는 틀린 답입니다. 올바른 답은 계산에 따라 사과 1개입니다 (5 - 3 - 2 + 1 = 1).\\n\\n그렇다면 이 문제를 올바르게 해결하도록 LLM을 어떻게 가르칠 수 있을까요?\\n\\n사고 사슬을 시도해봅시다. 사고 사슬을 적용하면 다음과 같습니다:\\n\\n1. LLM에게 유사한 예시를 제공합니다.\\n2. 계산 방법과 올바른 계산 방법을 보여줍니다.\\n3. 원래 프롬프트를 제공합니다.\\n\\n다음과 같이 진행해 봅니다:\\n\\n- 프롬프트: \"Lisa는 사과 7개가 있고, 사과 1개를 던지며, 사과 4개를 Bart에게 주었고, Bart는 하나를 다시 돌려줬습니다:\\n  7 - 1 = 6\\n  6 - 4 = 2\\n  2 + 1 = 3  \\n  Alice는 사과 5개가 있는데 사과 3개를 던지고, 2개를 Bob에게 주었으며, Bob이 하나를 다시 돌려줬습니다. Alice에게 몇 개의 사과가 남아 있습니까?\"\\n  답변: 1\\n\\n다른 예시와 계산, 그리고 원래의 프롬프트를 포함하는 더 긴 프롬프트를 작성하여 우리는 올바른 답인 1에 도달합니다.\\n\\n보시다시피 사고 사슬은 매우 강력한 기법입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332921, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=474, prompt_tokens=356, total_tokens=830, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUVS5CUFZw66pprM41sqTz5IUEO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 생성된 지식\\n\\n많은 경우 프롬프트를 구성할 때, 자신의 회사 데이터를 사용하고자 합니다. 프롬프트의 일부는 회사의 정보로 채우고, 다른 부분은 실제로 관심이 있는 프롬프트로 구성해야 합니다.\\n\\n예를 들어, 보험 업계에 있는 경우 프롬프트가 다음과 같이 보일 수 있습니다:\\n\\n```text\\n{{company}}: {{company_name}}\\n{{products}}:\\n{{products_list}}\\n다음 예산 및 요구사항에 따라 보험을 제안해 주세요:\\n예산: {{budget}}\\n요구사항: {{requirements}}\\n```\\n\\n위와 같이, 템플릿을 사용하여 프롬프트를 구성할 수 있습니다. 템플릿에는 `{{variable}}`로 표시된 여러 변수들이 실제 회사 API 의 값으로 대체됩니다.\\n\\n회사의 데이터로 변수를 대체한 후, 프롬프트는 다음과 같이 보일 수 있습니다:\\n\\n```text\\n보험 회사: ACME 보험\\n보험 상품(월 비용):\\n- 자동차, 저렴, 500 USD\\n- 자동차, 고가, 1100 USD\\n- 주택, 저렴, 600 USD\\n- 주택, 고가, 1200 USD\\n- 생명, 저렴, 100 USD\\n\\n다음 예산 및 요구사항에 따라 보험을 제안해 주세요:\\n예산: $1000\\n요구사항: 자동차, 주택, 생명 보험\\n```\\n\\n이 프롬프트를 LLM에 실행하면 다음과 같은 응답이 나옵니다:\\n\\n```output\\n예산과 요구사항에 따라, ACME 보험의 다음 보험 패키지를 제안합니다:\\n- 자동차, 저렴, 500 USD\\n- 주택, 저렴, 600 USD\\n- 생명, 저렴, 100 USD\\n전체 비용: $1,200 USD\\n```\\n\\n보시다시피, 생명 보험도 제안되었습니다. 이는 의도한 바가 아니므로, 프롬프트를 더 명확하게 수정해야 한다는 것을 의미합니다. 몇 차례 _시도와 오류_ 후, 다음과 같은 프롬프트를 도출했습니다:\\n\\n```text\\n보험 회사: ACME 보험\\n보험 상품(월 비용):\\n- 유형: 자동차, 저렴, 비용: 500 USD\\n- 유형: 자동차, 고가, 비용: 1100 USD\\n- 유형: 주택, 저렴, 비용: 600 USD\\n- 유형: 주택, 고가, 비용: 1200 USD\\n- 유형: 생명, 저렴, 비용: 100 USD\\n\\n다음 예산 및 요구사항에 따라 보험을 제안해 주세요:\\n예산: $1000, 선택하려는 유형 제한: 자동차, 주택\\n```\\n\\n유형과 비용을 추가하고, _제한_ 이라는 키워드를 사용하여 LLM이 우리의 의도를 더 잘 이해하도록 만든 점을 주목하세요.\\n\\n이제 다음과 같은 응답이 나옵니다:\\n\\n```output\\n예산과 요구사항에 따라, 자동차 저렴 상품을 제안합니다. 비용은 월 500 USD입니다.\\n```\\n\\n이 예제의 요점은 _생성된 지식_ 과 같은 기본 기술을 사용하더라도, 대부분의 경우 원하는 결과를 얻기 위해 프롬프트를 최적화해야 한다는 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332931, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=713, prompt_tokens=633, total_tokens=1346, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUcQZeisKXjFOXiDmrTpbPKRz0u', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 가장 적은 것에서 가장 많은 것으로\\n\\n가장 적은 것에서 가장 많은 것으로 프롬프트를 사용하는 아이디어는 더 큰 문제를 하위 문제로 분해하는 것입니다. 이렇게 하면 더 큰 문제를 \"정복\"하는 방법을 LLM이 안내하는 데 도움이 됩니다. 좋은 예로는 데이터 사이언스에서 문제를 다음과 같이 나누도록 LLM에 요청하는 경우가 될 수 있습니다:\\n\\n> 프롬프트: 데이터 사이언스를 5단계로 수행하는 방법은 무엇인가요?\\n\\n당신의 AI 어시스턴트는 이렇게 대답할 수 있습니다:\\n\\n1. 데이터 수집\\n2. 데이터 정제\\n3. 데이터 분석\\n4. 데이터 시각화\\n5. 데이터 발표', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332938, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c047b7b4ec', usage=CompletionUsage(completion_tokens=159, prompt_tokens=140, total_tokens=299, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUep7xMB4R7xrURC1RAJkcuxhle', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 자기 검토, 결과 비판하기\\n\\n생성형 AI와 대규모 언어 모델(LLM)을 사용할 때, 출력 결과를 신뢰할 수 없습니다. 이를 검증해야 합니다. 결국, LLM은 단지 다음에 가장 그럴듯한 말을 제시할 뿐, 그것이 올바른지에 대한 보장은 없습니다. 따라서 LLM에게 스스로 비판을 요청하는 \\'자기 검토 (Self-refine)\\' 기술을 사용하는 것이 좋은 아이디어입니다.\\n\\n작동 방식은 다음과 같습니다:\\n\\n1. LLM이 문제를 해결하도록 요청하는 초기 프롬프트를 입력합니다.\\n2. LLM이 답변을 제공합니다.\\n3. 답변을 비판하고 AI에게 개선을 요청합니다.\\n4. LLM이 비판을 반영한 개선된 답변을 다시 제공합니다.\\n\\n이 과정을 원하는 만큼 반복할 수 있습니다.\\n\\n다음은 이 기술을 사용한 예입니다:\\n\\n> 프롬프트: \"products와 customers 라우트를 가진 파이썬 웹 API를 생성해주세요.\"\\n\\nAI 답변:\\n\\n```python\\nimport flask\\napp = Flask(__name__)\\n\\n@app.route(\\'/products\\')\\ndef products():\\n    return \\'Products\\'\\n\\n@app.route(\\'/customers\\')\\ndef customers():\\n    return \\'Customers\\'\\n```\\n\\n> 프롬프트: 위 코드의 개선 사항 3가지를 제안해주세요.\\n\\nAI 답변:\\n\\n```text\\n물론입니다. 다음은 코드 개선을 위한 세 가지 제안입니다:\\n\\n1. 올바른 모듈을 임포트하기: 첫 번째 줄에서 Flask 대신 flask를 임포트하고 있습니다. 올바른 임포트 문은 from flask import Flask이어야 합니다.\\n2. 메인 함수를 추가하기: 파일이 실행될 때 애플리케이션이 실행되도록 파일의 끝에 if __name__ == \\'__main__\\': 블록을 추가합니다.\\n3. f-문자열 사용하기: 라우트 함수의 반환문을 포맷하기 위해 f-문자열을 사용합니다. 예를 들어, return \\'Products\\'를 return f\\'This is the {request.path} page\\'로 변경할 수 있습니다.\\n```\\n\\n```python\\nfrom flask import Flask, request\\n\\napp = Flask(__name__)\\n\\n@app.route(\\'/products\\')\\ndef products():\\n    return f\\'This is the {request.path} page\\'\\n\\n@app.route(\\'/customers\\')\\ndef customers():\\n    return f\\'This is the {request.path} page\\'\\n\\nif __name__ == \\'__main__\\':\\n    app.run()\\n```\\n\\n보시다시피, 위 AI 응답은 첫 번째 답변을 비판한 후 개선된 코드를 제공합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332940, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=553, prompt_tokens=475, total_tokens=1028, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUlo6MjUtOMqhtJ7TffqUS3T2P9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 산파기법 프롬프트\\n\\n산파기법 프롬프트(maieutic prompting)는 스스로 수정하는 방식과 유사한 기법이지만, LLM에게 스스로를 설명하도록 요청하는 것에 더 중점을 둡니다. 이 기법의 목표는 LLM의 출력물에서 일관성을 줄여 올바른 답에 도달하는 것입니다. 다음과 같은 워크플로우를 따릅니다:\\n\\n1. LLM에게 질문에 답하도록 요청합니다.\\n2. 답변의 각 부분에 대해 LLM에게 더 깊이 설명하도록 요청합니다.\\n3. 불일치가 발생하면, 일관성이 없는 부분을 제거합니다.\\n\\n2번과 3번을 반복하여 모든 부분을 확인하고 답변에 만족할 때까지 진행합니다.\\n\\n다음은 예시 프롬프트입니다:\\n\\n> 프롬프트: 팬데믹을 완화하기 위한 위기 계획을 5단계로 만드는 방법은 무엇인가요?\\n> LLM의 답변:\\n\\n```text\\n1. 위험 식별\\n1. 이해 관계자 식별\\n1. 자원 식별\\n1. 행동 식별\\n1. 의사소통 채널 식별\\n```\\n\\nLLM이 5단계를 식별했지만, 이것이 올바른지 확인할 수 있을까요? 각 단계를 설명하도록 LLM에게 요청해 보겠습니다:\\n\\n> 프롬프트: 첫 번째 단계를 더 자세히 설명해 주세요. 팬데믹 상황의 구체적인 위험은 무엇인가요?\\n\\n```text\\n위험은 다음과 같습니다:\\n\\n- 생명 손실\\n- 사업 손실\\n- 평판 손실\\n- 고객 손실\\n- 직원 손실\\n```\\n\\n이 시점에서 LLM이 올바른지 확인하기 위해 첫 번째 위험을 더 자세히 설명하도록 요청하고, 이전 답변과 일치하는지 확인합니다:\\n\\n> 프롬프트: 팬데믹 상황에서 가장 큰 위험은 무엇이며, 그 이유는 무엇인가요?\\n\\n```text\\n가장 큰 위험은 생명 손실입니다. 이것이 보호해야 할 가장 중요한 것기 때문입니다.\\n```\\n\\n> 팬데믹에서 가장 큰 두 가지 위험은 무엇인가요?\\n\\n```text\\n가장 큰 두 가지 위험은 생명 손실과 사업 손실입니다.\\n```\\n\\n이 시점에서 LLM은 \"생명\"과 \"사업\"을 가장 큰 두 가지 위험으로 언급하며 일관성을 유지합니다. 이제 다음 단계로 넘어가서 꽤 만족스럽다고 할 수 있습니다. 그러나 LLM을 맹목적으로 신뢰하지 말고 항상 출력을 검증해야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332947, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=568, prompt_tokens=458, total_tokens=1026, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUqovi94QjfmaemsLRVrybnfR1R', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 출력 다양화\\n\\nLLM은 본질적으로 비결정론적이기 때문에 동일한 프롬프트를 실행할 때마다 다른 결과를 얻게 됩니다. 다음 프롬프트를 시도해보세요:\\n\\n> \"Python 웹 API 용 코드를 생성하시오\"\\n\\n```python\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332952, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=64, prompt_tokens=78, total_tokens=142, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUsgAxGtNBqMbMQCzfmt7C5B0u4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 필요한 모듈 불러오기\\nimport flask\\nfrom flask import request, jsonify\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332954, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=19, prompt_tokens=43, total_tokens=62, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUtk6zXTft0IGieUMrOy7oWcVfp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# Flask 앱 생성하기\\napp = flask.Flask(__name__)\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332955, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=14, prompt_tokens=42, total_tokens=56, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUtCaKlxN4NC1MyCuoDo96SANg4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"# API를 위한 경로 생성\\n@app.route('/api', methods=['GET'])\\ndef api():\\n    # 요청에서 데이터를 가져옴\\n    data = request.args\\n\\n    # 데이터를 처리함\\n    result = process_data(data)\\n\\n    # 결과를 JSON으로 반환\\n    return jsonify(result)\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332955, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=61, prompt_tokens=89, total_tokens=150, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUv7bVVZxs8dMw5smRWPcngXYWV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 데이터를 처리하는 함수\\ndef process_data(data):\\n    # 데이터로 무언가를 합니다\\n    result = data + 1\\n\\n    # 결과를 반환합니다\\n    return result', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332957, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=39, prompt_tokens=66, total_tokens=105, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcUwk6jQfATJqxGcGG2NnviDPSNk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 앱 실행\\nif __name__ == \\'__main__\\':\\n    app.run()\\n\\n```\\n\\n동일한 프롬프트를 다시 실행하면 약간 다른 응답이 생성됩니다:\\n\\n```python\\n# 필요한 패키지 가져오기\\nimport flask\\nfrom flask import request, jsonify\\n\\n# Flask 애플리케이션 생성\\napp = flask.Flask(__name__)\\napp.config[\"DEBUG\"] = True\\n\\n# 책 목록 생성\\nbooks = [\\n    {\\'id\\': 0,\\n     \\'title\\': \\'A Fire Upon the Deep\\',\\n     \\'author\\': \\'Vernor Vinge\\',\\n     \\'first_sentence\\': \\'The coldsleep itself was dreamless.\\',\\n     \\'year_published\\': \\'1992\\'},\\n    {\\'id\\': 1,\\n     \\'title\\': \\'The Ones Who Walk Away From Omelas\\',\\n     \\'author\\': \\'Ursula K. Le Guin\\',\\n     \\'first_sentence\\': \\'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.\\',\\n     \\'published\\': \\'1973\\'},\\n    {\\'id\\': 2,\\n     \\'title\\': \\'Dhalgren\\',\\n     \\'author\\': \\'Samuel R. Delany\\',\\n     \\'first_sentence\\': \\'to wound the autumnal city.\\',\\n     \\'published\\': \\'1975\\'}\\n]\\n\\n# API를 위한 엔드포인트 생성\\n@app.route(\\'/\\', methods=[\\'GET\\'])\\ndef home():\\n    return \\'\\'\\'<h1>Books API</h1>\\n<p>A prototype API for retrieving books.</p>\\'\\'\\'\\n\\n# 모든 책을 반환하는 엔드포인트 생성\\n@app.route(\\'/api/v1/resources/books/all\\', methods=[\\'GET\\'])\\ndef api_all():\\n    return jsonify(books)\\n\\n# 단일 책을 반환하는 엔드포인트 생성\\n@app.route(\\'/api/v1/resources/books\\', methods=[\\'GET\\'])\\ndef api_id():\\n    # URL의 일부로 ID가 제공되었는지 확인\\n    # ID가 제공되면 변수를 할당\\n    # ID가 제공되지 않으면 오류 메시지 표시\\n    if \\'id\\' in request.args:\\n        id = int(request.args[\\'id\\'])\\n    else:\\n        return \"Error: No id field provided. Please specify an id.\"\\n\\n    # 결과를 위한 빈 리스트 생성\\n    results = []\\n\\n    # 데이터를 순회하여 요청된 ID와 일치하는 결과 찾기\\n    # ID는 고유하지만 다른 필드는 여러 결과를 반환할 수 있음\\n    for book in books:\\n        if book[\\'id\\'] == id:\\n            results.append(book)\\n\\n    # Flask의 jsonify 함수를 사용하여\\n    # 파이썬 딕셔너리 리스트를 JSON 형식으로 변환\\n    return jsonify(results)\\n\\napp.run()\\n```\\n\\n> 출력이 다양해지는 것이 문제일까요?\\n\\n해당 상황에 따라 다릅니다. 특정한 응답을 원한다면 문제일 수 있습니다. 만약 \"지리학에 관한 아무 질문이나 세 가지 생성\"와 같은 다양한 출력을 원하는 경우에는 문제가 되지 않습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332958, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=629, prompt_tokens=608, total_tokens=1237, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcV1bkT5oLiEwp90GvVkHpPmBrLR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 출력을 다양하게 하기 위해 온도 사용\\n\\n좋아요, 출력을 더 예측 가능하게, 즉 더 결정적으로 만들고 싶습니다. 어떻게 하면 될까요?\\n\\n온도는 0과 1 사이의 값으로, 0은 가장 결정적이고 1은 가장 다양합니다. 기본 값은 0.7입니다. 온도를 0.1로 설정하고 동일한 프롬프트를 두 번 실행했을 때 어떤 일이 일어나는지 살펴보겠습니다:\\n\\n> \"Python Web API를 위한 코드를 생성하세요.\"\\n\\n```python\\n#필요한 라이브러리 가져오기\\nimport flask\\nfrom flask import request, jsonify\\n\\n#Flask 클래스의 인스턴스 생성\\napp = flask.Flask(__name__)\\n\\n#API를 위한 엔드포인트 생성\\n@app.route(\\'/api/v1/endpoint\\', methods=[\\'GET\\'])\\ndef api_endpoint():\\n    #요청 데이터 가져오기\\n    data = request.get_json()\\n\\n    #데이터 처리\\n    result = process_data(data)\\n\\n    #결과 반환\\n    return jsonify(result)\\n\\n#데이터를 처리하는 함수\\ndef process_data(data):\\n    #데이터 처리\\n    result = {\\'result\\': \\'success\\'}\\n\\n    #결과 반환\\n    return result\\n\\n#Flask 앱 실행\\nif __name__ == \\'__main__\\':\\n    app.run()\\n\\n```\\n\\n프롬프트를 다시 실행한 결과는 다음과 같습니다:\\n\\n```python\\n#필요한 라이브러리 가져오기\\nimport flask\\nfrom flask import request, jsonify\\n\\n#Flask 앱 생성\\napp = flask.Flask(__name__)\\n\\n#API를 위한 라우트 생성\\n@app.route(\\'/api\\', methods=[\\'GET\\'])\\ndef api_call():\\n    #요청에서 데이터 가져오기\\n    data = request.get_json()\\n\\n    #데이터 처리\\n    result = process_data(data)\\n\\n    #결과 반환\\n    return jsonify(result)\\n\\n#process_data 함수 정의\\ndef process_data(data):\\n    #데이터 처리\\n    result = data + 1\\n\\n    #결과 반환\\n    return result\\n\\n#앱 실행\\nif __name__ == \\'__main__\\':\\n    app.run()\\n\\n```\\n\\n이 두 출력 사이에는 거의 차이가 없습니다. 이번에는 반대로 온도를 0.9로 설정해보겠습니다:\\n\\n```python\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332963, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=482, prompt_tokens=465, total_tokens=947, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcV6GOAdkb6wvv3DdMQ7jJ7d88nb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 필수 라이브러리 임포트\\nimport flask\\nfrom flask import request, jsonify\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332968, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=21, prompt_tokens=43, total_tokens=64, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcV6zvflMe0SBNB4HNykdNopx6TU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# Flask 앱 생성\\napp = flask.Flask(__name__)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332968, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=13, prompt_tokens=42, total_tokens=55, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcV7LGQiEFyu8hU8oFoawJEYw6aa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"# API를 위한 라우트 생성\\n@app.route('/api', methods=['GET'])\\ndef api_call():\\n    # 요청으로부터 데이터를 가져옴\\n    data = request.args\\n\\n    # 데이터를 처리함\\n    result = process_data(data)\\n\\n    # 결과를 반환함\\n    return jsonify(result)\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332969, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=63, prompt_tokens=88, total_tokens=151, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcV9QcH7MBSUNtPvwB4XF2PYhzH4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 데이터를 처리하는 함수\\ndef process_data(data):\\n    # 데이터 처리 작업 수행\\n    result = data + 1\\n\\n    # 결과 반환\\n    return result\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332971, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=35, prompt_tokens=66, total_tokens=101, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVAOyjDPauQGewcM1IMGuY7jNeD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"```markdown\\n# 앱 실행\\nif __name__ == '__main__':\\n    app.run()\\n\\n```\\n\\n그리고 0.9의 온도 값으로 두 번째 시도:\\n\\n```python\\nimport flask\\nfrom flask import request, jsonify\\n```\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332972, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=50, prompt_tokens=73, total_tokens=123, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVCbqh10iB2N0hunWul3sTMbSNO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"# Flask 앱 생성\\napp = flask.Flask(__name__)\\napp.config['DEBUG'] = True\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332974, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=20, prompt_tokens=50, total_tokens=70, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVDEmAXf9cIS8896PksFQk2JeoB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"# 테스트 데이터 생성\\n\\n```python\\nbooks = [\\n    {'id': 0, 'title': 'A Fire Upon The Deep', 'author': 'Vernor Vinge', 'first_sentence': 'The coldsleep itself was dreamless.', 'year_published': '1992'},\\n    {'id': 1, 'title': 'The Ones Who Walk Away From Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.', 'published': '1973'},\\n    {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'to wound the autumnal city.', 'published': '1975'}\\n]\\n```\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332975, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=182, prompt_tokens=207, total_tokens=389, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVGrgyS2uU4RhmpNiG3CFlev6tW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"# 엔드포인트 생성하기\\n@app.route('/', methods=['GET'])\\ndef home():\\n    return '''<h1>우리의 책 API에 오신 것을 환영합니다!</h1>'''\\n\\n@app.route('/api/v1/resources/books\\n\\n```\\n\\n보시다시피, 결과는 매우 다양할 수 있습니다.\\n\\n> 참고로, 출력 결과를 다양하게 하기 위해 top-k, top-p, 반복 패널티, 길이 패널티 및 다양성 패널티와 같은 더 많은 매개변수를 변경할 수 있지만, 이들은 이 커리큘럼의 범위를 벗어납니다.\\n\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332978, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=129, prompt_tokens=124, total_tokens=253, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVJeVwVsQG2xqHmrBe2dfd5Tlp2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 좋은 관행\\n\\n원하는 결과를 얻기 위해 적용할 수 있는 많은 관행이 있습니다. 프롬프트를 점점 더 많이 사용하면서 자신만의 스타일을 찾을 수 있을 것입니다.\\n\\n우리가 다룬 기술들 외에도, LLM을 프롬프트할 때 고려해야 할 몇 가지 좋은 관행이 있습니다.\\n\\n다음은 고려할 만한 좋은 관행들입니다:\\n\\n- **맥락 지정**. 맥락은 중요합니다. 도메인, 주제 등 가능한 한 많이 지정할수록 좋습니다.\\n- 출력을 제한하세요. 특정 항목 수나 길이를 원할 경우 이를 명시하세요.\\n- **무엇과 어떻게를 명확히 하세요**. 여러분이 원하는 것과 그 방법을 모두 언급하는 것을 기억하세요. 예를 들어, \"제품 및 고객 경로와 함께 Python 웹 API를 생성하고, 그것을 3개의 파일로 나누세요\".\\n- **템플릿을 사용하세요**. 종종, 프롬프트에 회사의 데이터를 추가하고 싶을 때가 있을 것입니다. 이를 위해 템플릿을 사용하세요. 템플릿에는 실제 데이터로 대체할 변수들이 있을 수 있습니다.\\n- **맞춤법을 정확히 하세요**. LLM은 여러분에게 올바른 응답을 제공할 수 있지만, 맞춤법을 정확하게 쓰면 더 나은 응답을 얻을 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332981, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a2ff031fb5', usage=CompletionUsage(completion_tokens=303, prompt_tokens=245, total_tokens=548, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVNjaInS1gz7kAgZXxN3YWnqZzq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n다음은 Flask를 사용하여 간단한 API를 구축하는 방법을 보여주는 Python 코드입니다:\\n\\n```python\\nfrom flask import Flask, request\\n\\napp = Flask(__name__)\\n\\n@app.route(\\'/\\')\\ndef hello():\\n    name = request.args.get(\\'name\\', \\'World\\')\\n    return f\\'Hello, {name}!\\'\\n\\nif __name__ == \\'__main__\\':\\n    app.run()\\n```\\n\\nGitHub Copilot이나 ChatGPT와 같은 AI 도우미를 사용하여 \"자체 개선\" 기법을 적용하여 코드를 개선하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332985, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=115, prompt_tokens=129, total_tokens=244, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVOpDThcnhtfacZV9kMsFUO1AGR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 해결책\\n\\n과제 해결을 위해 코드에 적절한 프롬프트를 추가해 보세요.\\n\\n> [!TIP]\\n> 개선을 요청하는 프롬프트를 작성할 때, 몇 가지 개선 사항으로 제한하는 것이 좋습니다. 또한 아키텍처, 성능, 보안 등 특정 방식으로 개선하도록 요청할 수 있습니다.\\n\\n[해결책](./python/aoai-solution.py?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332986, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=102, prompt_tokens=116, total_tokens=218, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVPhhmlh2fDMujZn3WDF094mZVD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 점검\\n\\n왜 연쇄적 사고 유도를 사용할까요? 1개의 정답과 2개의 오답을 보여주세요.\\n\\n1. 문제를 해결하는 방법을 LLM에게 가르치기 위해.\\n1. B, 코드에서 오류를 찾는 방법을 LLM에게 가르치기 위해.\\n1. C, 다른 해결책을 생각해내는 방법을 LLM에게 지시하기 위해.\\n\\nA: 1, 연쇄적 사고 유도는 일련의 단계와 유사한 문제 및 그 문제들이 어떻게 해결되었는지를 제공하여 LLM이 문제를 해결하는 방법을 보여주는 것이기 때문입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332987, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=140, prompt_tokens=137, total_tokens=277, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVSGJ46KnKvi2opJcjmTu6DJ9gc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 🚀 도전\\n\\n방금 과제에서 자기 수정 기법을 사용했습니다. 당신이 작성한 프로그램 중 하나를 가져와서 적용하고자 하는 개선 사항을 고려해 보십시오. 이제 자기 수정 기법을 사용하여 제안된 변경 사항을 적용하십시오. 결과에 대해 어떻게 생각하십니까? 더 나아졌습니까, 아니면 더 나빠졌습니까?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332990, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=82, prompt_tokens=86, total_tokens=168, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVUVlevJqWX5kHtNMY64Omsyslz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 학습을 계속하세요\\n\\n이 수업을 마친 후, [생성 AI 학습 모음집](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성 AI 지식을 계속 업그레이드하세요!\\n\\n우리의 프롬프트 엔지니어링 지식을 적용할 [텍스트 생성 앱 구축](../06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst)에 대한 6과로 이동하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332992, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=118, prompt_tokens=126, total_tokens=244, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVWJhDwm5Lv8OrDX5bUln4Jm1x2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"# 검색 애플리케이션 구축\\n\\n[![생성적 인공지능 및 대형 언어 모델 입문](./images/08-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson8-gh?WT.mc_id=academic-105485-koreyst)\\n\\n> > _위 이미지를 클릭하면 이 강의의 영상을 볼 수 있습니다_\\n\\n대형 언어 모델(LLM)은 챗봇과 텍스트 생성 이상을 제공합니다. 임베딩을 사용하여 검색 애플리케이션을 구축하는 것도 가능합니다. 임베딩은 벡터라고도 알려진 데이터의 수치적 표현이며 데이터의 의미적 검색에 사용할 수 있습니다.\\n\\n이 강의에서는 우리의 교육 스타트업을 위한 검색 애플리케이션을 구축할 것입니다. 우리 스타트업은 개발도상국의 학생들에게 무료 교육을 제공하는 비영리 조직입니다. 우리 스타트업은 학생들이 AI에 대해 배울 수 있는 많은 유튜브 동영상을 소유하고 있습니다. 우리 스타트업은 학생들이 질문을 입력하여 유튜브 동영상을 검색할 수 있는 검색 애플리케이션을 구축하고자 합니다.\\n\\n예를 들어, 학생이 'Jupyter 노트북이란 무엇인가?' 또는 'Azure ML이란 무엇인가?'라는 질문을 입력하면 검색 애플리케이션은 해당 질문과 관련된 유튜브 동영상 목록을 반환하며, 더 나아가 질문에 대한 답변이 있는 영상의 위치 링크도 반환합니다.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332994, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=333, prompt_tokens=295, total_tokens=628, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVbsp9UZCv5gI5SEZxF0NkMLWj9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 수업에서는 다음을 다룹니다:\\n\\n- 의미 검색 vs 키워드 검색\\n- 텍스트 임베딩이란 무엇인가\\n- 텍스트 임베딩 인덱스 생성\\n- 텍스트 임베딩 인덱스 검색\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727332999, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=60, prompt_tokens=68, total_tokens=128, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVctPKAvJUy0pJRIR85usORVSlt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의를 완료한 후, 당신은 다음을 할 수 있습니다:\\n\\n- 시맨틱 검색과 키워드 검색의 차이를 설명할 수 있습니다.\\n- 텍스트 임베딩이 무엇인지 설명할 수 있습니다.\\n- 임베딩을 사용하여 데이터를 검색하는 애플리케이션을 만들 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333000, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=73, prompt_tokens=73, total_tokens=146, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVdye7U7OeVMlp2pQBPW9iTDGV4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 왜 검색 응용 프로그램을 구축해야 할까요?\\n\\n검색 응용 프로그램을 제작하면 임베딩(Embeddings)을 사용하여 데이터를 검색하는 방법을 이해할 수 있게 됩니다. 또한, 학생들이 정보를 빠르게 찾을 수 있는 검색 응용 프로그램을 만드는 방법을 배우게 됩니다.\\n\\n이 강의에는 Microsoft [AI 쇼](https://www.youtube.com/playlist?list=PLlrxD0HtieHi0mwteKBOfEeOYf0LJU4O1) YouTube 채널의 자막에 대한 임베딩 인덱스가 포함되어 있습니다. AI 쇼는 AI와 머신 러닝에 대해 가르치는 YouTube 채널입니다. 임베딩 인덱스는 2023년 10월까지의 YouTube 자막에 대한 임베딩을 포함하고 있습니다. 이 임베딩 인덱스를 사용하여 우리 스타트업의 검색 응용 프로그램을 구축할 것입니다. 이 검색 응용 프로그램은 질문에 대한 답이 위치한 비디오의 링크를 반환합니다. 이는 학생들이 필요한 정보를 빠르게 찾을 수 있는 훌륭한 방법입니다.\\n\\n다음은 \\'RStudio를 Azure ML과 함께 사용할 수 있나요?\\'라는 질문에 대한 의미론적 쿼리의 예입니다. YouTube URL을 확인해보시면, URL에 질문에 대한 답이 위치한 비디오의 타임스탬프가 포함된 것을 볼 수 있습니다.\\n\\n![\"RStudio를 Azure ML과 함께 사용할 수 있나요?\"라는 질문에 대한 의미론적 쿼리](./images/query-results.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333001, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=349, prompt_tokens=310, total_tokens=659, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVhia8iSxHnt2HsUDyr1eLjHo2c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"## 의미 검색이란 무엇인가?\\n\\n이제 여러분은 의미 검색이 무엇인지 궁금할 수도 있습니다. 의미 검색은 쿼리 내 단어들의 의미를 이용하여 관련 결과를 반환하는 검색 기법입니다.\\n\\n다음은 의미 검색의 예입니다. 차를 사고자 한다고 가정해봅시다. '내 꿈의 차'라고 검색할 때, 의미 검색은 당신이 실제로 꿈에서 본 차를 찾는 것이 아니라 당신이 '이상적인' 차를 찾고 있다는 것을 이해합니다. 의미 검색은 사용자의 의도를 이해하고 관련된 결과를 반환합니다. 반면에 '키워드 검색'은 문자 그대로 꿈과 관련된 차를 검색하며 자주 관련 없는 결과를 반환합니다.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333005, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=159, prompt_tokens=157, total_tokens=316, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVjCcRjcqdPamiLGnfjNbEqnWyu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 텍스트 임베딩이란?\\n\\n[텍스트 임베딩](https://en.wikipedia.org/wiki/Word_embedding?WT.mc_id=academic-105485-koreyst)은 [자연어 처리](https://en.wikipedia.org/wiki/Natural_language_processing?WT.mc_id=academic-105485-koreyst)에서 사용되는 텍스트 표현 기술입니다. 텍스트 임베딩은 텍스트를 의미적으로 숫자로 표현한 것입니다. 임베딩은 데이터를 기계가 이해하기 쉬운 방식으로 표현하기 위해 사용됩니다. 텍스트 임베딩을 생성하는 많은 모델들이 있으며, 이 강좌에서는 OpenAI 임베딩 모델을 사용하여 임베딩을 생성하는 것에 중점을 둘 것입니다.\\n\\n예를 들어, 다음 텍스트가 AI 쇼 유튜브 채널의 한 에피소드에서 가져온 대본이라고 상상해보십시오:\\n\\n```text\\n오늘 우리는 Azure 머신 러닝에 대해 배울 것입니다.\\n```\\n\\n이 텍스트를 OpenAI 임베딩 API에 전달하면, 1536개의 숫자, 즉 벡터로 구성된 임베딩을 반환하게 됩니다. 벡터의 각 숫자는 텍스트의 다른 측면을 나타냅니다. 간결함을 위해, 벡터의 첫 10개의 숫자는 다음과 같습니다:\\n\\n```python\\n[-0.006655829958617687, 0.0026128944009542465, 0.008792596869170666, -0.02446001023054123, -0.008540431968867779, 0.022071078419685364, -0.010703742504119873, 0.003311325330287218, -0.011632772162556648, -0.02187200076878071, ...]\\n```\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333007, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c047b7b4ec', usage=CompletionUsage(completion_tokens=391, prompt_tokens=357, total_tokens=748, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVo9S8m1C1vA9ADUsp4LjFECVxz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 임베딩 인덱스는 어떻게 생성되나요?\\n\\n이 레슨의 임베딩 인덱스는 일련의 파이썬 스크립트를 통해 생성되었습니다. 스크립트와 관련된 지침은 이 레슨의 `scripts` 폴더 내 [README](./scripts/README.md?WT.mc_id=academic-105485-koreyst)에서 찾을 수 있습니다. 임베딩 인덱스는 이미 제공되므로, 이 레슨을 완료하기 위해 스크립트를 실행할 필요는 없습니다.\\n\\n스크립트는 다음과 같은 작업을 수행합니다:\\n\\n1. [AI Show](https://www.youtube.com/playlist?list=PLlrxD0HtieHi0mwteKBOfEeOYf0LJU4O1) 재생 목록의 각 YouTube 비디오에 대한 트랜스크립트를 다운로드합니다.\\n2. [OpenAI Functions](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?WT.mc_id=academic-105485-koreyst)를 사용하여, YouTube 트랜스크립트의 첫 3분에서 화자 이름을 추출하려고 시도합니다. 각 비디오의 화자 이름은 `embedding_index_3m.json`이라는 임베딩 인덱스에 저장됩니다.\\n3. 트랜스크립트 텍스트는 **3분 텍스트 세그먼트**로 나뉘며, 각 세그먼트는 다음 세그먼트에서 약 20 단어가 중복되어 포함됩니다. 이는 세그먼트의 임베딩이 잘리지 않고 더 나은 검색 컨텍스트를 제공하기 위함입니다.\\n4. 각 텍스트 세그먼트는 OpenAI Chat API에 전달되어 텍스트를 60 단어로 요약합니다. 요약된 내용은 `embedding_index_3m.json` 임베딩 인덱스에 저장됩니다.\\n5. 마지막으로, 세그먼트 텍스트는 OpenAI 임베딩 API에 전달됩니다. 임베딩 API는 세그먼트의 의미적 의미를 나타내는 1536개의 숫자로 구성된 벡터를 반환합니다. 세그먼트와 OpenAI 임베딩 벡터는 `embedding_index_3m.json` 임베딩 인덱스에 저장됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333012, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=505, prompt_tokens=407, total_tokens=912, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcVvufp7yKbv6wGtdT2o4qsWevYD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 벡터 데이터베이스\\n\\n수업의 간편함을 위해, 임베딩 인덱스는 `embedding_index_3m.json`이라는 JSON 파일에 저장되고 Pandas DataFrame으로 로드됩니다. 하지만 실제 환경에서는, 임베딩 인덱스는 [Azure Cognitive Search](https://learn.microsoft.com/training/modules/improve-search-results-vector-search?WT.mc_id=academic-105485-koreyst), [Redis](https://cookbook.openai.com/examples/vector_databases/redis/readme?WT.mc_id=academic-105485-koreyst), [Pinecone](https://cookbook.openai.com/examples/vector_databases/pinecone/readme?WT.mc_id=academic-105485-koreyst), [Weaviate](https://cookbook.openai.com/examples/vector_databases/weaviate/readme?WT.mc_id=academic-105485-koreyst) 등과 같은 벡터 데이터베이스에 저장됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333019, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=205, prompt_tokens=220, total_tokens=425, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcW0DZAaee6ump0MaOStAzSq4fXX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 코사인 유사성 이해하기\\n\\n우리는 텍스트 임베딩에 대해 배웠습니다. 다음 단계는 텍스트 임베딩을 사용하여 데이터를 검색하고 특히 주어진 쿼리에 가장 유사한 임베딩을 찾는 방법을 배우는 것입니다. 이를 위해 코사인 유사성을 사용합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333024, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=73, prompt_tokens=70, total_tokens=143, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcW2JrxdpK3sqReTKSPjcECayfgQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 코사인 유사도란 무엇인가?\\n\\n코사인 유사도는 두 벡터 간의 유사도를 측정하는 방법이며, `가장 가까운 이웃 검색`이라고도 합니다. 코사인 유사도 검색을 수행하려면 OpenAI 임베딩 API를 사용하여 _쿼리_ 텍스트를 _벡터화_ 해야 합니다. 그런 다음 쿼리 벡터와 임베딩 인덱스의 각 벡터 간의 _코사인 유사도_ 를 계산합니다. 임베딩 인덱스에는 각 YouTube 자막 텍스트 세그먼트에 대한 벡터가 있음을 기억하세요. 마지막으로 코사인 유사도로 결과를 정렬하면 코사인 유사도가 가장 높은 텍스트 세그먼트가 쿼리와 가장 유사한 텍스트 세그먼트입니다.\\n\\n수학적인 관점에서 코사인 유사도는 다차원 공간에 투영된 두 벡터 사이의 각도의 코사인을 측정합니다. 이 측정 방법은 유클리드 거리로는 멀리 떨어져 있는 두 문서가 크기 때문에 각도는 작을 수 있으며 따라서 코사인 유사도는 높을 수 있기 때문에 유용합니다. 코사인 유사도 방정식에 대한 더 자세한 정보는 [코사인 유사도](https://en.wikipedia.org/wiki/Cosine_similarity?WT.mc_id=academic-105485-koreyst)를 참조하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333026, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=334, prompt_tokens=242, total_tokens=576, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcW6Q47clXFTRiIs2Qv64R0zw0SN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 첫 번째 검색 애플리케이션 구축\\n\\n다음으로, 임베딩을 사용하여 검색 애플리케이션을 구축하는 방법을 배울 것입니다. 이 검색 애플리케이션은 학생들이 질문을 입력하여 비디오를 검색할 수 있게 해줍니다. 검색 애플리케이션은 질문과 관련된 비디오 목록을 반환합니다. 검색 애플리케이션은 또한 질문에 대한 답이 위치한 비디오의 부분에 대한 링크를 반환합니다.\\n\\n이 솔루션은 Windows 11, macOS, 및 Ubuntu 22.04에서 Python 3.10 또는 그 이상의 버전을 사용하여 구축 및 테스트되었습니다. Python은 [python.org](https://www.python.org/downloads/?WT.mc_id=academic-105485-koreyst)에서 다운로드할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333030, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=174, prompt_tokens=164, total_tokens=338, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcW9PVrBRC2R2ujqlrpQP2Z8875n', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제 - 학생들을 위한 검색 애플리케이션 구축\\n\\n이 수업의 시작 부분에서 우리 스타트업을 소개했습니다. 이제 학생들이 그들의 평가를 위해 검색 애플리케이션을 구축할 수 있도록 해야 할 때입니다.\\n\\n이 과제에서 여러분은 검색 애플리케이션을 구축하는 데 사용될 Azure OpenAI 서비스를 만들 것입니다. 다음과 같은 Azure OpenAI 서비스를 만들게 됩니다. 이 과제를 완료하려면 Azure 구독이 필요합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333033, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=103, prompt_tokens=109, total_tokens=212, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWBzV5zqIGhAegIURRLgjmENQD0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Azure Cloud Shell 시작하기\\n\\n1. [Azure 포털](https://portal.azure.com/?WT.mc_id=academic-105485-koreyst)에 로그인합니다.\\n2. Azure 포털의 오른쪽 상단에 있는 Cloud Shell 아이콘을 선택합니다.\\n3. 환경 유형으로 **Bash**를 선택합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333035, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=68, prompt_tokens=92, total_tokens=160, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWDEK8j90VmSZVq85yNba5FxnlN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### 리소스 그룹 생성\\n\\n> 이 지침에서는 미국 동부 지역의 \"semantic-video-search\"라는 리소스 그룹을 사용합니다.\\n> 리소스 그룹의 이름을 변경할 수 있지만, 리소스의 위치를 변경할 때는 \\n> [모델 가용성 표](https://aka.ms/oai/models?WT.mc_id=academic-105485-koreyst)를 확인하세요.\\n\\n```shell\\naz group create --name semantic-video-search --location eastus\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333037, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=104, prompt_tokens=120, total_tokens=224, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWFylzWZP3GcP3cCPBdh5CLlKzl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### Azure OpenAI 서비스 리소스 생성\\n\\nAzure Cloud Shell에서 다음 명령어를 실행하여 Azure OpenAI 서비스 리소스를 생성합니다.\\n\\n```shell\\naz cognitiveservices account create --name semantic-video-openai --resource-group semantic-video-search \\\\\\n    --location eastus --kind OpenAI --sku s0\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333039, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=68, prompt_tokens=94, total_tokens=162, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWG8K0JfUuvXnlIPwUr3inPe5aj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### 이 애플리케이션에서 사용하기 위한 엔드포인트 및 키 가져오기\\n\\nAzure Cloud Shell에서 다음 명령어를 실행하여 Azure OpenAI 서비스 리소스에 대한 엔드포인트 및 키를 가져옵니다.\\n\\n```shell\\naz cognitiveservices account show --name semantic-video-openai \\\\\\n   --resource-group  semantic-video-search | jq -r .properties.endpoint\\naz cognitiveservices account keys list --name semantic-video-openai \\\\\\n   --resource-group semantic-video-search | jq -r .key1\\n```\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333040, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=114, prompt_tokens=127, total_tokens=241, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWHvJrxCaPRrqjZ9jxw8eGUd20A', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### OpenAI 임베딩 모델 배포\\n\\nAzure Cloud Shell에서 다음 명령어를 실행하여 OpenAI 임베딩 모델을 배포하십시오.\\n\\n```shell\\naz cognitiveservices account deployment create \\\\\\n    --name semantic-video-openai \\\\\\n    --resource-group semantic-video-search \\\\\\n    --deployment-name text-embedding-ada-002 \\\\\\n    --model-name text-embedding-ada-002 \\\\\\n    --model-version \"2\" \\\\\\n    --model-format OpenAI \\\\\\n    --sku-capacity 100 --sku-name \"Standard\"\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333041, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=112, prompt_tokens=139, total_tokens=251, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWJCaSIYJZIVG0uiaqUG79SCP5l', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 해결책\\n\\nGitHub Codespaces에서 [해결책 노트북](./python/aoai-solution.ipynb?WT.mc_id=academic-105485-koreyst)을 열고 Jupyter 노트북의 지침을 따르세요.\\n\\n노트북을 실행하면 쿼리를 입력하라는 메시지가 표시됩니다. 입력 상자는 다음과 같이 보일 것입니다:\\n\\n![사용자가 쿼리를 입력할 입력 상자](./images/notebook-search.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333043, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=115, prompt_tokens=127, total_tokens=242, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWL0kquxNxe9LMeKoGfpDOmVQeF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 학습을 계속하세요\\n\\n이 레슨을 완료한 후, [생성형 AI 학습 모음](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성형 AI 지식을 계속해서 발전시키세요!\\n\\n9번째 레슨으로 이동하여 [이미지 생성 애플리케이션 구축](../09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst)에 대해 알아보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333045, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=111, prompt_tokens=123, total_tokens=234, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWMf3FPSJw9ba2mrsOiXjjOvNZ2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 생성 AI의 책임감 있는 사용\\n\\n[![책임감 있는 생성 AI 사용](./images/03-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)\\n\\n> _위의 이미지를 클릭하여 이 강의의 동영상을 보세요_\\n\\nAI, 특히 생성 AI에 매료되기 쉽지만, 이를 책임감 있게 사용하는 방법을 고려해야 합니다. 출력이 공정하고 해롭지 않도록 보장하는 방법 등 여러 가지를 생각해야 합니다. 이 장은 앞서 언급한 맥락을 제공하고, 고려해야 할 사항과 AI 사용을 개선하기 위해 취할 수 있는 적극적인 단계에 대해 설명하는 것을 목표로 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333046, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=170, prompt_tokens=177, total_tokens=347, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWPbd9I7L0C87YLuKePc2WLDroE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 강의에서는 다음 내용을 다룹니다:\\n\\n- 생성적 AI 애플리케이션을 구축할 때 왜 책임 있는 AI를 우선시해야 하는지.\\n- 책임 있는 AI의 핵심 원칙과 이것이 생성적 AI와 어떻게 관련되는지.\\n- 전략과 도구를 통해 이러한 책임 있는 AI 원칙을 실천하는 방법.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333049, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=78, prompt_tokens=80, total_tokens=158, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWRN4A0FA0vjgHyQrtmA7ejuGEH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 수업을 완료한 후에, 다음을 알게 될 것입니다:\\n\\n- 생성형 AI 응용 프로그램을 구성할 때 Responsible AI(책임 있는 AI)의 중요성.\\n- 생성형 AI 응용 프로그램을 구축할 때 Responsible AI의 핵심 원칙을 생각하고 적용해야 하는 시기.\\n- Responsible AI 개념을 실천에 옮기기 위해 사용 가능한 도구와 전략들.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333051, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=92, prompt_tokens=91, total_tokens=183, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWSojMNp4yt5hRaz9F5PqRdLcwC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 책임 있는 AI 원칙\\n\\n생성형 AI에 대한 열기는 그 어느 때보다 높습니다. 이러한 열기는 많은 신규 개발자, 관심 및 자금을 이 분야로 가져왔습니다. 이는 생성형 AI를 사용하여 제품과 회사를 구축하려는 사람들에게 매우 긍정적입니다. 그러나 우리는 책임 있게 진행하는 것이 중요합니다.\\n\\n이 과정 전반에 걸쳐 우리는 스타트업과 AI 교육 제품을 구축하는 데 중점을 둘 것입니다. 우리는 책임 있는 AI 원칙: 공정성, 포용성, 신뢰성/안전성, 보안 및 프라이버시, 투명성 및 책임성을 사용할 것입니다. 이러한 원칙을 통해 생성형 AI가 우리의 제품에 어떻게 관련되는지 탐구할 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333052, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=159, prompt_tokens=153, total_tokens=312, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWVWdpzjnNY802Tr0meNuF128vy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 책임 있는 AI를 우선시해야 하는 이유\\n\\n제품을 개발할 때 사용자 중심 접근 방식을 취하여 사용자의 최선의 이익을 염두에 두는 것이 최상의 결과를 이끌어냅니다.\\n\\n생성형 AI의 고유한 점은 사용자에게 유용한 답변, 정보, 지침 및 콘텐츠를 생성해낼 수 있는 강력한 능력입니다. 이는 많은 수작업 없이도 매우 인상적인 결과를 만들어낼 수 있습니다. 그러나 적절한 계획과 전략이 없다면, 사용자는 물론 제품과 사회 전체에 해를 끼치는 결과를 초래할 수도 있습니다.\\n\\n다음은 이러한 잠재적으로 해로운 결과 중 일부입니다(전부는 아닙니다):\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333055, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=157, prompt_tokens=143, total_tokens=300, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWXGH4wfbXWBJH3Rk6ViB8lAQNQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 환각\\n\\n환각(Hallucinations)은 LLM(Large Language Model)이 완전히 무의미한 내용이나 다른 정보 소스에 근거하여 사실적으로 잘못된 내용을 생성할 때 사용하는 용어입니다.\\n\\n예를 들어, 우리가 학생들이 모델에게 역사적 질문을 할 수 있는 기능을 우리 신생 기업에서 개발한다고 가정해봅시다. 한 학생이 `타이타닉의 유일한 생존자는 누구였나요?`라는 질문을 합니다.\\n\\n모델이 아래와 같은 응답을 생성합니다:\\n\\n![타이타닉의 유일한 생존자는 누구였나요?라는 질문이 적힌 프롬프트](../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp?WT.mc_id=academic-105485-koreyst)\\n\\n> _(출처: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_\\n\\n이것은 매우 확신에 차고 철저한 대답처럼 보입니다. 불행히도, 이것은 잘못된 정보입니다. 최소한의 연구만으로도 타이타닉 재난의 생존자가 한 명 이상 있다는 사실을 발견할 수 있습니다. 이 주제에 대한 연구를 이제 막 시작하는 학생에게는 이 대답이 충분히 설득력 있어서 의심 없이 사실로 받아들일 수 있습니다. 이로 인해 AI 시스템이 신뢰할 수 없게 되고, 우리의 신생 기업의 평판에도 부정적인 영향을 미칠 수 있습니다.\\n\\n주어진 LLM의 각 반복(iteration)과 함께 환각을 최소화하는 성능 향상을 보아왔습니다. 이러한 향상에도 불구하고, 애플리케이션 빌더와 사용자로서 이러한 제한점을 인지하고 있어야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333057, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=393, prompt_tokens=321, total_tokens=714, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWcjAO92XrGO00RSo7F8bXVtJyV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 유해한 콘텐츠\\n\\n이전 섹션에서 LLM이 부정확하거나 무의미한 응답을 생성하는 경우에 대해 다루었습니다. 우리가 인지해야 할 또 다른 위험은 모델이 유해한 콘텐츠로 응답하는 경우입니다.\\n\\n유해한 콘텐츠는 다음과 같이 정의될 수 있습니다:\\n\\n- 자해나 특정 그룹에 대한 해를 입히는 행동을 지시하거나 권장하는 내용.\\n- 혐오적이거나 비하하는 내용.\\n- 어떠한 종류의 공격이나 폭력 행위를 계획하도록 유도하는 내용.\\n- 불법 콘텐츠를 찾아내는 방법이나 불법 행위의 방법을 제공하는 내용.\\n- 성적으로 노골적인 내용을 표시하는 경우.\\n\\n우리 스타트업의 경우, 학생들이 이러한 유형의 콘텐츠를 보지 못하도록 적절한 도구와 전략을 마련하는 것이 중요합니다.\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333062, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=188, prompt_tokens=162, total_tokens=350, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWfH1bhzRImECo2fdsUlIQDK9YH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 공정성의 결여\\n\\n공정성은 \"AI 시스템이 편향과 차별에서 자유로우며, 모든 사람을 공정하고 평등하게 대하는 것\"으로 정의됩니다. 생성적 AI의 세계에서는 소외된 그룹의 배제적 세계관이 모델의 출력물에 의해 강화되지 않도록 해야 합니다.\\n\\n이러한 출력물은 사용자에게 긍정적인 제품 경험을 제공하는 데 파괴적일 뿐만 아니라 사회적 손해를 초래합니다. 애플리케이션 개발자로서, 생성적 AI를 사용하여 솔루션을 구축할 때 항상 넓고 다양한 사용자 기반을 염두에 두어야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333065, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=146, prompt_tokens=139, total_tokens=285, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWibrFVeiARCy3RFzmmN2QF6nP4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 책임감 있는 생성형 AI 사용 방법\\n\\n책임감 있는 생성형 AI의 중요성을 확인한 지금, AI 솔루션을 책임감 있게 구축하기 위해 취할 수 있는 4단계에 대해 알아봅시다:\\n\\n![완화 사이클](./images/mitigate-cycle.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333068, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=77, prompt_tokens=92, total_tokens=169, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWl2oZtghvvj60jJNpMnR5e977U', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 잠재적 피해 측정\\n\\n소프트웨어 테스트에서는 사용자가 애플리케이션에서 기대할 만한 행동을 테스트합니다. 마찬가지로, 사용자가 가장 많이 사용할 가능성이 높은 다양한 프롬프트를 테스트하는 것은 잠재적 피해를 측정하는 좋은 방법입니다.\\n\\n우리 스타트업이 교육 제품을 개발하고 있기 때문에, 교육과 관련된 프롬프트 목록을 준비하는 것이 좋습니다. 이 목록은 특정 주제, 역사적 사실 및 학생 생활에 대한 프롬프트를 포함할 수 있습니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333071, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=118, prompt_tokens=114, total_tokens=232, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcWnamGkwA6NTqIcAK9e27YO2gHA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 잠재적 해악 완화\\n\\n이제 모델 및 그 응답에 의해 발생할 수 있는 잠재적 해악을 방지하거나 제한할 수 있는 방법을 찾아야 할 때입니다. 우리는 이를 4가지 다른 계층으로 나누어 살펴볼 수 있습니다.\\n\\n![완화 계층](./images/mitigation-layers.png?WT.mc_id=academic-105485-koreyst)\\n\\n- **모델**. 적절한 사용 사례에 맞는 모델을 선택해야 합니다. GPT-4와 같은 크고 복잡한 모델은 더 작고 구체적인 사용 사례에 적용할 때 유해한 콘텐츠의 위험을 증가시킬 수 있습니다. 교육 데이터를 사용하여 미세 조정하면 유해한 콘텐츠의 위험을 줄일 수 있습니다.\\n\\n- **안전 시스템**. 안전 시스템은 모델을 제공하는 플랫폼에서 해악을 완화하는 데 도움이 되는 도구 및 구성 집합입니다. Azure OpenAI 서비스의 콘텐츠 필터링 시스템이 그 예입니다. 시스템은 또한 탈옥 공격 및 봇의 요청과 같은 원치 않는 활동을 감지해야 합니다.\\n\\n- **메타프롬프트**. 메타프롬프트와 그라운딩은 특정 행동 및 정보에 따라 모델을 지시하거나 제한하는 방법입니다. 이를 위해 시스템 입력을 사용하여 모델의 특정 한계를 정의할 수 있습니다. 또한 시스템의 범위나 도메인에 더 적합한 출력을 제공하는 것도 포함됩니다.\\n\\n또한 신뢰할 수 있는 소스에서만 정보를 가져오도록 모델을 설정하는 Retrieval Augmented Generation (RAG)과 같은 기술을 사용할 수 있습니다. [검색 애플리케이션 구축](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)에 대한 강의가 이 과정에서 후반에 있습니다.\\n\\n- **사용자 경험**. 마지막 계층은 사용자가 애플리케이션의 인터페이스를 통해 모델과 직접 상호작용하는 부분입니다. UI/UX를 설계하여 사용자가 모델에 보낼 수 있는 입력 유형과 사용자에게 표시되는 텍스트나 이미지를 제한할 수 있습니다. AI 애플리케이션을 배포할 때에는 우리의 생성형 AI 애플리케이션이 할 수 있는 것과 할 수 없는 것에 대해 투명하게 공개해야 합니다.\\n\\n[AI 애플리케이션을 위한 UX 설계](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)에 전념하는 전체 강의가 있습니다.\\n\\n- **모델 평가**. LLMs와 함께 작업하는 것은 모델이 학습한 데이터에 대해 항상 통제할 수 없기 때문에 어려울 수 있습니다. 그럼에도 불구하고 모델의 성능과 출력을 항상 평가해야 합니다. 모델의 정확성, 유사성, 기반성, 출력의 관련성을 측정하는 것은 여전히 중요합니다. 이는 이해 관계자와 사용자에게 투명성과 신뢰를 제공하는 데 도움이 됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333073, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=646, prompt_tokens=542, total_tokens=1188, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcX0sP1vQZrxB6jjNYNWx8fp4jLA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 책임 있는 생성형 AI 솔루션 운영\\n\\nAI 애플리케이션에 대한 운영 관행을 구축하는 것은 마지막 단계입니다. 여기에는 모든 규제 정책을 준수하기 위해 법무 및 보안과 같은 다른 부서와 협력하는 것이 포함됩니다. 출시 전에, 우리는 배송 계획, 사고 처리 및 롤백 계획을 수립하여 사용자가 성장하면서 발생할 수 있는 피해를 방지하고자 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333086, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=93, prompt_tokens=101, total_tokens=194, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcX2ABntb26zjTRGkSDZVjRLiwuv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 도구\\n\\n책임 있는 AI 솔루션을 개발하는 작업은 많아 보일 수 있지만, 그 노력은 충분히 가치가 있습니다. 생성 AI 분야가 성장함에 따라 개발자들이 워크플로우에 책임을 효율적으로 통합할 수 있도록 돕는 도구도 성숙해질 것입니다. 예를 들어, [Azure AI 콘텐츠 안전](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst)은 API 요청을 통해 유해한 콘텐츠와 이미지를 감지할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333088, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=126, prompt_tokens=126, total_tokens=252, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcX4CyQL8W0FGe2greyllB1PA7af', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 점검\\n\\n책임 있는 AI 사용을 보장하기 위해 신경 써야 할 몇 가지 사항은 무엇입니까?\\n\\n1. 답변이 올바른지 확인.\\n1. 유해한 사용, AI가 범죄 목적으로 사용되지 않도록 하는 것.\\n1. AI가 편향과 차별에서 자유롭게 하는 것.\\n\\nA: 2번과 3번이 맞습니다. 책임 있는 AI는 유해한 영향과 편향을 완화하는 방법을 고려하는 데 도움이 됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333090, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=112, prompt_tokens=107, total_tokens=219, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcX5UuattIz4w3MpuKzbPEgB4utl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 🚀 도전 과제\\n\\n[Azure AI 콘텐츠 안전성](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst)에 대해 읽어보고 사용할 수 있는 내용을 찾아보세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333091, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=55, prompt_tokens=82, total_tokens=137, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcX6tmF28jHxfFONgfpgRlDqMzwn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업, 학습을 계속하세요\\n\\n이 강의를 마치면 [생성형 AI 학습 모음집](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성형 AI 지식을 계속 쌓아보세요!\\n\\n[프롬프트 엔지니어링 기본 사항](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)을 다루는 4강으로 이동하세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333092, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=115, prompt_tokens=124, total_tokens=239, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcX7XDQNZOQ8QQjFTbzUf8V0bf4H', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# AI 애플리케이션을 위한 UX 설계\\n\\n[![AI 애플리케이션을 위한 UX 설계](./images/12-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst)\\n\\n> _(이 수업의 비디오를 보려면 위의 이미지를 클릭하세요)_\\n\\n사용자 경험은 앱을 구축할 때 매우 중요한 측면입니다. 사용자는 작업을 수행하기 위해 효율적으로 앱을 사용할 수 있어야 합니다. 효율적인 것만으로는 충분하지 않으며, 모든 사람이 사용할 수 있도록 _접근성_ 을 고려하여 앱을 설계해야 합니다. 이 장에서는 이 영역에 중점을 두어 사람들이 사용할 수 있고 사용하고 싶은 앱을 설계할 수 있도록 도와줄 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333093, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=186, prompt_tokens=181, total_tokens=367, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXAKIMR7HW2YjBKSJIh0V5vmatq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n사용자 경험은 사용자가 특정 제품 또는 서비스, 즉 시스템, 도구 또는 디자인을 어떻게 상호작용하고 사용하는지를 말합니다. AI 응용 프로그램을 개발할 때, 개발자들은 사용자 경험이 효과적일 뿐만 아니라 윤리적임을 보장하는 데 중점을 둡니다. 이 수업에서는 사용자 요구를 충족하는 인공지능(AI) 응용 프로그램을 구축하는 방법을 다룹니다.\\n\\n이 수업은 다음 영역을 포함합니다:\\n\\n- 사용자 경험 소개 및 사용자 요구 이해\\n- 신뢰와 투명성을 위한 AI 응용 프로그램 디자인\\n- 협업과 피드백을 위한 AI 응용 프로그램 디자인\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333096, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=145, prompt_tokens=132, total_tokens=277, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXDKy3Slxg1IaXR2qAOzWtnxuot', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 수업을 마친 후, 다음을 할 수 있습니다:\\n\\n- 사용자 요구를 충족하는 AI 애플리케이션을 구축하는 방법을 이해합니다.\\n- 신뢰와 협력을 증진하는 AI 애플리케이션을 설계합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333099, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=60, prompt_tokens=65, total_tokens=125, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXE4DcePWTIK9JIgUaGWIJh7p2R', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 전제 조건\\n\\n시간을 내어 [사용자 경험 및 디자인 사고](https://learn.microsoft.com/training/modules/ux-design?WT.mc_id=academic-105485-koreyst)에 대해 더 읽어보세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333100, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=48, prompt_tokens=72, total_tokens=120, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXFukp3d2124W5iWfPFabvOtDIq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 사용자 경험 소개 및 사용자 요구 이해하기\\n\\n우리의 가상 교육 스타트업에는 두 명의 주요 사용자가 있습니다. 바로 교사와 학생입니다. 이 두 사용자는 각각 고유한 필요를 가지고 있습니다. 사용자 중심 디자인은 사용자를 우선시하여 제품이 의도된 사용자에게 유용하고 유익하도록 합니다.\\n\\n애플리케이션은 **유용하고, 신뢰할 수 있으며, 접근 가능하고 즐거운** 사용자 경험을 제공해야 합니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333101, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=103, prompt_tokens=107, total_tokens=210, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXHmVRXU7EJftH25PraehBEIhGa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 사용성\\n\\n유용하다는 것은 응용 프로그램이 의도된 목적에 맞는 기능을 가지고 있다는 것을 의미합니다. 예를 들어, 채점 프로세스를 자동화하거나 복습용 플래시 카드를 생성하는 것입니다. 채점 프로세스를 자동화하는 응용 프로그램은 사전 정의된 기준에 따라 학생들의 작업에 점수를 정확하고 효율적으로 할당할 수 있어야 합니다. 마찬가지로, 복습용 플래시 카드를 생성하는 응용 프로그램은 그 데이터에 기반하여 관련 있고 다양한 질문을 만들어낼 수 있어야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333103, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=126, prompt_tokens=109, total_tokens=235, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXNgEt7scquC4JGlfYFKQSlvXTM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 신뢰성\\n\\n신뢰성이 있다는 것은 애플리케이션이 일관되고 오류 없이 작업을 수행할 수 있음을 의미합니다. 그러나 인간과 마찬가지로 AI도 완벽하지 않으며 오류가 발생할 수 있습니다. 애플리케이션은 때때로 오류나 예기치 않은 상황에 직면하여 인간의 개입이나 수정을 필요로 할 수 있습니다. 오류를 어떻게 처리합니까? 이 강의의 마지막 부분에서는 AI 시스템과 애플리케이션이 어떻게 협업과 피드백을 위해 설계되는지 다룰 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333109, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=126, prompt_tokens=106, total_tokens=232, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXOfEPopIUWFkNoaQAGL0YxaK5u', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 접근성\\n\\n접근성이 있다는 것은 다양한 능력을 가진 사용자, 장애가 있는 사용자를 포함하여, 모든 사용자가 배제되지 않고 사용자 경험을 누릴 수 있도록 하는 것을 의미합니다. 접근성 지침과 원칙을 준수함으로써 AI 솔루션은 더 포괄적이고, 사용 가능하며, 모든 사용자에게 도움이 될 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333110, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=79, prompt_tokens=77, total_tokens=156, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXQEipqIX0CBJZrloQAtTLpdF0E', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 유쾌함\\n\\n유쾌하다는 것은 애플리케이션을 사용하는 것이 즐겁다는 것을 의미합니다. 매력적인 사용자 경험은 사용자가 애플리케이션에 다시 방문하도록 격려하고 비즈니스 수익을 증가시키는 긍정적인 영향을 미칠 수 있습니다.\\n\\n![AI에서 UX 고려 사항을 설명하는 이미지](./images/uxinai.png?WT.mc_id=academic-105485-koreyst)\\n\\n모든 문제를 AI로 해결할 수 있는 것은 아닙니다. AI는 수작업을 자동화하거나 사용자 경험을 개인화하는 등의 방식으로 사용자 경험을 보완하기 위해 도입됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333112, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=144, prompt_tokens=125, total_tokens=269, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXSSZ1vUZpPGNmy2nA8E8pszblB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 신뢰와 투명성을 위한 인공지능 애플리케이션 설계\\n\\n인공지능 애플리케이션을 설계할 때 신뢰를 구축하는 것은 매우 중요합니다. 신뢰는 사용자가 애플리케이션이 작업을 완료하고 일관되게 결과를 제공하며 사용자에게 필요한 결과를 제공할 것이라는 확신을 갖도록 합니다. 이 분야에서의 위험 요소는 불신과 과신입니다. 불신은 사용자가 인공지능 시스템에 거의 또는 전혀 신뢰를 가지지 않을 때 발생하며, 이는 사용자가 애플리케이션을 거부하게 만듭니다. 과신은 사용자가 인공지능 시스템의 능력을 과대평가할 때 발생하며, 사용자가 인공지능 시스템을 너무 과신하게 만듭니다. 예를 들어, 자동 채점 시스템의 경우 과신이 발생하면 교사가 채점 시스템이 제대로 작동하는지 확인하기 위해 일부 시험지를 검토하지 않을 수 있습니다. 이는 학생들에게 불공정하거나 부정확한 점수 또는 피드백 및 개선 기회의 놓침을 초래할 수 있습니다.\\n\\n신뢰를 설계의 중심에 두는 두 가지 방법은 설명 가능성과 통제입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333114, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_057232b607', usage=CompletionUsage(completion_tokens=263, prompt_tokens=210, total_tokens=473, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXWg5mDhwgTYXvFojekHi5mGyn9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 설명 가능성\\n\\nAI가 향후 세대에 지식을 전달하는 등 결정을 내리는 데 도움을 줄 때, 교사와 부모가 AI 결정이 어떻게 이루어지는지 이해하는 것이 중요합니다. 이것이 바로 설명 가능성입니다 - AI 응용 프로그램이 어떻게 결정을 내리는지 이해하는 것입니다. 설명 가능성을 설계하는 것은 AI 응용 프로그램이 할 수 있는 일의 예시를 추가하는 것을 포함합니다. 예를 들어, \"AI 교사와 함께 시작하기\" 대신에, 시스템은 \"노트를 요약하여 더 쉽게 복습할 수 있도록 AI를 활용하세요.\" 라고 사용할 수 있습니다.\\n\\n![AI 응용 프로그램에서 설명 가능성을 명확하게 보여주는 앱 랜딩 페이지](./images/explanability-in-ai.png?WT.mc_id=academic-105485-koreyst)\\n\\n또 다른 예시는 AI가 사용자 및 개인 데이터를 어떻게 사용하는지입니다. 예를 들어, 학생이라는 페르소나를 가진 사용자는 그 페르소나에 따라 제한이 있을 수 있습니다. AI는 질문에 대한 정답을 공개할 수는 없지만, 사용자가 문제를 해결하는 방법을 생각하도록 도울 수 있습니다.\\n\\n![페르소나 기반으로 질문에 답변하는 AI](./images/solving-questions.png?WT.mc_id=academic-105485-koreyst)\\n\\n설명 가능성의 또 다른 중요한 부분은 설명의 단순화입니다. 학생들과 교사들은 AI 전문가가 아닐 수 있으므로, 응용 프로그램이 무엇을 할 수 있고 할 수 없는지를 설명하는 것은 단순하고 이해하기 쉬워야 합니다.\\n\\n![AI 기능에 대한 단순화된 설명](./images/simplified-explanations.png?WT.mc_id=academic-105485-koreyst)\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333118, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=374, prompt_tokens=311, total_tokens=685, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXbH1WeRkPik5iYIqoWh0NKHATh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 제어\\n\\n생성적 AI는 AI와 사용자 간의 협업을 창출합니다. 예를 들어 사용자가 다양한 결과를 위해 프롬프트를 수정할 수 있습니다. 또한, 출력이 생성된 후 사용자가 결과를 수정할 수 있어 제어감을 제공합니다. 예를 들어 Bing을 사용할 때, 서식, 톤 및 길이에 따라 프롬프트를 조정할 수 있습니다. 또한, 출력에 변경 사항을 추가하고 다음과 같이 출력을 수정할 수 있습니다:\\n\\n![프롬프트 및 출력 수정 옵션이 있는 Bing 검색 결과](./images/bing1.png?WT.mc_id=academic-105485-koreyst \"프롬프트 및 출력 수정 옵션이 있는 Bing 검색 결과\")\\n\\nBing에서 사용자가 애플리케이션에 대한 제어 권한을 가질 수 있는 또 다른 기능은 AI가 사용하는 데이터에 대한 옵트인 및 옵트아웃 기능입니다. 예를 들어, 학생이 학교 애플리케이션을 사용할 때, 자신의 노트와 교사의 자료를 복습 자료로 사용할 수 있습니다.\\n\\n![프롬프트 및 출력 수정 옵션이 있는 Bing 검색 결과](./images/bing2.png?WT.mc_id=academic-105485-koreyst \"프롬프트 및 출력 수정 옵션이 있는 Bing 검색 결과\")\\n\\n> AI 애플리케이션을 설계할 때, 사용자가 AI의 능력에 대해 비현실적인 기대를 갖지 않도록 하는 것이 중요합니다. 이를 위한 한 가지 방법은 프롬프트와 결과 사이에 마찰을 만드는 것입니다. 사용자에게 이것이 AI이며 인간이 아니라는 것을 상기시키는 것이 중요합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333123, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=352, prompt_tokens=316, total_tokens=668, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXikp6dYXz8Utv4vnXAcivtkjGp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 협업 및 피드백을 위한 AI 애플리케이션 설계\\n\\n앞서 언급한 바와 같이 생성 AI는 사용자와 AI 간의 협업을 만듭니다. 대부분의 상호작용은 사용자가 프롬프트를 입력하고 AI가 출력을 생성하는 방식으로 이루어집니다. 그렇다면 출력이 잘못되었을 경우 어떻게 될까요? 애플리케이션은 오류가 발생할 경우 어떻게 처리합니까? AI가 사용자에게 책임을 돌리거나 오류를 설명하는 데 시간을 할애합니까?\\n\\nAI 애플리케이션은 피드백을 주고받을 수 있도록 설계되어야 합니다. 이는 AI 시스템의 개선에 도움을 줄 뿐만 아니라 사용자와의 신뢰를 구축하는 데도 도움이 됩니다. 디자인 시 피드백 루프를 포함해야 하며, 예를 들면 출력에 대한 간단한 엄지손가락 위아래 평가가 될 수 있습니다.\\n\\n다른 방법으로는 시스템의 기능과 한계를 명확하게 전달하는 것입니다. 사용자가 AI의 능력을 벗어난 요청을 할 경우, 이를 처리하는 방법도 마련되어 있어야 합니다. 아래와 같은 방식으로 처리할 수 있습니다.\\n\\n![피드백 제공 및 오류 처리](./images/feedback-loops.png?WT.mc_id=academic-105485-koreyst)\\n\\n애플리케이션에서 시스템 오류는 일반적입니다. 사용자가 AI의 범위를 벗어난 정보에 대한 지원이 필요할 때나 애플리케이션에 사용자가 생성할 수 있는 질문/주제의 수에 한계가 있을 때 발생할 수 있습니다. 예를 들어, 역사와 수학에 대한 데이터로 학습된 AI 애플리케이션은 지리 관련 질문을 처리할 수 없을 수 있습니다. 이를 완화하기 위해 AI 시스템은 다음과 같은 응답을 제공할 수 있습니다: \"죄송합니다. 당사의 제품은 다음과 같은 주제에 대한 데이터로 학습되었습니다....., 요청하신 질문에 응답할 수 없습니다.\"\\n\\nAI 애플리케이션은 완벽하지 않으므로 실수를 저지르기 마련입니다. 애플리케이션을 설계할 때는 사용자의 피드백과 오류 처리를 위한 공간을 만들고 이를 간단하고 쉽게 설명할 수 있도록 해야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333130, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=495, prompt_tokens=375, total_tokens=870, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXoz5W3SGKQYxM1F20NYiJWRTCI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n지금까지 만들어온 AI 앱을 활용하여 아래의 단계를 앱에 구현해 보세요:\\n\\n- **유쾌함:** 어떻게 앱을 더 즐겁게 만들 수 있을지 고려해보세요. 설명을 추가하는지, 사용자가 탐색하도록 독려하는지 확인해보세요. 오류 메시지를 어떻게 전달하고 있나요?\\n\\n- **사용 편의성:** 웹 애플리케이션을 구축하세요. 마우스와 키보드 모두로 앱을 탐색할 수 있는지 확인하세요.\\n\\n- **신뢰성과 투명성:** AI와 그 결과를 완전히 신뢰하지 마세요. 결과를 검증하기 위해 인간을 프로세스에 추가하는 방법을 고려해보세요. 신뢰성과 투명성을 달성하기 위한 다른 방법도 고려하고 구현해보세요.\\n\\n- **통제:** 사용자가 애플리케이션에 제공하는 데이터를 제어할 수 있도록 하세요. 사용자가 데이터 수집에 옵트인하고 옵트아웃할 수 있는 방법을 구현하세요.\\n\\n<!-- ## [강의 후 퀴즈](quiz-url) -->', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333136, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=239, prompt_tokens=200, total_tokens=439, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXrxShhikZMcYsUMJAxeEPzHvHq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습을 계속하세요!\\n\\n이 강의를 마친 후 [생성형 AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성형 AI 지식을 계속 향상시키세요!\\n\\nAI 애플리케이션을 [보안하는 방법](../13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)을 살펴볼 13강으로 이동하세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333139, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=105, prompt_tokens=123, total_tokens=228, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXtsj8g7nZICqDQK00gK3JW3H1W', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 이미지 생성 애플리케이션 구축\\n\\n[![이미지 생성 애플리케이션 구축](./images/09-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst)\\n\\nLLM은 텍스트 생성 이상으로 더욱 다양합니다. 텍스트 설명으로부터 이미지를 생성하는 것도 가능합니다. 이미지를 하나의 형식으로 사용하는 것은 MedTech, 건축, 관광, 게임 개발 등 다양한 분야에서 매우 유용할 수 있습니다. 이 장에서는 가장 인기 있는 이미지 생성 모델인 DALL-E와 Midjourney에 대해 알아보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333141, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=146, prompt_tokens=157, total_tokens=303, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXx3Li8lBkFl1wnhc0Xk4PAqBRa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이번 강의에서는 다음 내용을 다룰 것입니다:\\n\\n- 이미지 생성과 그것이 왜 유용한지.\\n- DALL-E와 Midjourney, 이들이 무엇이고 어떻게 작동하는지.\\n- 이미지 생성 앱을 어떻게 구축하는지.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333145, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=55, prompt_tokens=75, total_tokens=130, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXy0kKDc4NdgPcPWnRlv428d9lp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의를 마친 후, 여러분은 다음을 할 수 있습니다:\\n\\n- 이미지 생성 애플리케이션 구축\\n- 메타 프롬프트를 사용하여 애플리케이션의 경계를 정의\\n- DALL-E 및 Midjourney 사용', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333146, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=59, prompt_tokens=71, total_tokens=130, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcXza2diuCi095qqtyOtivlW6RFn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 이미지 생성 애플리케이션을 왜 구축해야 할까요?\\n\\n이미지 생성 애플리케이션은 생성적 AI(Generative AI)의 역량을 탐구하는 좋은 방법입니다. 예를 들어, 다음과 같은 목적으로 사용될 수 있습니다:\\n\\n- **이미지 편집 및 합성**. 이미지 편집 및 이미지 합성과 같은 다양한 용도에 맞춰 이미지를 생성할 수 있습니다.\\n\\n- **다양한 산업에 적용**. Medtech(의료 기술), 관광, 게임 개발 등 다양한 산업에 이미지를 생성하는 데 사용할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333147, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_057232b607', usage=CompletionUsage(completion_tokens=122, prompt_tokens=122, total_tokens=244, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcY19kKS9Tx6B4ANP1IgVqqn4p2T', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 시나리오: 모두를 위한 교육(Edu4All)\\n\\n이 수업의 일환으로, 우리는 이 수업에서 스타트업인 Edu4All과 함께 계속 작업할 것입니다. 학생들은 평가를 위한 이미지를 만들 것입니다. 어떤 이미지를 만들지는 학생들에게 달려 있지만, 자신만의 동화를 위한 일러스트를 그리거나 이야기를 위한 새로운 캐릭터를 만들거나 아이디어와 개념을 시각화하는데 도움을 줄 수 있습니다.\\n\\n여기 Edu4All의 학생들이 예를 들어 수업시간에 기념물에 대해 작업할 때 생성할 수 있는 이미지 예시가 있습니다:\\n\\n![Edu4All 스타트업, 기념물 수업, 에펠탑](./images/startup.png?WT.mc_id=academic-105485-koreyst)\\n\\n다음과 같은 프롬프트를 사용할 수 있습니다\\n\\n> \"이른 아침 햇살에서 에펠탑 옆에 있는 강아지\"', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333149, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=210, prompt_tokens=170, total_tokens=380, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcY4Mwn4HR0TK9xjSegS4lgs41bO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## DALL-E와 Midjourney란 무엇인가요?\\n\\n[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst)와 [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst)는 두 가지 가장 인기 있는 이미지 생성 모델로, 프롬프트를 사용하여 이미지를 생성할 수 있게 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333152, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=91, prompt_tokens=112, total_tokens=203, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcY6wSNqXzIMRThIW0cPjNn6yN42', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### DALL-E\\n\\nDALL-E는 텍스트 설명으로부터 이미지를 생성하는 생성형 AI 모델입니다.\\n\\n> [DALL-E는 CLIP과 확산된 주의 메커니즘 두 가지 모델의 결합입니다](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\\n\\n- **CLIP**은 이미지와 텍스트로부터 데이터를 수치적으로 표현하는 임베딩을 생성하는 모델입니다.\\n\\n- **확산된 주의 메커니즘**은 임베딩으로부터 이미지를 생성하는 모델입니다. DALL-E는 이미지와 텍스트로 구성된 데이터셋으로 학습되며, 텍스트 설명으로부터 이미지를 생성하는 데 사용할 수 있습니다. 예를 들어, DALL-E는 모자를 쓴 고양이나 모호크 헤어스타일을 한 개의 이미지를 생성할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333154, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=217, prompt_tokens=206, total_tokens=423, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcY9rpg3vMIdxtBZwOml94hVrjW0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 미드저니 (Midjourney)\\n\\n미드저니는 DALL-E와 유사한 방식으로 작동하여, 텍스트로부터 이미지를 생성합니다. 미드저니는 \"모자를 쓴 고양이\" 또는 \"모히칸 헤어스타일을 한 강아지\"와 같은 프롬프트를 사용하여 이미지를 생성하는 데 사용할 수 있습니다.\\n\\n![미드저니로 생성된 이미지, 기계 비둘기](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\\n_이미지 출처: 위키백과, 미드저니로 생성된 이미지_', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333157, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=222, prompt_tokens=205, total_tokens=427, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYCOONn45PAgYXRsmWOBceCggph', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## DALL-E 및 Midjourney의 작동 원리\\n\\n먼저 [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E는 _자기회귀 변환기_가 포함된 변환기 아키텍처에 기반한 생성 AI 모델입니다.\\n\\n_자기회귀 변환기_는 모델이 텍스트 설명에서 이미지를 생성하는 방식을 정의합니다. 이 방식은 한 번에 하나의 픽셀을 생성하고, 생성된 픽셀을 사용하여 다음 픽셀을 생성합니다. 신경망의 여러 층을 통과하여 이미지를 완성합니다.\\n\\n이 과정을 통해 DALL-E는 생성된 이미지에서 속성, 객체, 특성 등을 제어할 수 있습니다. 그러나 DALL-E 2와 3은 생성된 이미지에 대해 더 많은 제어력을 가지고 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333160, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=201, prompt_tokens=187, total_tokens=388, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYFyuqR6efHYF31Yqtw44xqRHX8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 첫 번째 이미지 생성 애플리케이션 만들기\\n\\n이미지 생성 애플리케이션을 만들려면 다음 라이브러리가 필요합니다:\\n\\n- **python-dotenv**: 이 라이브러리를 사용하여 비밀 정보를 코드와 분리된 _.env_ 파일에 보관하는 것이 좋습니다.\\n- **openai**: OpenAI API와 상호 작용할 때 이 라이브러리를 사용합니다.\\n- **pillow**: Python에서 이미지를 다루기 위한 라이브러리입니다.\\n- **requests**: HTTP 요청을 도와주는 라이브러리입니다.\\n\\n1. 다음 내용을 포함하는 _.env_ 파일을 생성하세요:\\n\\n   ```text\\n   AZURE_OPENAI_ENDPOINT=<your endpoint>\\n   AZURE_OPENAI_API_KEY=<your key>\\n   ```\\n\\n   이 정보를 Azure 포털에서 \"키와 엔드포인트\" 섹션에서 찾을 수 있습니다.\\n\\n1. 위의 라이브러리를 _requirements.txt_ 파일에 다음과 같이 모으세요:\\n\\n   ```text\\n   python-dotenv\\n   openai\\n   pillow\\n   requests\\n   ```\\n\\n1. 다음으로 가상 환경을 생성하고 라이브러리를 설치하세요:\\n\\n   ```bash\\n   python3 -m venv venv\\n   source venv/bin/activate\\n   pip install -r requirements.txt\\n   ```\\n\\n   윈도우에서는 다음 명령어를 사용하여 가상 환경을 생성하고 활성화하세요:\\n\\n   ```bash\\n   python3 -m venv venv\\n   venv\\\\Scripts\\\\activate.bat\\n   ```\\n\\n1. _app.py_ 파일에 다음 코드를 추가하세요:\\n\\n   ```python\\n   import openai\\n   import os\\n   import requests\\n   from PIL import Image\\n   import dotenv\\n\\n   # import dotenv\\n   dotenv.load_dotenv()\\n\\n   # Get endpoint and key from environment variables\\n   openai.api_base = os.environ[\\'AZURE_OPENAI_ENDPOINT\\']\\n   openai.api_key = os.environ[\\'AZURE_OPENAI_API_KEY\\']\\n\\n   # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\\n   openai.api_version = \\'2023-06-01-preview\\'\\n   openai.api_type = \\'azure\\'\\n\\n\\n   try:\\n       # Create an image by using the image generation API\\n       generation_response = openai.Image.create(\\n           prompt=\\'Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\\',    # Enter your prompt text here\\n           size=\\'1024x1024\\',\\n           n=2,\\n           temperature=0,\\n       )\\n       # Set the directory for the stored image\\n       image_dir = os.path.join(os.curdir, \\'images\\')\\n\\n       # If the directory doesn\\'t exist, create it\\n       if not os.path.isdir(image_dir):\\n           os.mkdir(image_dir)\\n\\n       # Initialize the image path (note the filetype should be png)\\n       image_path = os.path.join(image_dir, \\'generated-image.png\\')\\n\\n       # Retrieve the generated image\\n       image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\\n       generated_image = requests.get(image_url).content  # download the image\\n       with open(image_path, \"wb\") as image_file:\\n           image_file.write(generated_image)\\n\\n       # Display the image in the default image viewer\\n       image = Image.open(image_path)\\n       image.show()\\n\\n   # catch exceptions\\n   except openai.InvalidRequestError as err:\\n       print(err)\\n\\n   ```\\n\\n이 코드를 설명해보겠습니다:\\n\\n- 먼저, OpenAI 라이브러리, dotenv 라이브러리, requests 라이브러리, Pillow 라이브러리를 포함합니다.\\n\\n  ```python\\n  import openai\\n  import os\\n  import requests\\n  from PIL import Image\\n  import dotenv\\n  ```\\n\\n- 다음으로, _.env_ 파일에서 환경 변수를 로드합니다.\\n\\n  ```python\\n  # import dotenv\\n  dotenv.load_dotenv()\\n  ```\\n\\n- 그 후, OpenAI API에 대한 엔드포인트, 키, 버전 및 타입을 설정합니다.\\n\\n  ```python\\n  # Get endpoint and key from environment variables\\n  openai.api_base = os.environ[\\'AZURE_OPENAI_ENDPOINT\\']\\n  openai.api_key = os.environ[\\'AZURE_OPENAI_API_KEY\\']\\n\\n  # add version and type, Azure specific\\n  openai.api_version = \\'2023-06-01-preview\\'\\n  openai.api_type = \\'azure\\'\\n  ```\\n\\n- 다음으로, 이미지를 생성합니다:\\n\\n  ```python\\n  # Create an image by using the image generation API\\n  generation_response = openai.Image.create(\\n      prompt=\\'Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\\',    # Enter your prompt text here\\n      size=\\'1024x1024\\',\\n      n=2,\\n      temperature=0,\\n  )\\n  ```\\n\\n  위의 코드에서는 생성된 이미지의 URL이 포함된 JSON 객체를 반환합니다. 이 URL을 사용하여 이미지를 다운로드하고 파일로 저장할 수 있습니다.\\n\\n- 마지막으로, 이미지를 열고 기본 이미지 뷰어를 사용하여 표시합니다:\\n\\n  ```python\\n  image = Image.open(image_path)\\n  image.show()\\n  ```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333163, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=1123, prompt_tokens=1085, total_tokens=2208, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYSigxCyfP5UfYLlUyUWaDTABhS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 이미지 생성에 대한 자세한 내용\\n\\n이미지 생성을 위한 코드를 좀 더 자세히 살펴보겠습니다:\\n\\n```python\\ngeneration_response = openai.Image.create(\\n        prompt=\\'Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\\',    # 여기에 프롬프트 텍스트를 입력하세요\\n        size=\\'1024x1024\\',\\n        n=2,\\n        temperature=0,\\n    )\\n```\\n\\n- **prompt**: 이미지를 생성하는 데 사용되는 텍스트 프롬프트입니다. 이 경우, \"안개 낀 초원에서 수선화가 자라는 곳에서 말 위에 있는 토끼, 사탕을 들고 있음\"이라는 프롬프트를 사용하고 있습니다.\\n- **size**: 생성되는 이미지의 크기입니다. 이 경우, 1024x1024 픽셀의 이미지를 생성하고 있습니다.\\n- **n**: 생성되는 이미지의 수입니다. 이 경우, 2개의 이미지를 생성하고 있습니다.\\n- **temperature**: 생성 AI 모델의 출력의 무작위성을 제어하는 매개변수입니다. temperature 값은 0에서 1 사이의 값으로, 0은 출력이 결정론적이고 1은 출력이 무작위임을 의미합니다. 기본값은 0.7입니다.\\n\\n이미지와 관련하여 더 할 수 있는 것들이 있으며, 다음 섹션에서 다루겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333176, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=310, prompt_tokens=297, total_tokens=607, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYaEXdnTam7C3GexxfU8u5LqeWE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 이미지 생성의 추가 기능\\n\\n지금까지 우리는 몇 줄의 파이썬 코드로 이미지를 생성하는 방법을 살펴보았습니다. 그러나 이미지와 관련해서 할 수 있는 더 많은 기능이 있습니다.\\n\\n다음과 같은 작업도 수행할 수 있습니다:\\n\\n- **편집 수행**. 기존 이미지에 마스크와 프롬프트를 제공하여 이미지를 변경할 수 있습니다. 예를 들어, 이미지의 일부에 무언가를 추가할 수 있습니다. 우리의 토끼 이미지에 모자를 추가할 수 있다고 상상해보세요. 이를 수행하는 방법은 이미지를 제공하고, 변경할 영역을 식별하는 마스크와 변경할 내용을 설명하는 텍스트 프롬프트를 제공하는 것입니다.\\n\\n  ```python\\n  response = openai.Image.create_edit(\\n    image=open(\"base_image.png\", \"rb\"),\\n    mask=open(\"mask.png\", \"rb\"),\\n    prompt=\"An image of a rabbit with a hat on its head.\",\\n    n=1,\\n    size=\"1024x1024\"\\n  )\\n  image_url = response[\\'data\\'][0][\\'url\\']\\n  ```\\n\\n  기본 이미지는 토끼만 포함하지만 최종 이미지는 토끼의 머리에 모자가 씌워져 있습니다.\\n\\n- **변형 생성**. 기존 이미지를 사용하여 변형을 생성합니다. 변형을 생성하기 위해서는 이미지를 제공하고 텍스트 프롬프트와 함께 다음과 같은 코드를 작성하면 됩니다:\\n\\n  ```python\\n  response = openai.Image.create_variation(\\n    image=open(\"bunny-lollipop.png\", \"rb\"),\\n    n=1,\\n    size=\"1024x1024\"\\n  )\\n  image_url = response[\\'data\\'][0][\\'url\\']\\n  ```\\n\\n  > 참고로, 이는 OpenAI에서만 지원됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333184, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=378, prompt_tokens=371, total_tokens=749, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYd38v7IGpnhwhjZ0OYklSCnJLF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 온도\\n\\n온도는 생성형 AI 모델의 출력 랜덤성을 제어하는 매개변수입니다. 온도는 0과 1 사이의 값이며, 0은 출력이 결정적이라는 의미이고 1은 출력이 랜덤이라는 의미입니다. 기본 값은 0.7입니다.\\n\\n온도가 어떻게 작동하는지 예제를 통해 알아보겠습니다. 이 프롬프트를 두 번 실행해보겠습니다:\\n\\n> 프롬프트: \"안개가 낀 초원에서 수선화가 자라는 장소에서 말 위에 앉아 막대사탕을 들고 있는 토끼\"\\n\\n![막대사탕을 들고 있는 말 위의 토끼, 버전 1](./images/v1-generated-image.png?WT.mc_id=academic-105485-koreyst)\\n\\n이제 같은 프롬프트를 다시 실행하여 동일한 이미지를 얻지 못할 것임을 확인해봅시다:\\n\\n![말 위의 토끼가 생성된 이미지](./images/v2-generated-image.png?WT.mc_id=academic-105485-koreyst)\\n\\n보시다시피, 이미지들은 유사하지만 동일하지 않습니다. 이제 온도 값을 0.1로 변경하고 어떤 일이 일어나는지 살펴봅시다:\\n\\n```python\\ngeneration_response = openai.Image.create(\\n        prompt=\\'안개가 낀 초원에서 수선화가 자라는 장소에서 말 위에 앉아 막대사탕을 들고 있는 토끼\\',    # 여기 프롬프트 텍스트를 입력하세요\\n        size=\\'1024x1024\\',\\n        n=2\\n    )\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333187, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=352, prompt_tokens=306, total_tokens=658, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYjrkp1NEzglbm2FlnWVGpwIJO8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### 온도 변경\\n\\n이제 응답을 더 결정론적으로 만들어 보겠습니다. 생성한 두 이미지를 보면, 첫 번째 이미지에는 토끼가 있고 두 번째 이미지에는 말이 있어서 이미지가 크게 다릅니다.\\n\\n따라서 코드를 변경하여 온도를 0으로 설정해 보겠습니다. 다음과 같습니다:\\n\\n```python\\ngeneration_response = openai.Image.create(\\n        prompt='토끼가 말을 타고, 롤리팝을 들고 있는 모습, 안개가 낀 목초지에 수선화가 자라는 모습',    # 여기에 프롬프트 텍스트를 입력하세요\\n        size='1024x1024',\\n        n=2,\\n        temperature=0\\n    )\\n```\\n\\n이제 이 코드를 실행하면 다음 두 이미지를 얻게 됩니다:\\n\\n- ![온도 0, 버전 1](./images/v1-temp-generated-image.png?WT.mc_id=academic-105485-koreyst)\\n- ![온도 0, 버전 2](./images/v2-temp-generated-image.png?WT.mc_id=academic-105485-koreyst)\\n\\n여기에서 두 이미지가 서로 더 비슷해진 것을 명확히 볼 수 있습니다.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333193, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=258, prompt_tokens=249, total_tokens=507, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYmWW6VQaLMUjjEMbScBjJkFqRc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 메타프롬프트를 사용하여 애플리케이션의 경계를 정의하는 방법\\n\\n우리의 데모를 통해 이미 고객에게 이미지를 생성할 수 있습니다. 그러나 애플리케이션에 몇 가지 경계를 설정해야 합니다.\\n\\n예를 들어, 업무에 적합하지 않거나 어린이에게 부적절한 이미지를 생성하지 않도록 하고 싶습니다.\\n\\n이를 _메타프롬프트_로 수행할 수 있습니다. 메타프롬프트는 생성적 AI 모델의 출력을 제어하기 위해 사용되는 텍스트 프롬프트입니다. 예를 들어, 메타프롬프트를 사용하여 출력을 제어하고 생성된 이미지가 업무에 적합하거나 어린이에게 적합하도록 할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333196, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=162, prompt_tokens=154, total_tokens=316, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYo4BV3CmQcRAwiJJglaIXUFU89', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 어떻게 작동하나요?\\n\\n이제 메타 프롬프트는 어떻게 작동하나요?\\n\\n메타 프롬프트는 생성형 AI 모델의 출력을 제어하기 위해 사용되는 텍스트 프롬프트로, 텍스트 프롬프트 앞에 위치하여 모델의 출력을 제어하고, 프롬프트 입력과 메타 프롬프트 입력을 단일 텍스트 프롬프트로 캡슐화합니다.\\n\\n메타 프롬프트의 한 예는 다음과 같습니다:\\n\\n```text\\n당신은 어린이를 위한 이미지를 만드는 보조 디자이너입니다.\\n\\n이미지는 작업에 적합하고 어린이에게 적절해야 합니다.\\n\\n이미지는 색상이 있어야 합니다.\\n\\n이미지는 가로 방향이어야 합니다.\\n\\n이미지는 16:9 비율이어야 합니다.\\n\\n작업에 적합하지 않거나 어린이에게 적절하지 않은 입력은 고려하지 마십시오.\\n\\n(입력)\\n```\\n\\n이제 우리의 데모에서 메타 프롬프트를 어떻게 사용할 수 있는지 보겠습니다.\\n\\n```python\\n금지_리스트 = \"검, 폭력, 피, 고어, 누드, 성적인 콘텐츠, 성인 콘텐츠, 성인 주제, 성인 언어, 성인 유머, 성인 농담, 성인 상황, 성인\"\\n\\n메타_프롬프트 = f\"\"\"당신은 어린이를 위한 이미지를 만드는 보조 디자이너입니다.\\n\\n이미지는 작업에 적합하고 어린이에게 적절해야 합니다.\\n\\n이미지는 색상이 있어야 합니다.\\n\\n이미지는 가로 방향이어야 합니다.\\n\\n이미지는 16:9 비율이어야 합니다.\\n\\n작업에 적합하지 않거나 어린이에게 적절하지 않은 입력은 고려하지 마십시오.\\n{금지_리스트}\\n\"\"\"\\n\\n프롬프트 = f\"{메타_프롬프트}\\n말 위에 앉아 사탕을 들고 있는 토끼의 이미지를 만드세요\"\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333198, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=424, prompt_tokens=364, total_tokens=788, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYs2L7vttqj6hvzTOHwLBZiQyUT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 요청에 이미지 생성 추가하기\\n```\\n\\n위의 프롬프트에서, 모든 생성된 이미지가 메타프롬프트를 고려하는 방식을 볼 수 있습니다.\\n\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333202, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=39, prompt_tokens=57, total_tokens=96, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYtj4coqVWEoTMFui8ocAVO4nvo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제 - 학생들을 돕자\\n\\n우리는 이번 수업의 시작에서 Edu4All을 도입했습니다. 이제 학생들이 그들의 평가를 위해 이미지를 생성할 수 있도록 도와줄 때입니다.\\n\\n학생들은 그들의 평가에 사용할 기념물 이미지를 생성할 것입니다. 정확히 어떤 기념물인지는 학생들이 선택할 수 있습니다. 이 과제에서 학생들은 창의력을 발휘하여 다양한 맥락에서 이러한 기념물을 배치하도록 요청받습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333203, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=105, prompt_tokens=100, total_tokens=205, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYypWz9lcWpF5uxmNL9IgLH688c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 솔루션\\n\\n다음은 가능한 솔루션 중 하나입니다:\\n\\n```python\\nimport openai\\nimport os\\nimport requests\\nfrom PIL import Image\\nimport dotenv\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333208, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=38, prompt_tokens=57, total_tokens=95, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcYzfA8jQfX3JbAozw1PimvlTXxi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# dotenv 불러오기\\ndotenv.load_dotenv()', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333209, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=11, prompt_tokens=37, total_tokens=48, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZ0nD7DhyDmJ0P5CSWgdkb15mq5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 환경 변수에서 엔드포인트와 키 가져오기\\nopenai.api_base = \"<엔드포인트로 교체>\"\\nopenai.api_key = \"<api 키로 교체>\"', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333210, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=39, prompt_tokens=59, total_tokens=98, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZ1cVdEGCe1OLx7J8G30IuIhTkb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# API 버전 할당 (현재 DALL-E는 2023-06-01-preview API 버전만 지원합니다)\\nopenai.api_version = \\'2023-06-01-preview\\'\\nopenai.api_type = \\'azure\\'\\n\\ndisallow_list = \"검, 폭력, 피, 유혈, 노출, 성적 콘텐츠, 성인 콘텐츠, 성인 주제, 성인 언어, 성인 유머, 성인 농담, 성인 상황, 성인\"\\n\\nmeta_prompt = f\"\"\"당신은 어린이를 위해 이미지를 만드는 보조 디자이너입니다.\\n\\n이미지는 작업하기 안전하고 어린이에게 적합해야 합니다.\\n\\n이미지는 컬러여야 합니다.\\n\\n이미지는 가로 방향이어야 합니다.\\n\\n이미지는 16:9 비율이어야 합니다.\\n\\n아래에 나열된 작업에 안전하지 않거나 어린이에게 적절하지 않은 입력을 고려하지 마십시오.\\n{disallow_list}\"\"\"\\n\\nprompt = f\"\"\"{meta_prompt}\\n저녁 빛 속에서 파리, 프랑스의 개선문 기념물을 만들고 있는 테디를 들고 있는 작은 어린이가 보고 있는 모습.\\n\"\"\"\\n\\ntry:\\n    # 이미지 생성 API를 사용하여 이미지 생성\\n    generation_response = openai.Image.create(\\n        prompt=prompt,    # 여기서 프롬프트 텍스트 입력\\n        size=\\'1024x1024\\',\\n        n=2,\\n        temperature=0,\\n    )\\n    # 저장된 이미지 디렉토리 설정\\n    image_dir = os.path.join(os.curdir, \\'images\\')\\n\\n    # 디렉토리가 존재하지 않으면 생성\\n    if not os.path.isdir(image_dir):\\n        os.mkdir(image_dir)\\n\\n    # 이미지 경로 초기화 (파일 타입은 png여야 함)\\n    image_path = os.path.join(image_dir, \\'generated-image.png\\')\\n\\n    # 생성된 이미지 가져오기\\n    image_url = generation_response[\"data\"][0][\"url\"]  # 응답에서 이미지 URL 추출\\n    generated_image = requests.get(image_url).content  # 이미지 다운로드\\n    with open(image_path, \"wb\") as image_file:\\n        image_file.write(generated_image)\\n\\n    # 기본 이미지 뷰어에서 이미지 표시\\n    image = Image.open(image_path)\\n    image.show()\\n\\n\"\"\"', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333211, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=478, prompt_tokens=463, total_tokens=941, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZ75b2eqb8ijhQOPUWV0V2hGoYw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```markdown\\n# 예외 처리\\nexcept openai.InvalidRequestError as err:\\n    print(err)\\n```\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333217, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=23, prompt_tokens=47, total_tokens=70, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZ8tQ7lpByAK6QsCyfa5UByM0g4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 학습을 계속하세요\\n\\n이 강의를 마친 후, [Generative AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 Generative AI 지식을 계속해서 향상시키세요!\\n\\n레슨 10으로 이동하여 [로우코드로 AI 애플리케이션 구축](../10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)에 대해 알아보세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333218, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=116, prompt_tokens=127, total_tokens=243, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZAXJEU5ORM5AUD9NwFLTmy1e7G', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 다양한 대형 언어 모델(LLM) 탐색 및 비교\\n\\n[![다양한 대형 언어 모델 탐색 및 비교](./images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)\\n\\n> _이 강의의 영상을 보려면 위 이미지를 클릭하세요_\\n\\n이전 강의에서는 생성적 AI가 기술 지형을 어떻게 변화시키고, 대형 언어 모델(LLM)이 어떻게 작동하며, 우리의 스타트업 같은 비즈니스가 이를 어떻게 활용하여 성장할 수 있는지 살펴보았습니다. 이번 장에서는 다양한 종류의 대형 언어 모델(LLM)을 비교하고 대조하여 그 장단점을 이해하려고 합니다.\\n\\n우리 스타트업의 다음 단계는 현재 LLM의 지형을 탐색하고, 우리의 사용 사례에 적합한 모델을 이해하는 것입니다.\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333220, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=209, prompt_tokens=206, total_tokens=415, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZCvk8G5ptGNeBNwcPdVb3at0uH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 수업에서는 다음 내용을 다룹니다:\\n\\n- 현재의 LLMs 유형들.\\n- Azure에서 사용 사례에 맞는 모델들을 테스트, 반복, 비교하는 방법.\\n- LLM 배포 방법.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333222, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=47, prompt_tokens=73, total_tokens=120, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZD0quv2E64EqTh9S7l6IwwYEE8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 수업을 완료한 후, 여러분은 다음을 할 수 있습니다:\\n\\n- 사용 사례에 맞는 적절한 모델 선택하기.\\n- 모델의 성능을 테스트하고 반복하며 개선하는 방법 이해하기.\\n- 기업이 모델을 배포하는 방법 알기.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333223, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=62, prompt_tokens=75, total_tokens=137, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZEttNuGWFG1LKDguZ5fetC7bW9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 다양한 유형의 LLM 이해하기\\n\\nLLM은 아키텍처, 훈련 데이터, 사용 사례에 따라 여러 가지 범주로 나눌 수 있습니다. 이러한 차이점을 이해하면 스타트업이 시나리오에 적합한 모델을 선택하고, 테스트, 반복 및 성능 개선 방법을 이해하는 데 도움이 됩니다.\\n\\nLLM 모델의 선택은 사용 용도, 데이터, 지불할 준비가 된 비용 등에 따라 달라질 수 있습니다.\\n\\n모델을 텍스트, 오디오, 비디오, 이미지 생성 등의 용도로 사용하려는 경우, 다른 유형의 모델을 선택할 수 있습니다.\\n\\n- **오디오 및 음성 인식**. 이를 위해 Whisper 유형 모델은 다목적용이며 음성 인식을 목표로 하기 때문에 훌륭한 선택입니다. 이 모델은 다양한 오디오로 훈련되었으며 다국어 음성 인식을 수행할 수 있습니다. [Whisper 유형 모델에 대해 더 알아보십시오](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).\\n\\n- **이미지 생성**. 이미지 생성을 위해 DALL-E와 Midjourney는 잘 알려진 두 가지 선택입니다. DALL-E는 Azure OpenAI에서 제공됩니다. [DALL-E에 대해 더 알아보십시오](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) 및 이 커리큘럼의 9장에서 다룹니다.\\n\\n- **텍스트 생성**. 대부분의 모델은 텍스트 생성을 위해 훈련되었으며, GPT-3.5부터 GPT-4까지 다양한 선택이 가능합니다. 비용은 모델마다 다르며 GPT-4가 가장 비쌉니다. [Azure OpenAI 플레이그라운드](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst)를 통해 능력과 비용 면에서 어느 모델이 가장 적합한지 평가해볼 가치가 있습니다.\\n\\n- **멀티 모달리티**. 입력과 출력에서 여러 종류의 데이터를 처리하려면 [비전 기능을 포함한 GPT-4 터보 또는 GPT-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) 같은 모델을 살펴볼 수 있습니다. 이 최신 OpenAI 모델은 자연어 처리와 시각적 이해를 결합하여 멀티모달 인터페이스를 통한 상호작용을 가능하게 합니다.\\n\\n모델을 선택하면 기본 기능을 제공받지만, 이는 충분하지 않을 수 있습니다. 종종 회사 특유의 데이터를 LLM에게 제공해야 하기 때문에 몇 가지 접근 방법이 있으며, 이에 대해서는 다음 섹션에서 더 자세히 다루겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333224, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=615, prompt_tokens=565, total_tokens=1180, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZLvOJ2LjrHVFKfbc1NPq7b6j3h', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 파운데이션 모델 대 LLMs\\n\\n파운데이션 모델이라는 용어는 [스탠포드 연구원들에 의해 만들어졌습니다](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst)와 다음과 같은 기준을 따르는 AI 모델로 정의됩니다:\\n\\n- **비지도 학습 또는 자가 지도 학습을 사용하여 훈련됩니다**, 즉, 라벨이 없는 다중 모달 데이터를 사용하여 훈련되며, 데이터의 인간 주석이나 라벨링이 필요하지 않습니다.\\n- **매우 큰 모델입니다**, 수십 억 개의 매개변수로 훈련된 매우 깊은 신경망에 기반을 둡니다.\\n- **일반적으로 다른 모델의 ‘기초’로 사용되도록 의도됩니다**, 즉, 다른 모델이 그 위에 구축될 출발점으로 사용할 수 있으며, 이는 미세 조정을 통해 가능합니다.\\n\\n![파운데이션 모델 대 LLMs](./images/FoundationModel.png?WT.mc_id=academic-105485-koreyst)\\n\\n이미지 출처: [Foundation Models and Large Language Models에 대한 필수 가이드 | Babar M Bhatti 작성 | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)\\n\\n이 구분을 더욱 명확히 하기 위해, ChatGPT를 예로 들어 보겠습니다. ChatGPT의 첫 번째 버전을 만들기 위해 GPT-3.5라는 모델이 파운데이션 모델로 사용되었습니다. 이는 OpenAI가 GPT-3.5를 대화 시나리오, 예를 들어 챗봇에서 잘 수행하도록 특화된 버전을 만들기 위해 일부 채팅 관련 데이터를 사용했다는 것을 의미합니다.\\n\\n![파운데이션 모델](./images/Multimodal.png?WT.mc_id=academic-105485-koreyst)\\n\\n이미지 출처: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333231, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=456, prompt_tokens=414, total_tokens=870, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZPt6U9b9ZmcGo5IZSuP9sWiV4w', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 오픈 소스 대 독점 모델\\n\\nLLM(대형 언어 모델)을 분류하는 또 다른 방법은 모델이 오픈 소스인지 독점적인지에 따라 구분하는 것입니다.\\n\\n오픈 소스 모델은 대중에게 공개되어 누구나 사용할 수 있는 모델입니다. 이러한 모델은 종종 이를 만든 회사나 연구 커뮤니티에 의해 제공됩니다. 이러한 모델은 LLM의 다양한 사용 사례에 맞게 검사, 수정, 사용자 정의할 수 있습니다. 그러나 항상 생산용으로 최적화되어 있지는 않으며, 독점 모델만큼 성능이 우수하지 않을 수 있습니다. 또한 오픈 소스 모델에 대한 자금 지원은 제한될 수 있으며, 장기적으로 유지되지 않거나 최신 연구 결과로 업데이트되지 않을 수 있습니다. 인기 있는 오픈 소스 모델의 예로는 [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom), [LLaMA](https://llama.meta.com) 등이 있습니다.\\n\\n독점 모델은 회사가 소유하고 대중에게 공개되지 않는 모델입니다. 이러한 모델들은 종종 생산 사용을 위해 최적화되어 있습니다. 그러나 이러한 모델은 다양한 사용 사례에 맞게 검사, 수정, 사용자 정의하는 것이 허용되지 않습니다. 또한 항상 무료로 제공되지 않으며, 사용을 위해 구독하거나 요금을 지불해야 할 수도 있습니다. 또한, 사용자는 모델을 훈련하는 데 사용되는 데이터에 대한 통제권이 없기 때문에, 데이터 프라이버시 및 AI의 책임 있는 사용에 대한 약속을 모델 소유자에게 신뢰해야 합니다. 인기 있는 독점 모델의 예로는 [OpenAI 모델](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst), [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst) 등이 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333235, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=472, prompt_tokens=434, total_tokens=906, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZVkyRGF04uthfUnsGHRKCTdjUa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 임베딩 vs. 이미지 생성 vs. 텍스트 및 코드 생성\\n\\n대규모 언어 모델(LLMs)은 생성하는 출력에 따라 분류될 수 있습니다.\\n\\n임베딩은 텍스트를 임베딩이라는 수치적 형식으로 변환할 수 있는 모델들의 집합입니다. 임베딩은 입력된 텍스트를 수치적으로 표현한 것이며, 이는 단어 또는 문장 간의 관계를 기계가 더 쉽게 이해할 수 있게 해줍니다. 임베딩은 분류 모델이나 클러스터링 모델과 같은 다른 모델들이 숫자 데이터를 이용해 더 나은 성능을 발휘할 수 있도록 입력값으로 사용할 수 있습니다. 임베딩 모델은 데이터가 풍부한 대리 작업에 대해 모델을 구축한 후, 그 모델의 가중치(임베딩)를 다른 다운스트림 작업에 재사용하는 전이 학습에 자주 사용됩니다. 이 범주의 예로는 [OpenAI 임베딩](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst)을 들 수 있습니다.\\n\\n![Embedding](./images/Embedding.png?WT.mc_id=academic-105485-koreyst)\\n\\n이미지 생성 모델은 이미지를 생성하는 모델입니다. 이 모델은 이미지 편집, 이미지 합성, 이미지 번역 등에 자주 사용됩니다. 이미지 생성 모델은 [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst)와 같은 대규모 이미지 데이터셋으로 학습되며, 새로운 이미지를 생성하거나 기존 이미지를 인페인팅, 초해상도 및 색상화 기술로 편집할 수 있습니다. 예로는 [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst)와 [Stable Diffusion 모델](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst)이 있습니다.\\n\\n![Image generation](./images/Image.png?WT.mc_id=academic-105485-koreyst)\\n\\n텍스트와 코드 생성 모델은 텍스트 또는 코드를 생성하는 모델입니다. 이 모델은 텍스트 요약, 번역, 질문 응답 등에 자주 사용됩니다. 텍스트 생성 모델은 [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst)와 같은 대규모 텍스트 데이터셋을 학습하며, 새로운 텍스트를 생성하거나 질문에 답할 수 있습니다. 코드 생성 모델인 [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst)은 GitHub과 같은 대규모 코드 데이터셋을 학습하며, 새로운 코드를 생성하거나 기존 코드의 버그를 수정할 수 있습니다.\\n\\n![Text and code generation](./images/Text.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333241, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=672, prompt_tokens=595, total_tokens=1267, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZcp16PBuVovUVgwAdJfgwkiiZT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 인코더-디코더 vs 디코더-온리\\n\\nLLM(대형 언어 모델)의 다양한 아키텍처 타입에 대해 이야기하기 위해 비유를 사용해봅시다.\\n\\n당신의 상사가 학생들을 위한 퀴즈를 작성하라는 임무를 주었다고 가정해보겠습니다. 당신에게는 두 명의 동료가 있으며, 한 명은 콘텐츠 생성을, 다른 한 명은 리뷰를 담당합니다.\\n\\n콘텐츠 작성자는 디코더-온리 모델과 같습니다. 그들은 주제를 보고 이미 작성된 내용을 참조한 다음 그에 기반하여 코스를 작성할 수 있습니다. 그들은 매력적이고 유익한 콘텐츠를 작성하는 데 매우 능숙하지만, 주제와 학습 목표를 이해하는 데는 그다지 능숙하지 않습니다. 디코더 모델의 예로는 GPT-3 같은 GPT 계열의 모델이 있습니다.\\n\\n리뷰어는 인코더-온리 모델과 같습니다. 그들은 작성된 코스와 답변을 보고 그들 사이의 관계를 이해하지만, 콘텐츠 생성에는 능숙하지 않습니다. 인코더-온리 모델의 예로는 BERT가 있습니다.\\n\\n이제 퀴즈를 작성하고 리뷰할 수 있는 사람도 있다고 상상해봅시다. 이것이 바로 인코더-디코더 모델입니다. 예로는 BART와 T5가 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333248, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=303, prompt_tokens=243, total_tokens=546, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZvOeCJyIIXCOq6xYZxiJT0HoqI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 서비스와 모델\\n\\n이번에는 서비스와 모델의 차이에 대해 이야기해 보겠습니다. 서비스는 클라우드 서비스 제공자가 제공하는 제품으로, 종종 모델, 데이터 및 기타 구성 요소의 조합으로 구성됩니다. 모델은 서비스의 핵심 구성 요소로, LLM과 같은 기반 모델인 경우가 많습니다.\\n\\n서비스는 종종 운영 환경에 최적화되어 있으며, 그래픽 사용자 인터페이스를 통해 모델보다 사용이 용이한 경우가 많습니다. 그러나 서비스는 항상 무료로 제공되는 것은 아니며, 구독 또는 사용료가 필요할 수 있습니다. 이는 서비스 소유자의 장비와 자원을 활용하여 비용을 최적화하고 손쉽게 확장할 수 있도록 교환하는 것입니다. 서비스의 예로는 [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst)를 들 수 있습니다. 이는 사용량에 비례해 비용이 청구되는 요금제를 제공하며, 사용자들이 서비스를 얼마나 사용하느냐에 따라 비용이 결정됩니다. 또한, Azure OpenAI Service는 모델의 기능 외에도 엔터프라이즈급 보안 및 책임 있는 AI 프레임워크를 제공합니다.\\n\\n모델은 단지 매개변수, 가중치 등을 가진 신경망일 뿐입니다. 기업이 이를 로컬에서 실행하려면 장비를 구매하고, 확장할 수 있는 구조를 구축해야 하며, 라이선스를 구매하거나 오픈 소스 모델을 사용해야 할 필요가 있습니다. 예를 들어 LLaMA와 같은 모델은 사용할 수 있지만, 이를 구동하기 위해서는 컴퓨팅 성능이 필요합니다.\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333267, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=359, prompt_tokens=307, total_tokens=666, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcZzmQNoqWL6U8bSkR18FMbW6w3O', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Azure에서 성능을 이해하기 위해 다양한 모델을 테스트하고 반복하는 방법\\n\\n우리 팀이 현재 LLM(대규모 언어 모델) 환경을 탐색하고 그들의 시나리오에 적합한 후보를 확인한 이후, 다음 단계는 그 모델을 데이터와 워크로드에 테스트하는 것입니다. 이는 실험과 측정을 통한 반복 과정입니다.\\n앞서 언급한 대부분의 모델(예: OpenAI 모델, Llama2 및 Hugging Face transformers와 같은 오픈 소스 모델)은 [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst)의 [모델 카탈로그](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst)에서 사용할 수 있습니다.\\n\\n[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst)는 개발자가 생성적 AI 애플리케이션을 구축하고 실험부터 평가까지 전체 개발 라이프사이클을 관리할 수 있도록 설계된 클라우드 플랫폼입니다. 이 플랫폼은 모든 Azure AI 서비스를 하나의 편리한 GUI로 결합하여 제공합니다. Azure AI Studio의 모델 카탈로그는 사용자에게 다음과 같은 기능을 제공합니다:\\n\\n- 카탈로그에서 흥미로운 기본 모델 찾기 - 독점적이거나 오픈 소스 모델을 작업, 라이선스 또는 이름으로 필터링할 수 있습니다. 검색성을 향상시키기 위해 모델은 Azure OpenAI 컬렉션, Hugging Face 컬렉션 등으로 조직되어 있습니다.\\n\\n![모델 카탈로그](./images/AzureAIStudioModelCatalog.png?WT.mc_id=academic-105485-koreyst)\\n\\n- 모델 카드 검토: 사용 목적, 학습 데이터, 코드 샘플 및 내부 평가 라이브러리에 대한 평가 결과를 포함한 상세 설명을 확인할 수 있습니다.\\n\\n![모델 카드](./images/ModelCard.png?WT.mc_id=academic-105485-koreyst)\\n\\n- 모델 벤치마크를 통해 산업에서 이용할 수 있는 모델 및 데이터셋을 비교하여 비즈니스 시나리오에 맞는 모델을 평가할 수 있습니다. 이 기능은 [모델 벤치마크](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) 창에서 확인할 수 있습니다.\\n\\n![모델 벤치마크](./images/ModelBenchmarks.png?WT.mc_id=academic-105485-koreyst)\\n\\n- 사용자 정의 학습 데이터를 사용하여 특정 작업에서 모델 성능을 개선하기 위해 모델을 미세 조정할 수 있으며, Azure AI Studio의 실험 및 추적 기능을 활용할 수 있습니다.\\n\\n![모델 미세 조정](./images/FineTuning.png?WT.mc_id=academic-105485-koreyst)\\n\\n- 원본 사전 학습 모델 또는 미세 조정된 버전을 원격 실시간 추론 환경 - 관리형 컴퓨팅 - 또는 서버리스 API 엔드포인트 - [사용한 만큼 지불](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - 으로 배포하여 애플리케이션에서 사용할 수 있게 합니다.\\n\\n![모델 배포](./images/ModelDeploy.png?WT.mc_id=academic-105485-koreyst)\\n\\n> [!NOTE]\\n> 현재 카탈로그에 있는 모든 모델이 미세 조정 및/또는 사용한 만큼 지불 배포를 지원하는 것은 아닙니다. 모델의 기능과 한계에 대한 자세한 내용은 모델 카드를 확인하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333271, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=828, prompt_tokens=687, total_tokens=1515, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABca9Q6kWyBgqOflEHHyQ633NK9Ne', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## LLM 결과 개선\\n\\n저희 스타트업 팀은 다양한 종류의 LLM(Large Language Models)과 클라우드 플랫폼(Azure Machine Learning)을 탐구하여 다양한 모델을 비교하고, 테스트 데이터로 평가하며, 성능을 향상시키고 추론 엔드포인트에 배포할 수 있도록 했습니다.\\n\\n하지만 언제 사전 학습된 모델을 사용하는 대신 모델을 미세 조정해야 할까요? 특정 작업에서 모델 성능을 향상시키기 위한 다른 접근 방식이 있을까요?\\n\\n비즈니스는 LLM에서 원하는 결과를 얻기 위해 몇 가지 접근 방식을 사용할 수 있습니다. LLM을 배포할 때는 다양한 수준의 복잡성, 비용 및 품질로 다양한 종류의 모델을 선택할 수 있습니다. 다음은 몇 가지 접근 방식입니다:\\n\\n- **컨텍스트를 포함한 프롬프트 엔지니어링**: 프롬프트할 때 원하는 응답을 얻기 위해 충분한 컨텍스트를 제공하는 것이 중요합니다.\\n\\n- **검색 기반 생성(RAG)**: 예를 들어, 데이터가 데이터베이스나 웹 엔드포인트에 존재할 수 있으며, 프롬프트 시점에 이 데이터 또는 그 하위 집합이 포함되도록 관련 데이터를 검색하여 사용자의 프롬프트 일부로 포함시킬 수 있습니다.\\n\\n- **미세 조정된 모델**: 여기서 모델을 자체 데이터로 추가 학습시켜 모델이 더 정확하고 요구에 맞게 응답하게 할 수 있지만, 비용이 많이 들 수 있습니다.\\n\\n![LLMs deployment](./images/Deploy.png?WT.mc_id=academic-105485-koreyst)\\n\\n이미지 출처: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333281, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=403, prompt_tokens=362, total_tokens=765, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaDsSs9mkqMuQj7EPdbELk3cnWq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 컨텍스트를 활용한 프롬프트 엔지니어링\\n\\n사전 학습된 대형 언어 모델(LLM)은 일반화된 자연어 작업에서 매우 잘 작동하며, 짧은 프롬프트(예: 완성할 문장이나 질문)로 호출할 때도 뛰어난 성능을 보입니다. 이를 \"제로 샷\" 학습이라고 합니다.\\n\\n그러나 사용자가 상세한 요청과 예시(컨텍스트)를 통해 자신의 쿼리를 더 잘 구성할수록 답변이 사용자 기대에 더 정확하고 가까워집니다. 이 경우, 프롬프트에 하나의 예시만 포함되면 “원샷” 학습, 여러 개의 예시가 포함되면 “페샷” 학습이라고 합니다.\\n컨텍스트를 활용한 프롬프트 엔지니어링은 가장 비용 효율적인 시작 방법입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333285, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=195, prompt_tokens=156, total_tokens=351, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaINy9zXnQ8WdGhGm2udhBI5JTi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 검색 증강 생성 (RAG)\\n\\n대형 언어 모델(LLMs)은 훈련 중에 사용된 데이터를 기반으로만 답변을 생성할 수 있는 한계가 있습니다. 이로 인해 훈련 이후에 발생한 사실이나 비공개 정보(예: 회사 데이터)에 대해 알지 못합니다.\\n이 문제는 RAG를 통해 극복할 수 있습니다. RAG는 외부 데이터를 문서의 조각 형태로 추가하여 프롬프트의 길이 제한을 고려하면서 프롬프트를 증강하는 기술입니다. 이는 다양한 사전 정의된 데이터 소스에서 유용한 조각들을 검색하여 프롬프트 맥락(Context)에 추가하는 Vector 데이터베이스 도구(예: [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst))에 의해 지원됩니다.\\n\\n이 기술은 데이터나 시간, 자원이 충분하지 않은 경우에도 특정 작업 부하에 대한 성능을 향상시키고 현실 왜곡이나 유해한 콘텐츠 생성의 위험을 줄이기를 원하는 비즈니스에 매우 유용합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333290, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=244, prompt_tokens=234, total_tokens=478, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaNBj9NmPIsB0ZqoEe7XdPFGz5Q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### Fine-tuned model\\n\\n파인 튜닝은 모델을 다운스트림 작업이나 특정 문제를 해결하기 위해 '적응'시키는 전이 학습을 활용하는 과정입니다. 소수 샷 학습과 RAG와는 달리, 이는 업데이트된 가중치와 편향이 있는 새로운 모델을 생성하는 결과를 낳습니다. 여기에는 단일 입력(프롬프트)과 그에 대한 연관 출력(완성)으로 구성된 훈련 예제가 필요합니다.\\n이는 다음과 같은 경우 선호되는 접근 방식입니다:\\n\\n- **파인 튜닝된 모델 사용**. 기업은 고성능 모델보다는 덜 능력이 있는 모델(예: 임베딩 모델)을 사용하여 비용 효율적이고 빠른 솔루션을 원하는 경우.\\n\\n- **지연 시간 고려**. 지연 시간이 특정 사용 사례에서 중요하기 때문에 매우 긴 프롬프트를 사용할 수 없거나 모델이 학습해야 할 예제의 수가 프롬프트 길이 제한에 맞지 않는 경우.\\n\\n- **최신 상태 유지**. 기업이 고품질 데이터와 정답 라벨을 많이 보유하고 있으며 이러한 데이터를 지속적으로 최신 상태로 유지하는 데 필요한 자원을 가지고 있는 경우.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333295, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=267, prompt_tokens=244, total_tokens=511, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaSqSd598DuepXyQCgeWFFeiLcJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 훈련된 모델\\n\\nLLM을 처음부터 훈련하는 것은 의심할 여지 없이 가장 어렵고 복잡한 접근 방식으로, 방대한 데이터, 숙련된 자원, 적절한 컴퓨팅 파워가 필요합니다. 이 옵션은 비즈니스가 분야별 특정 사용 사례와 대량의 분야 중심 데이터를 보유한 경우에만 고려되어야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333300, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=85, prompt_tokens=95, total_tokens=180, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaT4ji0tzgIpxofGcQtxkvSe5l0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 점검\\n\\nLLM(대형 언어 모델) 완성 결과를 개선할 수 있는 좋은 접근법은 무엇일까요?\\n\\n1. 문맥을 고려한 프롬프트 엔지니어링\\n2. RAG\\n3. 미세 조정된 모델\\n\\nA: 3, 시간과 자원 그리고 고품질 데이터를 가지고 있다면, 미세 조정이 최신 상태를 유지하는 데 더 나은 옵션입니다. 그러나 시간을 절약하려 한다면 먼저 RAG를 고려할 가치가 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333301, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=114, prompt_tokens=112, total_tokens=226, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaUs1zZLGtzbeGAq9SYU8l2KMbD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 🚀 도전\\n\\n당신의 비즈니스에 대해 [RAG 사용 방법](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst)에 대해 더 알아보세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333302, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=56, prompt_tokens=79, total_tokens=135, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaWGP6O42uXsjN4bhnXTXr6u8Sl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업, 학습을 계속하세요\\n\\n이 레슨을 완료한 후, 우리의 [생성적 AI 학습 모음](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성적 AI 지식을 계속 향상시키세요!\\n\\nLesson 3로 이동하여 [책임감 있게 생성적 AI 구축하기](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)를 알아봅시다!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333304, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=116, prompt_tokens=130, total_tokens=246, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaYEXGdWon3Yq69xLQFSs5V7irD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 텍스트 생성 애플리케이션 빌드하기\\n\\n[![텍스트 생성 애플리케이션 빌드하기](./images/06-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson6-gh?WT.mc_id=academic-105485-koreyst)\\n\\n> _(위 이미지를 클릭하여 이 레슨의 비디오를 시청하세요)_\\n\\n지금까지 이 커리큘럼을 통해 프롬프트와 같은 핵심 개념 및 \"프롬프트 엔지니어링\"이라는 전체 분야도 존재한다는 것을 보셨습니다. ChatGPT, Office 365, Microsoft Power Platform 등과 같은 여러 도구들은 당신이 프롬프트를 사용하여 무언가를 달성할 수 있도록 지원합니다.\\n\\n이러한 경험을 애플리케이션에 추가하려면, 프롬프트, 완료 그리고 작업할 라이브러리를 선택하는 것과 같은 개념을 이해해야 합니다. 바로 이 장에서 이러한 내용을 배우게 될 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333306, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_057232b607', usage=CompletionUsage(completion_tokens=227, prompt_tokens=190, total_tokens=417, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcag3uGzB8bYtMVUUQb9BQLviaki', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 장에서는 다음을 학습합니다:\\n\\n- openai 라이브러리와 그 핵심 개념에 대해 배웁니다.\\n- openai를 사용하여 텍스트 생성 앱을 만듭니다.\\n- 프롬프트, 온도, 토큰과 같은 개념을 사용하여 텍스트 생성 앱을 구축하는 방법을 이해합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333314, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=80, prompt_tokens=80, total_tokens=160, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcahRV9xpZAOjW45EwaK4gwMrpQw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 수업이 끝나면, 다음을 할 수 있습니다:\\n\\n- 텍스트 생성 앱이 무엇인지 설명할 수 있습니다.\\n- openai를 사용하여 텍스트 생성 앱을 구축할 수 있습니다.\\n- 다양한 결과를 위해 토큰 사용량을 조절하고 온도를 변경하도록 앱을 구성할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333315, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=74, prompt_tokens=84, total_tokens=158, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaiKLcK0bhM22b16Y3hXSBu0KLO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 텍스트 생성 앱이란 무엇인가?\\n\\n일반적으로 앱을 구축할 때 다음과 같은 종류의 인터페이스를 갖추고 있습니다:\\n\\n- 명령 기반. 콘솔 앱은 명령을 입력하면 작업을 수행하는 일반적인 앱입니다. 예를 들어, `git`은 명령 기반 앱입니다.\\n- 사용자 인터페이스 (UI). 일부 앱은 버튼을 클릭하고, 텍스트를 입력하고, 옵션을 선택하는 등의 그래픽 사용자 인터페이스(GUI)를 가지고 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333316, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=110, prompt_tokens=114, total_tokens=224, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcakkrY89MnPEbmvEMnlmzkjss5C', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 콘솔 및 UI 앱에는 한계가 있다\\n\\n명령어 기반 앱에서 명령어를 입력하는 것과 비교해보세요:\\n\\n- **한계가 있습니다**. 모든 명령어를 입력할 수 있는 것이 아니라, 앱이 지원하는 명령어만 입력할 수 있습니다.\\n- **특정 언어에 맞춰져 있습니다**. 일부 앱은 여러 언어를 지원하지만 기본적으로 특정 언어를 위해 만들어졌고, 더 많은 언어 지원을 추가할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333318, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=108, prompt_tokens=103, total_tokens=211, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcam6gsPxHgOmpLKKQBZyIzi68bA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 텍스트 생성 앱의 이점\\n\\n그렇다면 텍스트 생성 앱은 어떻게 다를까요?\\n\\n텍스트 생성 앱에서는 더 큰 유연성을 누릴 수 있으며, 특정 명령어나 특정 입력 언어에 제한되지 않습니다. 대신 자연어를 사용하여 앱과 상호작용할 수 있습니다. 또 다른 이점은 방대한 정보 집합을 학습한 데이터 소스와 이미 상호작용하고 있기 때문에, 전통적인 앱이 데이터베이스에 있는 내용에 제한될 수 있는 반면, 텍스트 생성 앱은 더 많은 정보를 제공할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333320, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a2ff031fb5', usage=CompletionUsage(completion_tokens=128, prompt_tokens=118, total_tokens=246, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcaoqppnsfzW0zp3GyFS9odLrK1t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 텍스트 생성 애플리케이션으로 무엇을 만들 수 있나요?\\n\\n많은 것을 만들 수 있습니다. 예를 들어:\\n\\n- **챗봇**: 회사와 제품에 대한 질문에 답변하는 챗봇은 좋은 선택이 될 수 있습니다.\\n- **도우미**: 대형 언어 모델(LLMs)은 텍스트 요약, 텍스트에서 인사이트 도출, 이력서 작성 같은 텍스트 생성 작업에 매우 유용합니다.\\n- **코드 어시스턴트**: 사용하는 언어 모델에 따라 코드를 작성하는 데 도움을 주는 코드 어시스턴트를 만들 수 있습니다. 예를 들어, GitHub Copilot이나 ChatGPT와 같은 제품을 사용하여 코드를 작성하는 데 도움을 받을 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333322, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=170, prompt_tokens=154, total_tokens=324, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcavx6I9bXe98nIecAEgEOsMdIFU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 어떻게 시작할 수 있나요?\\n\\n먼저, LLM과 통합할 방법을 찾아야 합니다. 일반적으로 다음 두 가지 접근 방식을 따릅니다:\\n\\n- API 사용. 여기서는 프롬프트와 함께 웹 요청을 구성하여 생성된 텍스트를 반환받습니다.\\n- 라이브러리 사용. 라이브러리는 API 호출을 캡슐화하여 사용하기 쉽도록 도와줍니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333329, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=92, prompt_tokens=95, total_tokens=187, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcax5NJl2cdNknqIfbNEdaFGyRkg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 라이브러리/SDK\\n\\nLLM(대형 언어 모델)과 함께 작업할 때 잘 알려진 몇 가지 라이브러리가 있습니다:\\n\\n- **openai**: 이 라이브러리는 모델에 쉽게 연결하고 프롬프트를 보내는 것을 가능하게 합니다.\\n\\n그런 다음 더 높은 수준에서 작동하는 라이브러리들입니다:\\n\\n- **Langchain**: Langchain은 잘 알려져 있으며 Python을 지원합니다.\\n- **Semantic Kernel**: Semantic Kernel은 Microsoft가 제공하는 라이브러리로, C#, Python 및 Java 언어를 지원합니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333331, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=126, prompt_tokens=119, total_tokens=245, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcb16It2izX6ZxPENfsDAWrbMgUH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 첫 번째 앱 만들기 - OpenAI 사용\\n\\n우리의 첫 번째 앱을 어떻게 만들 수 있는지, 필요한 라이브러리는 무엇인지, 얼마나 많은 것이 필요한지 등을 살펴보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333335, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=42, prompt_tokens=58, total_tokens=100, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcb2OPto0t9Xw7226HgQBCSI5rL3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### OpenAI 설치\\n\\nOpenAI 또는 Azure OpenAI와 상호 작용하기 위한 많은 라이브러리가 존재합니다. C#, Python, JavaScript, Java 등 다양한 프로그래밍 언어를 사용할 수도 있습니다. 우리는 `openai` Python 라이브러리를 사용하기로 선택했으므로, `pip`을 사용하여 이를 설치하겠습니다.\\n\\n```bash\\npip install openai\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333336, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=84, prompt_tokens=102, total_tokens=186, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcb4jbIPa0bCfBMbBFVLt3cmaGMk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 리소스 생성하기\\n\\n다음 단계를 수행해야 합니다:\\n\\n- Azure에서 계정을 생성하세요 [https://azure.microsoft.com/free/](https://azure.microsoft.com/free/?WT.mc_id=academic-105485-koreyst).\\n- Azure OpenAI에 대한 액세스를 얻으세요. [https://learn.microsoft.com/azure/ai-services/openai/overview#how-do-i-get-access-to-azure-openai](https://learn.microsoft.com/azure/ai-services/openai/overview#how-do-i-get-access-to-azure-openai?WT.mc_id=academic-105485-koreyst)로 이동하여 액세스를 요청하세요.\\n\\n  > [!NOTE]\\n  > 작성 시점에서는 Azure OpenAI에 액세스하기 위해 신청해야 합니다.\\n\\n- 파이썬을 설치하세요 <https://www.python.org/>\\n- Azure OpenAI 서비스 리소스를 생성하세요. [리소스를 생성하는 방법](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal?WT.mc_id=academic-105485-koreyst)에 대한 가이드를 참고하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333338, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=239, prompt_tokens=247, total_tokens=486, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcb7qA1Q2IjOcYE1sb4ehMqvOG84', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### API 키와 엔드포인트 위치 확인\\n\\n이제 `openai` 라이브러리에 사용할 API 키를 알려줘야 합니다. API 키를 찾으려면 Azure OpenAI 리소스의 \"키 및 엔드포인트\" 섹션으로 이동하여 \"키 1\" 값을 복사하세요.\\n\\n![Azure 포털에서의 키 및 엔드포인트 리소스 블레이드](https://learn.microsoft.com/azure/ai-services/openai/media/quickstarts/endpoint.png?WT.mc_id=academic-105485-koreyst)\\n\\n이 정보를 복사했으니, 라이브러리에 이를 사용하라고 지시해 봅시다.\\n\\n> [!NOTE]\\n> API 키를 코드와 분리하는 것이 좋습니다. 환경 변수를 사용하여 이를 수행할 수 있습니다.\\n>\\n> - 환경 변수 `OPENAI_API_KEY`를 API 키로 설정하세요.\\n>   `export OPENAI_API_KEY=\\'sk-...\\'`', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333341, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=203, prompt_tokens=199, total_tokens=402, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcbAJK6fhNrNojP0ChVtDIxakxIR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Azure 설정 구성\\n\\nAzure OpenAI를 사용하는 경우 설정 구성을 다음과 같이 할 수 있습니다:\\n\\n```python\\nopenai.api_type = \\'azure\\'\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\nopenai.api_version = \\'2023-05-15\\'\\nopenai.api_base = os.getenv(\"API_BASE\")\\n```\\n\\n위의 코드는 다음을 설정하고 있습니다:\\n\\n- `api_type`을 `azure`로 설정합니다. 이는 라이브러리가 OpenAI가 아닌 Azure OpenAI를 사용하도록 지시합니다.\\n- `api_key`는 Azure 포털에서 찾을 수 있는 API 키입니다.\\n- `api_version`은 사용하려는 API의 버전입니다. 작성 시점에서 최신 버전은 `2023-05-15`입니다.\\n- `api_base`는 API의 엔드포인트입니다. Azure 포털에서 API 키 옆에 이 정보를 찾을 수 있습니다.\\n\\n> [!NOTE] > `os.getenv`는 환경 변수를 읽는 함수입니다. 이 함수를 사용하여 `OPENAI_API_KEY` 및 `API_BASE`와 같은 환경 변수를 읽을 수 있습니다. 터미널에서 또는 `dotenv`와 같은 라이브러리를 사용하여 이러한 환경 변수를 설정하십시오.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333344, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=262, prompt_tokens=257, total_tokens=519, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcbEQSesYL145MS5qNd1K93u92Yv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 텍스트 생성\\n\\n텍스트를 생성하는 방법은 `Completion` 클래스를 사용하는 것입니다. 다음은 예제입니다:\\n\\n```python\\nprompt = \"다음을 완료하십시오: 옛날 옛적에\"\\n\\ncompletion = openai.Completion.create(model=\"davinci-002\", prompt=prompt)\\nprint(completion.choices[0].text)\\n```\\n\\n위의 코드에서 우리는 completion 객체를 생성하고 사용하려는 모델과 프롬프트를 전달합니다. 그런 다음 생성된 텍스트를 출력합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333348, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_157b3831f5', usage=CompletionUsage(completion_tokens=110, prompt_tokens=128, total_tokens=238, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcbIpzdO98emhpMBBVlgkfXrTW0Z', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 채팅 완료\\n\\n지금까지 텍스트 생성을 위해 `Completion`을 사용해왔습니다. 하지만 챗봇에 더 적합한 `ChatCompletion`이라는 또 다른 클래스가 있습니다. 다음은 이를 사용하는 예제입니다:\\n\\n```python\\nimport openai\\n\\nopenai.api_key = \"sk-...\"\\n\\ncompletion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\\nprint(completion.choices[0].message.content)\\n```\\n\\n이 기능에 대해서는 다음 챕터에서 더 다루겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333352, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=130, prompt_tokens=145, total_tokens=275, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcbLfI8XWnbACH1dHqnztIgmeIKq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Exercise - your first text generation app\\n\\n이제 openai를 설정하고 구성하는 방법을 배웠으니, 첫 번째 텍스트 생성 앱을 만들어봅시다. 앱을 만들려면 다음 단계를 따르세요:\\n\\n1. 가상 환경을 생성하고 openai를 설치합니다:\\n\\n   ```bash\\n   python -m venv venv\\n   source venv/bin/activate\\n   pip install openai\\n   ```\\n\\n   > [!NOTE]\\n   > Windows를 사용하는 경우 `source venv/bin/activate` 대신 `venv\\\\Scripts\\\\activate`를 입력하세요.\\n\\n   > [!NOTE]\\n   > [https://portal.azure.com/](https://portal.azure.com/?WT.mc_id=academic-105485-koreyst)에 접속하여 `Open AI`를 검색하고 `Open AI resource`를 선택한 다음 `Keys and Endpoint`를 선택하여 `Key 1` 값을 복사합니다.\\n\\n1. _app.py_ 파일을 만들고 다음 코드를 입력합니다:\\n\\n   ```python\\n   import openai\\n\\n   openai.api_key = \"<여기에 open ai 키 또는 Azure OpenAI 키를 입력하세요>\"\\n\\n   openai.api_type = \\'azure\\'\\n   openai.api_version = \\'2023-05-15\\'\\n   openai.api_base = \"<Azure Portal에서 API 키가 있는 엔드포인트>\"\\n   deployment_name = \"<배포 이름>\"\\n\\n   # 텍스트 완성 코드 추가\\n   prompt = \"다음을 완료하세요: 옛날 옛적에\"\\n   messages = [{\"role\": \"user\", \"content\": prompt}]\\n\\n   # 텍스트 완성 요청\\n   completion = openai.ChatCompletion.create(model=deployment_name, messages=messages)\\n\\n   # 응답 출력\\n   print(completion.choices[0].message[\\'content\\'])\\n   ```\\n\\n   > [!NOTE]\\n   > Azure OpenAI를 사용하는 경우, `api_type`을 `azure`로 설정하고 `api_key`를 Azure OpenAI 키로 설정해야 합니다.\\n\\n   다음과 같은 출력이 표시됩니다:\\n\\n   ```output\\n    매우 불행한 _____.\\n\\n   옛날 옛적에 매우 불행한 인어가 있었습니다.\\n   ```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333355, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=468, prompt_tokens=471, total_tokens=939, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcbPqPvRTt3xPH7RZ8ADc3oXOttB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"## 다양한 종류의 프롬프트, 다양한 용도\\n\\n이제 프롬프트를 사용하여 텍스트를 생성하는 방법을 보았습니다. 다른 종류의 텍스트를 생성할 수 있도록 수정하고 변경할 수 있는 프로그램도 실행하고 있습니다.\\n\\n프롬프트는 다양한 작업에 사용할 수 있습니다. 예를 들어:\\n\\n- **특정 유형의 텍스트 생성**. 예를 들어, 시를 생성하거나 퀴즈의 질문을 생성하는 등의 작업을 할 수 있습니다.\\n- **정보 검색**. '웹 개발에서 CORS는 무엇을 의미합니까?'와 같은 정보를 검색하는 프롬프트를 사용할 수 있습니다.\\n- **코드 생성**. 이메일 유효성을 검사하는 정규 표현식을 개발하는 것부터 전체 프로그램(웹 앱과 같은)을 생성하는 것까지 코드 생성을 위한 프롬프트를 사용할 수 있습니다.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333359, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=187, prompt_tokens=174, total_tokens=361, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcbTgrIVisSnOc5tun8O4UBNwDV5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 더 실용적인 사용 사례: 레시피 생성기\\n\\n집에 있는 재료를 가지고 요리를 하고 싶다고 상상해보세요. 이를 위해 레시피가 필요합니다. 레시피를 찾는 한 가지 방법은 검색 엔진을 사용하는 것이고, 또 다른 방법은 LLM을 사용하는 것입니다.\\n\\n다음과 같은 프롬프트를 작성할 수 있습니다:\\n\\n> \"치킨, 감자, 당근을 사용하는 요리의 레시피 5개를 보여줘. 각 레시피마다 사용된 모든 재료를 나열해줘\"\\n\\n위의 프롬프트를 통해 다음과 같은 응답을 받을 수 있습니다:\\n\\n```output\\n1. 구운 치킨과 채소:\\n재료:\\n- 닭다리 4개\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 올리브유 2 큰술\\n- 마늘 2쪽, 다진 것\\n- 말린 타임 1 작은술\\n- 말린 오레가노 1 작은술\\n- 소금과 후추, 기호에 따라\\n\\n2. 치킨 감자 스튜:\\n재료:\\n- 올리브유 2 큰술\\n- 양파 1개, 다진 것\\n- 마늘 2쪽, 다진 것\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 말린 오레가노 1 작은술\\n- 말린 타임 1 작은술\\n- 닭 육수 1컵\\n- 소금과 후추, 기호에 따라\\n\\n3. 치킨 감자 베이크:\\n재료:\\n- 올리브유 2 큰술\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 양파 1개, 다진 것\\n- 마늘 2쪽, 다진 것\\n- 말린 오레가노 1 작은술\\n- 말린 타임 1 작은술\\n- 닭 육수 1컵\\n- 소금과 후추, 기호에 따라\\n\\n4. 치킨 감자 수프:\\n재료:\\n- 올리브유 2 큰술\\n- 양파 1개, 다진 것\\n- 마늘 2쪽, 다진 것\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 말린 오레가노 1 작은술\\n- 말린 타임 1 작은술\\n- 닭 육수 4컵\\n- 소금과 후추, 기호에 따라\\n\\n5. 치킨 감자 해시:\\n재료:\\n- 올리브유 2 큰술\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 양파 1개, 다진 것\\n- 마늘 2쪽, 다진 것\\n- 말린 오레가노 1 작은술\\n```\\n\\n이 결과는 훌륭합니다. 이제 무엇을 요리해야 하는지 알 수 있습니다. 이 시점에서 유용한 개선 사항은 다음과 같습니다:\\n\\n- 싫어하거나 알레르기가 있는 재료는 걸러내기.\\n- 집에 없는 재료를 구매할 수 있도록 쇼핑 목록 작성하기.\\n\\n위의 경우에 대해 추가 프롬프트를 추가해 봅시다:\\n\\n> \"마늘에 알레르기가 있으니 마늘을 제외한 레시피로 대체해줘. 또한, 집에 치킨, 감자, 당근이 있다고 가정하고 쇼핑 목록을 작성해줘.\"\\n\\n이제 새로운 결과를 받을 수 있습니다:\\n\\n```output\\n1. 구운 치킨과 채소:\\n재료:\\n- 닭다리 4개\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 올리브유 2 큰술\\n- 말린 타임 1 작은술\\n- 말린 오레가노 1 작은술\\n- 소금과 후추, 기호에 따라\\n\\n2. 치킨 감자 스튜:\\n재료:\\n- 올리브유 2 큰술\\n- 양파 1개, 다진 것\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 말린 오레가노 1 작은술\\n- 말린 타임 1 작은술\\n- 닭 육수 1컵\\n- 소금과 후추, 기호에 따라\\n\\n3. 치킨 감자 베이크:\\n재료:\\n- 올리브유 2 큰술\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 양파 1개, 다진 것\\n- 말린 오레가노 1 작은술\\n- 말린 타임 1 작은술\\n- 닭 육수 1컵\\n- 소금과 후추, 기호에 따라\\n\\n4. 치킨 감자 수프:\\n재료:\\n- 올리브유 2 큰술\\n- 양파 1개, 다진 것\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 말린 오레가노 1 작은술\\n- 말린 타임 1 작은술\\n- 닭 육수 4컵\\n- 소금과 후추, 기호에 따라\\n\\n5. 치킨 감자 해시:\\n재료:\\n- 올리브유 2 큰술\\n- 닭가슴살 2개, 깍둑썰기\\n- 감자 2개, 깍둑썰기\\n- 당근 2개, 깍둑썰기\\n- 양파 1개, 다진 것\\n- 말린 오레가노 1 작은술\\n\\n쇼핑 목록:\\n- 올리브유\\n- 양파\\n- 타임\\n- 오레가노\\n- 소금\\n- 후추\\n```\\n\\n이렇게 하면 마늘이 없는 다섯 가지 레시피를 얻을 수 있고, 집에 이미 있는 재료를 고려한 쇼핑 목록도 포함됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333363, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=1544, prompt_tokens=1069, total_tokens=2613, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcbmOAZ88UiHtTIgCUCk4fJHQ1TR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Exercise - 레시피 생성기 만들기\\n\\n이제 시나리오를 실행해 보았으니, 시나리오에 맞는 코드를 작성해 봅시다. 다음 단계를 따르세요:\\n\\n1. 기존의 _app.py_ 파일을 시작점으로 사용합니다.\\n1. `prompt` 변수를 찾아 다음 코드로 변경합니다:\\n\\n   ```python\\n   prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\\n   ```\\n\\n   이 코드를 실행하면 다음과 유사한 출력을 확인할 수 있습니다:\\n\\n   ```output\\n   -Chicken Stew with Potatoes and Carrots: 3 tablespoons oil, 1 onion, chopped, 2 cloves garlic, minced, 1 carrot, peeled and chopped, 1 potato, peeled and chopped, 1 bay leaf, 1 thyme sprig, 1/2 teaspoon salt, 1/4 teaspoon black pepper, 1 1/2 cups chicken broth, 1/2 cup dry white wine, 2 tablespoons chopped fresh parsley, 2 tablespoons unsalted butter, 1 1/2 pounds boneless, skinless chicken thighs, cut into 1-inch pieces\\n   -Oven-Roasted Chicken with Potatoes and Carrots: 3 tablespoons extra-virgin olive oil, 1 tablespoon Dijon mustard, 1 tablespoon chopped fresh rosemary, 1 tablespoon chopped fresh thyme, 4 cloves garlic, minced, 1 1/2 pounds small red potatoes, quartered, 1 1/2 pounds carrots, quartered lengthwise, 1/2 teaspoon salt, 1/4 teaspoon black pepper, 1 (4-pound) whole chicken\\n   -Chicken, Potato, and Carrot Casserole: cooking spray, 1 large onion, chopped, 2 cloves garlic, minced, 1 carrot, peeled and shredded, 1 potato, peeled and shredded, 1/2 teaspoon dried thyme leaves, 1/4 teaspoon salt, 1/4 teaspoon black pepper, 2 cups fat-free, low-sodium chicken broth, 1 cup frozen peas, 1/4 cup all-purpose flour, 1 cup 2% reduced-fat milk, 1/4 cup grated Parmesan cheese\\n\\n   -One Pot Chicken and Potato Dinner: 2 tablespoons olive oil, 1 pound boneless, skinless chicken thighs, cut into 1-inch pieces, 1 large onion, chopped, 3 cloves garlic, minced, 1 carrot, peeled and chopped, 1 potato, peeled and chopped, 1 bay leaf, 1 thyme sprig, 1/2 teaspoon salt, 1/4 teaspoon black pepper, 2 cups chicken broth, 1/2 cup dry white wine\\n\\n   -Chicken, Potato, and Carrot Curry: 1 tablespoon vegetable oil, 1 large onion, chopped, 2 cloves garlic, minced, 1 carrot, peeled and chopped, 1 potato, peeled and chopped, 1 teaspoon ground coriander, 1 teaspoon ground cumin, 1/2 teaspoon ground turmeric, 1/2 teaspoon ground ginger, 1/4 teaspoon cayenne pepper, 2 cups chicken broth, 1/2 cup dry white wine, 1 (15-ounce) can chickpeas, drained and rinsed, 1/2 cup raisins, 1/2 cup chopped fresh cilantro\\n   ```\\n\\n   > 주의: LLM은 비결정적이므로 프로그램을 실행할 때마다 다른 결과가 나올 수 있습니다.\\n\\n   좋아요, 이제 어떻게 개선할 수 있는지 봅시다. 개선하기 위해 코드를 유연하게 만들어, 재료와 레시피 수를 쉽게 변경할 수 있도록 합시다.\\n\\n1. 코드를 다음과 같이 변경합니다:\\n\\n   ```python\\n   no_recipes = input(\"레시피 수 (예: 5): \")\\n\\n   ingredients = input(\"재료 목록 (예: chicken, potatoes, and carrots): \")\\n\\n   # 레시피 수와 재료를 프롬프트에 삽입\\n   prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\\n   ```\\n\\n   코드를 테스트 실행하면 다음과 같이 나타날 수 있습니다:\\n\\n   ```output\\n   레시피 수 (예: 5): 3\\n   재료 목록 (예: chicken, potatoes, and carrots): milk,strawberries\\n\\n   -Strawberry milk shake: milk, strawberries, sugar, vanilla extract, ice cubes\\n   -Strawberry shortcake: milk, flour, baking powder, sugar, salt, unsalted butter, strawberries, whipped cream\\n   -Strawberry milk: milk, strawberries, sugar, vanilla extract\\n   ```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333382, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=1019, prompt_tokens=1021, total_tokens=2040, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcc0JwN73AQKhX1bDgVtq4KLIQC7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 필터 및 쇼핑 리스트 추가하여 개선하기\\n\\n현재 저희는 레시피를 생성할 수 있는 작동 앱을 가지고 있으며, 사용자로부터 입력을 받아 유연하게 작동합니다. 여기엔 레시피 수뿐만 아니라 사용되는 재료도 포함됩니다.\\n\\n이를 더욱 개선하기 위해 다음을 추가하고자 합니다:\\n\\n- **재료 필터링**. 좋아하지 않거나 알레르기가 있는 재료를 필터링할 수 있기를 원합니다. 이 변경을 달성하기 위해 기존 프롬프트를 편집하고 끝에 필터 조건을 추가할 수 있습니다:\\n\\n  ```python\\n  filter = input(\"필터 (예: 채식, 비건, 또는 글루텐 프리): \")\\n\\n  prompt = f\"다음 재료를 사용한 요리의 레시피 {no_recipes} 개를 보여주세요: {ingredients}. 각 레시피마다 사용된 모든 재료를 나열하고, {filter} 제외\"\\n  ```\\n\\n  위에서 우리는 프롬프트 끝에 `{filter}`를 추가하고 사용자로부터 필터 값을 캡처합니다.\\n\\n  프로그램을 실행했을 때의 예제 입력은 다음과 같이 보일 수 있습니다:\\n\\n  ```output\\n  레시피 수 (예: 5): 3\\n  재료 목록 (예: 치킨, 감자, 당근): 양파, 우유\\n  필터 (예: 채식, 비건, 또는 글루텐 프리): 우유 없음\\n\\n  1. 프렌치 어니언 수프\\n\\n  재료:\\n\\n  - 큰 양파 1개, 슬라이스\\n  - 비프 브로스 3컵\\n  - 우유 1컵\\n  - 프렌치 브레드 6조각\\n  - 파마산 치즈 1/4컵\\n  - 버터 1큰술\\n  - 타임 1티스푼\\n  - 소금 1/4티스푼\\n  - 블랙 페퍼 1/4티스푼\\n\\n  조리 방법:\\n\\n  1. 큰 냄비에서 양파를 버터에 황금빛이 될 때까지 볶습니다.\\n  2. 비프 브로스, 우유, 타임, 소금, 후추를 추가하고 끓입니다.\\n  3. 열을 줄이고 10분 동안 끓입니다.\\n  4. 수프 볼에 프렌치 빵 조각을 놓습니다.\\n  5. 수프를 빵 위에 붓습니다.\\n  6. 파마산 치즈를 뿌립니다.\\n\\n  2. 양파와 감자 수프\\n\\n  재료:\\n\\n  - 큰 양파 1개, 다진 것\\n  - 감자 2컵, 다진 것\\n  - 야채 브로스 3컵\\n  - 우유 1컵\\n  - 블랙 페퍼 1/4티스푼\\n\\n  조리 방법:\\n\\n  1. 큰 냄비에서 양파를 버터에 황금빛이 될 때까지 볶습니다.\\n  2. 감자, 야채 브로스, 우유, 후추를 추가하고 끓입니다.\\n  3. 열을 줄이고 10분 동안 끓입니다.\\n  4. 뜨겁게 서빙합니다.\\n\\n  3. 크리미 어니언 수프\\n\\n  재료:\\n\\n  - 큰 양파 1개, 다진 것\\n  - 야채 브로스 3컵\\n  - 우유 1컵\\n  - 블랙 페퍼 1/4티스푼\\n  - 밀가루 1/4컵\\n  - 파마산 치즈 1/2컵\\n\\n  조리 방법:\\n\\n  1. 큰 냄비에서 양파를 버터에 황금빛이 될 때까지 볶습니다.\\n  2. 야채 브로스, 우유, 후추를 추가하고 끓입니다.\\n  3. 열을 줄이고 10분 동안 끓입니다.\\n  4. 작은 볼에서 밀가루와 파마산 치즈를 함께 휘저어 부드럽게 만듭니다.\\n  5. 수프에 추가하고 수프가 걸쭉해질 때까지 추가로 5분 더 끓입니다.\\n  ```\\n\\n  위에서 보시다시피 우유가 포함된 모든 레시피가 필터링되었습니다. 하지만, 유당불내증이 있다면 치즈가 포함된 레시피도 필터링하고 싶을 수 있으므로 명확히 할 필요가 있습니다.\\n\\n- **장보기 목록 생성**. 우리는 이미 집에 있는 것들을 고려하여 장보기 목록을 생성하고자 합니다.\\n\\n  이 기능을 위해 모든 것을 하나의 프롬프트로 해결하거나 두 개의 프롬프트로 나눌 수 있습니다. 후자의 접근 방식을 시도해 보겠습니다. 여기서 추가 프롬프트를 추가할 것을 제안하지만, 이를 위해 첫 번째 프롬프트의 결과를 두 번째 프롬프트의 컨텍스트로 추가해야 합니다.\\n\\n  코드에서 첫 번째 프롬프트의 결과를 출력하는 부분을 찾아 다음 코드를 아래에 추가합니다:\\n\\n  ```python\\n  old_prompt_result = completion.choices[0].message.content\\n  prompt = \"생성된 레시피에 대한 장보기 목록을 작성하고 이미 내가 가지고 있는 재료는 포함하지 마세요.\"\\n\\n  new_prompt = f\"{old_prompt_result} {prompt}\"\\n  messages = [{\"role\": \"user\", \"content\": new_prompt}]\\n  completion = openai.Completion.create(engine=deployment_name, messages=messages, max_tokens=1200)\\n\\n  # 응답을 출력합니다.\\n  print(\"장보기 목록:\")\\n  print(completion.choices[0].message.content)\\n  ```\\n\\n  다음 사항을 유의하세요:\\n\\n  1. 첫 번째 프롬프트의 결과를 새로운 프롬프트에 추가하여 새 프롬프트를 생성합니다:\\n\\n     ```python\\n     new_prompt = f\"{old_prompt_result} {prompt}\"\\n     ```\\n\\n  2. 새로운 요청을 생성하되, 첫 번째 프롬프트에서 요청한 토큰 수를 고려하여 이번에는 `max_tokens`을 1200으로 설정합니다.\\n\\n     ```python\\n     completion = openai.Completion.create(engine=deployment_name, prompt=new_prompt, max_tokens=1200)\\n     ```\\n\\n     그러면 다음과 같이 출력됩니다:\\n\\n     ```output\\n     No of recipes (for example, 5: 2\\n     List of ingredients (for example, chicken, potatoes, and carrots: apple,flour\\n     Filter (for example, vegetarian, vegan, or gluten-free: sugar\\n\\n     -Apple and flour pancakes: 1 cup flour, 1/2 tsp baking powder, 1/2 tsp baking soda, 1/4 tsp salt, 1 tbsp sugar, 1 egg, 1 cup buttermilk or sour milk, 1/4 cup melted butter, 1 Granny Smith apple, peeled and grated\\n     -Apple fritters: 1-1/2 cups flour, 1 tsp baking powder, 1/4 tsp salt, 1/4 tsp baking soda, 1/4 tsp nutmeg, 1/4 tsp cinnamon, 1/4 tsp allspice, 1/4 cup sugar, 1/4 cup vegetable shortening, 1/4 cup milk, 1 egg, 2 cups shredded, peeled apples\\n     장보기 목록:\\n     - 밀가루, 베이킹파우더, 베이킹소다, 소금, 설탕, 계란, 버터밀크, 버터, 사과, 육두구, 계피, 올스파이스\\n     ```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333396, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=1691, prompt_tokens=1385, total_tokens=3076, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccLDczfGZsLUkLe8WCfIBvcvfnU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 설정 개선하기\\n\\n현재까지 작성한 코드는 작동하지만, 더 나은 결과를 위해 몇 가지 조정을 해야 합니다. 우리가 해야 할 몇 가지 작업은 다음과 같습니다:\\n\\n- **비밀 정보를 코드와 분리하기**, 예를 들어 API 키. 비밀 정보는 코드에 포함되어서는 안 되며, 안전한 위치에 저장되어야 합니다. 비밀 정보를 코드와 분리하려면, 환경 변수를 사용하고 `python-dotenv`과 같은 라이브러리를 사용하여 파일에서 로드할 수 있습니다. 코드에서는 다음과 같이 설정할 수 있습니다:\\n\\n  1. `.env` 파일을 다음 내용으로 생성하세요:\\n\\n     ```bash\\n     OPENAI_API_KEY=sk-...\\n     ```\\n\\n     > 참고로 Azure의 경우 다음 환경 변수를 설정해야 합니다:\\n\\n     ```bash\\n     OPENAI_API_TYPE=azure\\n     OPENAI_API_VERSION=2023-05-15\\n     OPENAI_API_BASE=<replace>\\n     ```\\n\\n     코드에서는 환경 변수를 다음과 같이 로드할 수 있습니다:\\n\\n     ```python\\n     from dotenv import load_dotenv\\n     import os\\n\\n     load_dotenv()\\n\\n     openai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n     ```\\n\\n- **토큰 길이에 대한 한 마디**. 필요한 텍스트를 생성하기 위해 몇 개의 토큰이 필요한지 고려해야 합니다. 토큰은 비용이 들기 때문에, 가능한 한 사용되는 토큰 수를 절약할 수 있도록 노력해야 합니다. 예를 들어, 프롬프트를 어떻게 표현하여 적은 토큰을 사용할 수 있을지 고민해 볼 수 있습니다.\\n\\n  사용되는 토큰 수를 변경하려면 `max_tokens` 매개변수를 사용할 수 있습니다. 예를 들어, 100개의 토큰을 사용하고 싶다면 다음과 같이 작성할 수 있습니다:\\n\\n  ```python\\n  completion = client.chat.completions.create(model=deployment, messages=messages, max_tokens=100)\\n  ```\\n\\n- **온도 조절 실험하기**. 온도는 우리 프로그램의 성능에 중요한 영향을 미치는 요소입니다. 온도 값이 높을수록 출력이 더 무작위성이 커지고, 반대로 온도 값이 낮을수록 출력이 더 예측 가능해집니다. 출력에 변화를 원하는지 고려해 보세요.\\n\\n  온도를 변경하려면 `temperature` 매개변수를 사용할 수 있습니다. 예를 들어, 온도를 0.5로 사용하고 싶다면 다음과 같이 작성할 수 있습니다:\\n\\n  ```python\\n  completion = client.chat.completions.create(model=deployment, messages=messages, temperature=0.5)\\n  ```\\n\\n  > 참고, 1.0에 가까울수록 출력이 다양해집니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333417, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=583, prompt_tokens=528, total_tokens=1111, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccPVAltQdaK24v199Uesa6LcsAI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n이 과제에서는 무엇을 만들지 자유롭게 선택할 수 있습니다.\\n\\n여기에 몇 가지 제안을 드립니다:\\n\\n- 레시피 생성기 앱을 더 개선해보세요. 온도 값을 조정하고 프롬프트를 실험하여 개선해보세요.\\n- \"공부 친구\"를 만들어보세요. 이 앱은 Python와 같은 특정 주제에 대해 질문에 답할 수 있어야 합니다. 예를 들어 \"Python의 특정 주제는 무엇입니까?\"와 같은 프롬프트를 사용할 수 있고, 또는 \"특정 주제에 대한 코드를 보여줘\"와 같은 프롬프트를 적용할 수도 있습니다.\\n- 역사 봇: 역사를 생생하게 만들고, 특정 역사적 인물 역할을 수행하도록 봇에게 지시한 후 그 인물의 삶과 시대에 대해 질문해보세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333421, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=185, prompt_tokens=159, total_tokens=344, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccSYUZosDmfg050MVMFqlEHTv8F', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 해결책', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333424, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=3, prompt_tokens=31, total_tokens=34, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccTIsbXOa5JOdwRhZcxCBYtNj9l', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 학습 친구\\n\\n아래는 시작용 프롬프트입니다. 어떻게 사용하고 원하는 형태로 조정할 수 있는지 확인해 보세요.\\n\\n```text\\n- \"당신은 파이썬 언어의 전문가입니다.\\n\\n    다음 형식으로 파이썬 초급 레슨을 제안해 주세요:\\n\\n    형식:\\n    - 개념:\\n    - 레슨의 간략한 설명:\\n    - 코드와 함께 연습 문제 및 해답:\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333425, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=102, prompt_tokens=101, total_tokens=203, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccW9aUMG0EyJAZGupWoLfkNnQZb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 역사 봇\\n\\n다음은 사용할 수 있는 몇 가지 프롬프트입니다:\\n\\n```text\\n- \"당신은 에이브러햄 링컨입니다. 세 문장으로 자신에 대해 말해 주세요. 그리고 링컨이 사용했을 법한 문법과 단어를 사용해 주세요.\"\\n- \"당신은 에이브러햄 링컨입니다. 링컨이 사용했을 법한 문법과 단어를 사용해 다음 질문에 답해 주세요:\\n\\n   300 단어로 자신의 가장 큰 업적에 대해 말해 주세요.\"\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333428, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=123, prompt_tokens=105, total_tokens=228, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccZlci1uMjPpyyxMNJGUWzIh6Bx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 점검\\n\\n온도(temperature) 개념은 무엇을 하나요?\\n\\n1. 출력의 무작위성을 조절합니다.\\n2. 응답의 크기를 조절합니다.\\n3. 사용되는 토큰의 수를 조절합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333431, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=55, prompt_tokens=69, total_tokens=124, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccab5o5TROWXirYaR0lYTHnHWcE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 🚀 도전\\n\\n과제를 진행할 때 온도를 다양하게 설정해보세요. 설정 값으로 0, 0.5, 1을 시도해 보세요. 0은 가장 변동이 적고 1은 가장 변동이 큽니다. 어떤 값이 여러분의 앱에 가장 적합한지 확인해보세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333432, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=77, prompt_tokens=84, total_tokens=161, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccb3iN9AWkp1mIm4W9Mf0o4YFIy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업입니다! 학습을 계속하세요\\n\\n이번 수업을 마친 후, 우리 [Generative AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 Generative AI 지식을 계속해서 향상시키세요!\\n\\nLesson 7로 이동하여 [채팅 애플리케이션 빌드하기](../07-building-chat-applications/README.md?WT.mc_id=academic-105485-koreyst)를 알아보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333433, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=114, prompt_tokens=122, total_tokens=236, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccdPyIYI4gClIM2OR0cUPja3uoY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\nAI 에이전트는 Generative AI의 흥미로운 발전을 나타내며, 대형 언어 모델(LLM)이 단순한 보조 역할에서 벗어나 행동을 취할 수 있는 에이전트로 진화하도록 합니다. AI 에이전트 프레임워크는 개발자가 LLM에 도구와 상태 관리를 제공하는 애플리케이션을 만들 수 있게 하며, 에이전트의 투명성을 높여 사용자와 개발자가 LLM이 계획한 행동을 모니터링할 수 있게 합니다. 이는 경험 관리를 개선하는 데 도움을 줍니다.\\n\\n이번 강의에서는 다음 영역을 다룰 것입니다:\\n\\n- AI 에이전트란 무엇인가 - AI 에이전트의 정의\\n- 네 가지 다른 AI 에이전트 프레임워크 탐구 - 각 프레임워크의 특이점\\n- 다양한 사용 사례에 AI 에이전트 적용 - AI 에이전트를 언제 활용할 수 있을까?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333435, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=216, prompt_tokens=160, total_tokens=376, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccgEg56Bw9OvGxinnNgQr7a4CW2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 수업을 마친 후, 여러분은 다음을 할 수 있습니다:\\n\\n- AI 에이전트가 무엇인지와 그것이 어떻게 사용될 수 있는지 설명할 수 있습니다.\\n- 인기 있는 AI 에이전트 프레임워크들 사이의 차이점을 이해하고, 그들이 어떻게 다른지 파악할 수 있습니다.\\n- AI 에이전트가 어떻게 작동하는지 이해하여 그것들을 이용한 애플리케이션을 구축할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333438, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=105, prompt_tokens=91, total_tokens=196, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccipfuJNK9WCT1qxcwPdUXMROST', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## AI 에이전트란 무엇인가?\\n\\nAI 에이전트는 생성 AI의 세계에서 매우 흥미로운 분야입니다. 이 흥미와 함께 용어 및 그 적용에 대한 혼란이 종종 따릅니다. 대부분의 AI 에이전트를 참조하는 도구를 포괄하면서 간단하게 유지하기 위해, 우리는 다음과 같은 정의를 사용하겠습니다:\\n\\nAI 에이전트는 **상태**와 **도구**에 접근하여 대규모 언어 모델(LLM)이 작업을 수행할 수 있게 합니다.\\n\\n![에이전트 모델](images/what-agent.png?WT.mc_id=academic-105485-koreyst)\\n\\n이 용어들을 정의해 보겠습니다:\\n\\n**대규모 언어 모델** - 이들은 GPT-3.5, GPT-4, Llama-2 등 이 과정에서 참조되는 모델들입니다.\\n\\n**상태** - 이는 LLM이 작업 중인 컨텍스트를 의미합니다. LLM은 과거 행동의 컨텍스트와 현재 컨텍스트를 사용하여 후속 행동에 대한 의사 결정을 안내합니다. AI 에이전트 프레임워크는 개발자가 이 컨텍스트를 더 쉽게 유지할 수 있게 합니다.\\n\\n**도구** - 사용자가 요청한 작업을 완료하고 LLM이 계획한 작업을 수행하기 위해, LLM은 도구에 접근할 필요가 있습니다. 도구의 예로는 데이터베이스, API, 외부 애플리케이션 또는 또 다른 LLM이 될 수 있습니다!\\n\\n이 정의는 향후 구현 방법을 살펴볼 때 좋은 기초가 되기를 바랍니다. 몇 가지 다른 AI 에이전트 프레임워크를 탐구해 보겠습니다:\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333440, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=369, prompt_tokens=306, total_tokens=675, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccogOFIY9cULgNCwfW2oar7zWwQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## LangChain 에이전트\\n\\n[LangChain 에이전트](https://python.langchain.com/docs/modules/agents/?WT.mc_id=academic-105485-koreyst)는 우리가 위에서 제공한 정의의 구현입니다.\\n\\n**상태**를 관리하기 위해 `AgentExecutor`라는 내장 함수를 사용합니다. 이는 정의된 `에이전트`와 사용 가능한 `도구`를 받아들입니다.\\n\\n`Agent Executor`는 채팅 기록도 저장하여 채팅의 맥락을 제공합니다.\\n\\n![Langchain Agents](images/langchain-agents.png?WT.mc_id=academic-105485-koreyst)\\n\\nLangChain은 LLM이 접근할 수 있는 [도구 카탈로그](https://integrations.langchain.com/tools?WT.mc_id=academic-105485-koreyst)를 제공합니다. 이 도구들은 커뮤니티와 LangChain 팀이 제작한 것입니다.\\n\\n이러한 도구를 정의한 후 `Agent Executor`에 전달할 수 있습니다.\\n\\nAI 에이전트에 대해 이야기할 때 가시성도 중요한 측면입니다. 애플리케이션 개발자가 LLM이 어떤 도구를 사용하고 왜 사용하는지 이해하는 것이 중요합니다. 이를 위해 LangChain 팀은 LangSmith를 개발했습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333446, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=264, prompt_tokens=267, total_tokens=531, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccrqBJU7xvTnAht187VGs5W2cFT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## AutoGen\\n\\n다음으로 논의할 AI 에이전트 프레임워크는 [AutoGen](https://microsoft.github.io/autogen/?WT.mc_id=academic-105485-koreyst)입니다. AutoGen의 주요 초점은 대화입니다. 에이전트는 **대화 가능**하고 **맞춤화 가능**합니다.\\n\\n**대화 가능 -** LLM(대규모 언어 모델)은 다른 LLM과의 대화를 시작하고 지속할 수 있어서 작업을 완료할 수 있습니다. 이는 `AssistantAgents`를 생성하고 그들에게 특정 시스템 메시지를 제공함으로써 이루어집니다.\\n\\n```python\\nautogen.AssistantAgent( name=\"Coder\", llm_config=llm_config, ) \\npm = autogen.AssistantAgent( name=\"Product_manager\", system_message=\"Creative in software product ideas.\", llm_config=llm_config, )\\n```\\n\\n**맞춤화 가능** - 에이전트는 LLM뿐만 아니라 사용자 또는 도구로 정의될 수 있습니다. 개발자로서 사용자 피드백을 통해 작업을 완료하는 `UserProxyAgent`를 정의할 수 있습니다. 이 피드백은 작업의 실행을 계속하거나 멈출 수 있습니다.\\n\\n```python\\nuser_proxy = UserProxyAgent(name=\"user_proxy\")\\n```\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333449, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c047b7b4ec', usage=CompletionUsage(completion_tokens=276, prompt_tokens=267, total_tokens=543, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccuKMgHwjrSuUPNXSkRlhgiVAjY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 상태 및 도구\\n\\n상태를 변경하고 관리하기 위해, 보조 에이전트는 작업을 완료하기 위해 Python 코드를 생성합니다.\\n\\n여기 예시가 있습니다:\\n\\n![AutoGen](images/autogen.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333452, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=61, prompt_tokens=79, total_tokens=140, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccvu6YndxyNLcZqQ6RZE4UFc2TG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### 시스템 메시지가 포함된 LLM 정의\\n\\n```python\\nsystem_message=\"날씨 관련 작업의 경우, 제공된 함수만 사용하십시오. 작업이 완료되면 TERMINATE로 응답하십시오.\"\\n```\\n\\n이 시스템 메시지는 특정 LLM에게 해당 작업에 관련된 함수가 무엇인지 지시합니다. AutoGen을 사용하면 서로 다른 시스템 메시지를 가진 여러 AssistantAgents를 정의할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333453, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=85, prompt_tokens=103, total_tokens=188, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccxfhkRBGRbfegYYf5NlS4ouP34', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### 사용자가 대화를 시작함\\n\\n```python\\nuser_proxy.initiate_chat( chatbot, message=\"다음 주에 뉴욕시로 여행을 갈 계획입니다. 무엇을 입을지 도와줄 수 있나요?\", )\\n```\\n\\n이 메시지는 user_proxy(인간)로부터 온 것이며, 이는 에이전트가 실행해야 할 가능한 기능을 탐색하는 과정을 시작할 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333455, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=87, prompt_tokens=102, total_tokens=189, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABccySuB5TK3Us5cAG5B2jyiYYPmJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### 함수가 실행됨\\n\\n```bash\\nchatbot (to user_proxy):\\n\\n***** 제안된 도구 호출: get_weather ***** 인수: {\"location\":\"New York City, NY\",\"time_period:\"7\",\"temperature_unit\":\"Celsius\"} ******************************************************** --------------------------------------------------------------------------------\\n\\n>>>>>>>> 함수 get_weather 실행 중... user_proxy (to chatbot): ***** 함수 \"get_weather\" 호출에 대한 응답 ***** 112.22727272727272 EUR ****************************************************************\\n\\n```\\n\\n초기 채팅이 처리되면 에이전트는 호출할 제안된 도구를 보낼 것입니다. 이 경우, `get_weather`라는 함수입니다. 구성에 따라 이 함수는 에이전트가 자동으로 실행하고 읽을 수 있거나 사용자 입력에 따라 실행될 수 있습니다.\\n\\n시작하는 방법을 더 탐색하려면 [AutoGen 코드 샘플](https://microsoft.github.io/autogen/docs/Examples/?WT.mc_id=academic-105485-koreyst) 목록을 찾을 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333456, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=205, prompt_tokens=216, total_tokens=421, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcd2JH3ubD7S3ZG0eZFVTMBSsHYn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Taskweaver\\n\\n다음으로 탐구할 에이전트 프레임워크는 [Taskweaver](https://microsoft.github.io/TaskWeaver/?WT.mc_id=academic-105485-koreyst)입니다. Taskweaver는 \"코드 우선\" 에이전트로 알려져 있는데, 이는 `문자열`과 엄격하게 작업하는 대신 Python에서 DataFrame과 함께 작업할 수 있기 때문입니다. 이것은 데이터 분석 및 생성 작업에서 매우 유용합니다. 예를 들어 그래프나 차트를 생성하거나 무작위 숫자를 생성하는 것과 같은 작업이 포함될 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333460, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=135, prompt_tokens=123, total_tokens=258, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcd50r3YDdbhBFwMmTpeCCGTv3wB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 상태와 도구\\n\\n대화의 상태를 관리하기 위해 TaskWeaver는 `Planner`라는 개념을 사용합니다. `Planner`는 사용자의 요청을 받아들여 이 요청을 충족하기 위해 수행해야 할 작업을 계획하는 LLM입니다.\\n\\n작업을 완료하기 위해 `Planner`는 `Plugins`라는 도구 컬렉션에 접근합니다. 이는 파이썬 클래스 또는 일반 코드 인터프리터일 수 있습니다. 이러한 플러그인은 내장이 되어 있어 LLM이 올바른 플러그인을 더 잘 검색할 수 있습니다.\\n\\n![Taskweaver](images/taskweaver.png?WT.mc_id=academic-105485-koreyst)\\n\\n다음은 이상 감지를 처리하기 위한 플러그인 예제입니다:\\n\\n```python\\nclass AnomalyDetectionPlugin(Plugin): def __call__(self, df: pd.DataFrame, time_col_name: str, value_col_name: str):\\n```\\n\\n코드는 실행 전에 검증됩니다. Taskweaver에서 컨텍스트를 관리하는 또 다른 기능은 `experience`입니다. 경험은 대화의 컨텍스트를 장기적으로 YAML 파일에 저장할 수 있게 해줍니다. 이를 구성하면 LLM이 이전 대화에 노출되므로 특정 작업에서 시간이 지남에 따라 개선될 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333463, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=278, prompt_tokens=268, total_tokens=546, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdFRxwR1Flxv6VPWACpIxTpvOGl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## JARVIS\\n\\n마지막으로 탐구할 에이전트 프레임워크는 [JARVIS](https://github.com/microsoft/JARVIS?tab=readme-ov-file?WT.mc_id=academic-105485-koreyst)입니다. JARVIS의 독특한 점은 대화의 `상태(state)`를 관리하는 데 LLM을 사용하고, `도구(tool)`는 다른 AI 모델들이라는 것입니다. 각 AI 모델들은 객체 감지, 전사, 이미지 캡션 생성 등의 특정 작업을 수행하는 전문 모델들입니다.\\n\\n![JARVIS](images/jarvis.png?WT.mc_id=academic-105485-koreyst)\\n\\nLLM은 범용 모델로서 사용자로부터 요청을 받고 특정 작업과 그 작업을 완료하는 데 필요한 인수/데이터를 식별합니다.\\n\\n```python\\n[{\"task\": \"object-detection\", \"id\": 0, \"dep\": [-1], \"args\": {\"image\": \"e1.jpg\" }}]\\n```\\n\\n그런 다음 LLM은 요청을 JSON과 같은 형식으로 전문 AI 모델이 해석할 수 있는 방식으로 형식화합니다. AI 모델이 작업을 기반으로 예측을 반환하면, LLM은 그 응답을 수신합니다.\\n\\n여러 모델이 작업을 완료하는 데 필요할 경우, LLM은 해당 모델들의 응답을 해석하여 이를 결합한 후 사용자에게 응답을 생성할 것입니다.\\n\\n아래의 예시는 사용자가 사진의 객체 설명과 개수를 요청할 때 이 과정이 어떻게 이루어지는지를 보여줍니다:', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333473, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=343, prompt_tokens=324, total_tokens=667, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdKxEvyfAF1SELn8AnRKwDw6ehO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\nAutoGen을 사용하여 구축할 수 있는 AI 에이전트를 계속 학습하기 위해 다음 작업을 수행하십시오:\\n\\n- 교육 스타트업의 다양한 부서를 시뮬레이트하는 비즈니스 회의 애플리케이션.\\n- LLM이 다양한 페르소나와 우선 순위를 이해하도록 안내하는 시스템 메시지를 생성하고 사용자가 새로운 제품 아이디어를 제안할 수 있게 합니다.\\n- 그런 다음 LLM은 각 부서에서 후속 질문을 생성하여 피치와 제품 아이디어를 개선하고 정제합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333478, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=122, prompt_tokens=113, total_tokens=235, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdOtts9i7FX0ac4snuS5e5krYC2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습은 여기서 멈추지 않습니다, 여정을 계속하세요\\n\\n이 수업을 마친 후 [Generative AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성형 AI 지식을 계속 향상시키세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333482, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=68, prompt_tokens=85, total_tokens=153, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdQfyH2etUBCOqvVZPij82sP0VF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 함수 호출과 통합\\n\\n[![함수 호출과 통합](./images/11-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson11-gh?WT.mc_id=academic-105485-koreyst)\\n\\n이전 수업들에서 여러분은 많은 것을 배웠습니다. 그러나 우리는 더 나아질 수 있습니다. 해결해야 할 몇 가지 문제는 다운스트림에서 응답을 처리하기 쉽게 하기 위해 더 일관된 응답 형식을 얻는 방법입니다. 또한, 응용 프로그램을 더욱 풍부하게 만들기 위해 다른 소스의 데이터를 추가하고 싶을 수도 있습니다.\\n\\n이 장에서는 위에서 언급한 문제들을 해결하고자 합니다.\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333484, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=156, prompt_tokens=163, total_tokens=319, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdRk860mIwkVOhkOJz5blzMb32g', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 강의에서는 다음을 다룹니다:\\n\\n- 함수 호출이 무엇인지와 그 사용 사례 설명.\\n- Azure OpenAI를 사용하여 함수 호출 생성.\\n- 애플리케이션에 함수 호출을 통합하는 방법.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333485, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=51, prompt_tokens=68, total_tokens=119, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdSuFvzOgbif3GdiDIzklpjKhQk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의가 끝날 때쯤, 당신은 다음을 할 수 있을 것입니다:\\n\\n- 함수 호출의 목적을 설명할 수 있다.\\n- Azure OpenAI 서비스를 사용하여 함수 호출을 설정할 수 있다.\\n- 응용 프로그램의 사용 사례에 맞는 효과적인 함수 호출을 설계할 수 있다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333486, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=72, prompt_tokens=76, total_tokens=148, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdUvMlQVuHO6aLKDLdx4VnKL6AA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 시나리오: 함수로 채팅봇 개선하기\\n\\n이 레슨에서는 사용자가 채팅봇을 사용하여 기술 과정을 찾을 수 있는 기능을 교육 스타트업에 구축하고자 합니다. 우리는 사용자의 숙련도, 현재 역할 및 관심 기술에 맞는 과정을 추천할 것입니다.\\n\\n이 시나리오를 완료하기 위해 다음을 조합하여 사용할 것입니다:\\n\\n- `Azure OpenAI`를 사용하여 사용자에게 채팅 경험을 제공합니다.\\n- `Microsoft Learn Catalog API`를 사용하여 사용자의 요청에 따라 과정을 찾도록 도와줍니다.\\n- `함수 호출`을 사용하여 사용자의 쿼리를 받아 함수를 통해 API 요청을 보냅니다.\\n\\n먼저, 우리가 함수 호출을 사용하고자 하는 이유를 살펴보겠습니다:', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333488, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=171, prompt_tokens=168, total_tokens=339, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdZhIZ92Y1KjmLgzujkt0ftKZ8r', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 함수 호출의 이유\\n\\n함수 호출 이전에는 LLM(대규모 언어 모델)에서 나오는 응답이 비구조적이고 일관되지 않았습니다. 개발자는 각기 다른 응답 변형을 처리하기 위해 복잡한 검증 코드를 작성해야 했습니다. 사용자들은 \"스톡홀름의 현재 날씨는 무엇인가요?\"와 같은 질문에 답변을 받을 수 없었습니다. 이는 모델이 훈련된 데이터의 시점에 제한되어 있기 때문입니다.\\n\\n함수 호출(Function Calling)은 다음과 같은 제한을 극복하기 위해 Azure OpenAI 서비스의 기능입니다:\\n\\n- **일관된 응답 형식**. 응답 형식을 더 잘 제어할 수 있다면 응답을 다른 시스템으로 쉽게 통합할 수 있습니다.\\n- **외부 데이터**. 대화 환경에서 애플리케이션의 다른 소스 데이터를 사용할 수 있는 기능.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333493, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=194, prompt_tokens=167, total_tokens=361, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcddfPCR536qOECtK3tDFSAiUiJy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 시나리오를 통한 문제 설명\\n\\n> 아래 시나리오를 실행하려면 [포함된 노트북](./python/aoai-assignment.ipynb?WT.mc_id=academic-105485-koreyst)을 사용하는 것을 권장합니다. 문제를 해결하는 데 함수를 어떻게 사용할 수 있는지를 설명하기 위해 읽기만 할 수도 있습니다.\\n\\n문제의 응답 형식 문제를 설명하는 예시를 봅시다:\\n\\n학생 데이터베이스를 만들어 학생들에게 적합한 과정을 추천하고자 한다고 가정해 봅시다. 아래 두 학생 설명이 포함된 데이터는 매우 유사합니다.\\n\\n1. Azure OpenAI 리소스에 연결을 설정합니다:\\n\\n   ```python\\n   import os\\n   import json\\n   from openai import AzureOpenAI\\n   from dotenv import load_dotenv\\n   load_dotenv()\\n\\n   client = AzureOpenAI(\\n   api_key=os.environ[\\'AZURE_OPENAI_API_KEY\\'],  # 이 부분은 생략 가능하며, 기본값입니다.\\n   api_version = \"2023-07-01-preview\"\\n   )\\n\\n   deployment=os.environ[\\'AZURE_OPENAI_DEPLOYMENT\\']\\n   ```\\n\\n   아래는 `api_type`, `api_base`, `api_version`, `api_key`를 설정하여 Azure OpenAI에 연결을 구성하는 Python 코드입니다.\\n\\n1. `student_1_description`과 `student_2_description` 변수를 사용하여 두 학생 설명을 만듭니다.\\n\\n   ```python\\n   student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university\\'s Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\\n\\n   student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university\\'s Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\"\\n   ```\\n\\n   위의 학생 설명을 LLM에 보내 데이터를 파싱하려고 합니다. 이 데이터는 나중에 애플리케이션에서 사용하거나 API로 보내거나 데이터베이스에 저장할 수 있습니다.\\n\\n1. 관심 있는 정보를 LLM에 추출하도록 지시하는 두 개의 동일한 프롬프트를 만듭니다:\\n\\n   ```python\\n   prompt1 = f\\'\\'\\'\\n   Please extract the following information from the given text and return it as a JSON object:\\n\\n   name\\n   major\\n   school\\n   grades\\n   club\\n\\n   This is the body of text to extract the information from:\\n   {student_1_description}\\n   \\'\\'\\'\\n\\n   prompt2 = f\\'\\'\\'\\n   Please extract the following information from the given text and return it as a JSON object:\\n\\n   name\\n   major\\n   school\\n   grades\\n   club\\n\\n   This is the body of text to extract the information from:\\n   {student_2_description}\\n   \\'\\'\\'\\n   ```\\n\\n   위의 프롬프트는 LLM에게 정보를 JSON 형식으로 추출하여 반환하도록 지시합니다.\\n\\n1. Azure OpenAI에 연결을 설정하고 프롬프트를 준비한 후, `openai.ChatCompletion`을 사용하여 프롬프트를 LLM에 보냅니다. 프롬프트를 `messages` 변수에 저장하고 `role`을 `user`로 지정합니다. 이는 사용자로부터 채팅봇에 메시지를 작성하는 것을 모방하기 위함입니다.\\n\\n   ```python\\n   # 첫 번째 프롬프트의 응답\\n   openai_response1 = client.chat.completions.create(\\n   model=deployment,\\n   messages = [{\\'role\\': \\'user\\', \\'content\\': prompt1}]\\n   )\\n   openai_response1.choices[0].message.content\\n\\n   # 두 번째 프롬프트의 응답\\n   openai_response2 = client.chat.completions.create(\\n   model=deployment,\\n   messages = [{\\'role\\': \\'user\\', \\'content\\': prompt2}]\\n   )\\n   openai_response2.choices[0].message.content\\n   ```\\n\\n이제 두 요청을 LLM에 보내고 `openai_response1[\\'choices\\'][0][\\'message\\'][\\'content\\']`와 같이 응답을 확인할 수 있습니다.\\n\\n1. 마지막으로, `json.loads`를 호출하여 응답을 JSON 형식으로 변환할 수 있습니다:\\n\\n   ```python\\n   # 응답을 JSON 객체로 로드\\n   json_response1 = json.loads(openai_response1.choices[0].message.content)\\n   json_response1\\n   ```\\n\\n   응답 1:\\n\\n   ```json\\n   {\\n     \"name\": \"Emily Johnson\",\\n     \"major\": \"computer science\",\\n     \"school\": \"Duke University\",\\n     \"grades\": \"3.7\",\\n     \"club\": \"Chess Club\"\\n   }\\n   ```\\n\\n   응답 2:\\n\\n   ```json\\n   {\\n     \"name\": \"Michael Lee\",\\n     \"major\": \"computer science\",\\n     \"school\": \"Stanford University\",\\n     \"grades\": \"3.8 GPA\",\\n     \"club\": \"Robotics Club\"\\n   }\\n   ```\\n\\n   프롬프트는 같고 설명도 유사하지만, `Grades` 속성의 값이 때때로 `3.7` 또는 `3.7 GPA`와 같이 다른 형식으로 반환되는 것을 볼 수 있습니다.\\n\\n   이는 LLM이 비구조적인 데이터를 이용해 작성된 프롬프트를 받아 비구조적인 데이터를 반환하기 때문입니다. 데이터를 저장하거나 사용할 때 예상할 수 있는 구조적인 형식이 필요합니다.\\n\\n그럼 형식 문제는 어떻게 해결할까요? 기능 호출을 사용하면 구조화된 데이터를 받을 수 있습니다. 기능 호출을 사용할 때 LLM은 실제로 함수나 기능을 호출하지 않습니다. 대신 LLM이 응답할 때 따를 수 있는 구조를 만듭니다. 그런 다음 이 구조화된 응답을 사용하여 애플리케이션에서 호출할 기능을 결정할 수 있습니다.\\n\\n![기능 흐름](./images/Function-Flow.png?WT.mc_id=academic-105485-koreyst)\\n\\n우리는 함수로부터 반환된 결과를 LLM에 다시 보낼 수 있습니다. 그런 다음 LLM은 사용자의 질문에 자연어로 응답할 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333497, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=1344, prompt_tokens=1276, total_tokens=2620, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdqvETsoCzOZXm1NK3l2spyaz4E', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 함수 호출 사용 사례\\n\\n앱을 개선하기 위해 함수 호출을 사용할 수 있는 다양한 사례가 있습니다:\\n\\n- **외부 도구 호출**. 챗봇은 사용자 질문에 답변을 제공하는 데 뛰어납니다. 함수 호출을 사용하면 챗봇이 사용자 메시지를 기반으로 특정 작업을 수행할 수 있습니다. 예를 들어, 학생이 \"이 과목에 대해 더 많은 도움이 필요하다는 이메일을 내 강사에게 보내 주세요\"라고 챗봇에게 요청할 수 있습니다. 이는 `send_email(to: string, body: string)` 함수를 호출해서 수행할 수 있습니다.\\n\\n- **API 또는 데이터베이스 쿼리 생성**. 사용자는 자연어를 사용하여 포맷된 쿼리나 API 요청으로 변환되는 정보를 찾을 수 있습니다. 예를 들어, 교사가 \"마지막 과제를 완료한 학생들이 누구인가요?\"라고 요청할 수 있으며, 이는 `get_completed(student_name: string, assignment: int, current_status: string)`라는 함수를 호출해서 수행할 수 있습니다.\\n\\n- **구조화된 데이터 생성**. 사용자는 텍스트 블록이나 CSV를 활용하여 LLM을 사용해 중요한 정보를 추출할 수 있습니다. 예를 들어, 학생이 평화 협정에 관한 위키백과 기사를 사용하여 AI 플래시 카드를 생성할 수 있습니다. 이는 `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`라는 함수를 호출하여 수행할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333510, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=328, prompt_tokens=284, total_tokens=612, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcduqWL43bONL6JfT33KfJRoTDew', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 첫 번째 함수 호출 만들기\\n\\n함수 호출을 만드는 과정에는 다음 3가지 주요 단계가 포함됩니다:\\n\\n1. 사용자가 보낸 메시지와 함수 목록을 함께 Chat Completions API를 **호출**합니다.\\n2. 모델의 응답을 **읽어** 함수 실행 또는 API 호출 같은 동작을 수행합니다.\\n3. 함수 응답을 사용하여 사용자에게 응답을 생성하기 위해 다시 Chat Completions API를 **호출**합니다.\\n\\n![LLM 흐름](./images/LLM-Flow.png?WT.mc_id=academic-105485-koreyst)\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333514, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=129, prompt_tokens=148, total_tokens=277, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcdwC38beCMzxhQ89piOQMfMq9T8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Step 1 - 메시지 생성\\n\\n첫 번째 단계는 사용자 메시지를 생성하는 것입니다. 이는 텍스트 입력의 값을 동적으로 할당하여 생성할 수 있으며, 여기서 값을 지정할 수도 있습니다. Chat Completions API를 처음 사용하는 경우, 메시지의 `role`과 `content`를 정의해야 합니다.\\n\\n`role`은 `system` (규칙 생성), `assistant` (모델) 또는 `user` (최종 사용자) 중 하나로 설정할 수 있습니다. 함수 호출을 위해, 우리는 `user`를 지정하고 예시 질문을 작성합니다.\\n\\n```python\\nmessages= [ {\"role\": \"user\", \"content\": \"초보 학생이 Azure를 배우기에 좋은 강좌를 찾아주세요.\"} ]\\n```\\n\\n다양한 역할을 할당함으로써, LLM에게 시스템이 말하는 것인지 사용자가 말하는 것인지 분명히 알려줄 수 있으며, 이는 LLM이 누적된 대화 기록을 바탕으로 대화를 이어가는 데 도움이 됩니다.\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333516, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=216, prompt_tokens=216, total_tokens=432, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABce0SKcgKA2Ekb0YtSIm51v7c2Gy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 2단계 - 함수 생성\\n\\n이제 함수를 정의하고 그 함수의 매개변수를 설정하겠습니다. 여기서는 `search_courses`라는 하나의 함수만 사용하겠지만, 여러 개의 함수를 생성할 수도 있습니다.\\n\\n> **중요** : 함수는 시스템 메시지에 포함되며, 사용 가능한 토큰의 양에 포함됩니다.\\n\\n아래에서 우리는 함수를 아이템 배열로 작성합니다. 각 아이템은 함수로, `name`, `description`, `parameters`라는 속성을 가지고 있습니다:\\n\\n```python\\nfunctions = [\\n   {\\n      \"name\": \"search_courses\",\\n      \"description\": \"제공된 매개변수를 기반으로 검색 인덱스에서 강좌를 검색합니다\",\\n      \"parameters\": {\\n         \"type\": \"object\",\\n         \"properties\": {\\n            \"role\": {\\n               \"type\": \"string\",\\n               \"description\": \"학습자의 역할 (예: 개발자, 데이터 과학자, 학생 등)\"\\n            },\\n            \"product\": {\\n               \"type\": \"string\",\\n               \"description\": \"수업이 다루는 제품 (예: Azure, Power BI 등)\"\\n            },\\n            \"level\": {\\n               \"type\": \"string\",\\n               \"description\": \"학습자가 강좌를 듣기 전의 경험 수준 (예: 초급, 중급, 고급)\"\\n            }\\n         },\\n         \"required\": [\\n            \"role\"\\n         ]\\n      }\\n   }\\n]\\n```\\n\\n아래에 각 함수 인스턴스에 대해 더 자세히 설명합니다:\\n\\n- `name` - 호출하려는 함수의 이름입니다.\\n- `description` - 함수가 어떻게 작동하는지 설명합니다. 여기에서는 구체적이고 명확하게 설명하는 것이 중요합니다.\\n- `parameters` - 모델이 응답 시 제공해야 할 값과 형식의 목록입니다. 매개변수 배열은 다음 속성을 가진 항목으로 구성됩니다:\\n  1. `type` - 속성이 저장될 데이터 타입입니다.\\n  1. `properties` - 모델이 응답에 사용하게 될 구체적인 값들의 목록입니다.\\n      1. `name` - 모델이 형식화된 응답에 사용할 속성의 이름입니다. 예를 들어, `product`.\\n      1. `type` - 이 속성의 데이터 타입입니다. 예를 들어, `string`.\\n      1. `description` - 구체적인 속성에 대한 설명입니다.\\n\\n또한 선택적 속성 `required`가 있습니다 - 함수 호출이 완료되기 위해 필요한 속성입니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333520, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=540, prompt_tokens=519, total_tokens=1059, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABce66EhW2MxjWrcSylQcm1iJYKF1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Step 3 - 함수 호출하기\\n\\n함수를 정의한 후 이제 이를 Chat Completion API 호출에 포함해야 합니다. 이를 위해 요청에 `functions`를 추가합니다. 이 경우 `functions=functions`로 설정합니다.\\n\\n또한 `function_call` 옵션을 `auto`로 설정할 수도 있습니다. 이는 사용자의 메시지에 따라 호출할 함수를 우리가 직접 지정하는 대신 LLM이 결정하도록 하는 의미입니다.\\n\\n아래에 `ChatCompletion.create`를 호출하는 코드가 있습니다. `functions=functions`와 `function_call=\"auto\"`를 설정하여 제공된 함수를 언제 호출할지 LLM에 선택권을 주는 것을 주목하세요:\\n\\n```python\\nresponse = client.chat.completions.create(model=deployment,\\n                                        messages=messages,\\n                                        functions=functions,\\n                                        function_call=\"auto\")\\n\\nprint(response.choices[0].message)\\n```\\n\\n이제 응답은 다음과 같이 보입니다:\\n\\n```json\\n{\\n  \"role\": \"assistant\",\\n  \"function_call\": {\\n    \"name\": \"search_courses\",\\n    \"arguments\": \"{\\\\n  \\\\\"role\\\\\": \\\\\"student\\\\\",\\\\n  \\\\\"product\\\\\": \\\\\"Azure\\\\\",\\\\n  \\\\\"level\\\\\": \\\\\"beginner\\\\\"\\\\n}\"\\n  }\\n}\\n```\\n\\n여기서 함수 `search_courses`가 호출되었고, JSON 응답의 `arguments` 속성에 나열된 인수와 함께 호출되었음을 알 수 있습니다.\\n\\nLLM이 함수의 인수에 맞는 데이터를 찾을 수 있었던 결론은 chat completion 호출의 `messages` 파라미터에 제공된 값에서 이를 추출했기 때문입니다. 아래는 `messages` 값의 예:\\n\\n```python\\nmessages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]\\n```\\n\\n보시다시피, `student`, `Azure` 및 `beginner`가 `messages`에서 추출되어 함수의 입력으로 설정되었습니다. 이와 같이 함수를 사용하는 것은 프롬프트에서 정보를 추출하는 좋은 방법일 뿐만 아니라 LLM에 구조를 제공하고 재사용 가능한 기능을 가지게 하는 훌륭한 방법입니다.\\n\\n다음으로, 이를 우리 앱에서 어떻게 사용할 수 있는지 살펴보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333526, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_157b3831f5', usage=CompletionUsage(completion_tokens=475, prompt_tokens=464, total_tokens=939, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABceCMPAuWioj8ZMcKXWZWdLLDoGf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 애플리케이션에 함수 호출 통합\\n\\nLLM에서 포맷된 응답을 테스트한 후, 이제 이를 애플리케이션에 통합할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333532, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=40, prompt_tokens=58, total_tokens=98, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABceD2M0kSMI6rreffIMHmtdSVW5Q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 흐름 관리\\n\\n이것을 애플리케이션에 통합하려면 다음 단계를 따르겠습니다:\\n\\n1. 먼저 Open AI 서비스에 호출을 하고 메시지를 `response_message`라는 변수에 저장합니다.\\n\\n   ```python\\n   response_message = response.choices[0].message\\n   ```\\n\\n1. 이제 Microsoft Learn API를 호출하여 코스 목록을 가져올 함수를 정의하겠습니다:\\n\\n   ```python\\n   import requests\\n\\n   def search_courses(role, product, level):\\n     url = \"https://learn.microsoft.com/api/catalog/\"\\n     params = {\\n        \"role\": role,\\n        \"product\": product,\\n        \"level\": level\\n     }\\n     response = requests.get(url, params=params)\\n     modules = response.json()[\"modules\"]\\n     results = []\\n     for module in modules[:5]:\\n        title = module[\"title\"]\\n        url = module[\"url\"]\\n        results.append({\"title\": title, \"url\": url})\\n     return str(results)\\n   ```\\n\\n   여기서 함수 이름을 `functions` 변수에 소개된 함수 이름과 매핑하는 실제 Python 함수를 만드는 방법을 알아보겠습니다. 우리는 필요한 데이터를 가져오기 위해 실제 외부 API 호출도 합니다. 이 경우 Microsoft Learn API를 사용하여 교육 모듈을 검색합니다.\\n\\n좋습니다, `functions` 변수를 생성하고 해당하는 Python 함수를 만들었으니, 어떻게 두 개를 매핑하여 Python 함수가 호출되도록 LLM에 알릴까요?\\n\\n1. Python 함수 호출이 필요한지 확인하려면 LLM 응답을 확인하여 `function_call`이 포함되어 있는지 확인하고 지정된 함수를 호출해야 합니다. 다음과 같이 확인할 수 있습니다:\\n\\n   ```python\\n   # 모델이 함수를 호출하려고 하는지 확인합니다.\\n   if response_message.function_call.name:\\n    print(\"추천 함수 호출:\")\\n    print(response_message.function_call.name)\\n    print()\\n\\n    # 함수 호출\\n    function_name = response_message.function_call.name\\n\\n    available_functions = {\\n            \"search_courses\": search_courses,\\n    }\\n    function_to_call = available_functions[function_name]\\n\\n    function_args = json.loads(response_message.function_call.arguments)\\n    function_response = function_to_call(**function_args)\\n\\n    print(\"함수 호출의 출력:\")\\n    print(function_response)\\n    print(type(function_response))\\n\\n\\n    # 어시스턴트 응답과 함수 응답을 메시지에 추가합니다.\\n    messages.append( # 어시스턴트 응답 추가\\n        {\\n            \"role\": response_message.role,\\n            \"function_call\": {\\n                \"name\": function_name,\\n                \"arguments\": response_message.function_call.arguments,\\n            },\\n            \"content\": None\\n        }\\n    )\\n    messages.append( # 함수 응답 추가\\n        {\\n            \"role\": \"function\",\\n            \"name\": function_name,\\n            \"content\": function_response,\\n        }\\n    )\\n   ```\\n\\n   아래 세 줄은 함수 이름, 인수를 추출하고 함수를 호출하는 것을 보장합니다:\\n\\n   ```python\\n   function_to_call = available_functions[function_name]\\n\\n   function_args = json.loads(response_message.function_call.arguments)\\n   function_response = function_to_call(**function_args)\\n   ```\\n\\n   아래는 우리의 코드 실행 결과입니다:\\n\\n   **출력**\\n\\n   ```추천 함수 호출:\\n   {\\n     \"name\": \"search_courses\",\\n     \"arguments\": \"{\\\\n  \\\\\"role\\\\\": \\\\\"student\\\\\",\\\\n  \\\\\"product\\\\\": \\\\\"Azure\\\\\",\\\\n  \\\\\"level\\\\\": \\\\\"beginner\\\\\"\\\\n}\"\\n   }\\n\\n   함수 호출의 출력:\\n   [{\\'title\\': \\'Describe concepts of cryptography\\', \\'url\\': \\'https://learn.microsoft.com/training/modules/describe-concepts-of-cryptography/?\\n   WT.mc_id=api_CatalogApi\\'}, {\\'title\\': \\'Introduction to audio classification with TensorFlow\\', \\'url\\': \\'https://learn.microsoft.com/en-\\n   us/training/modules/intro-audio-classification-tensorflow/?WT.mc_id=api_CatalogApi\\'}, {\\'title\\': \\'Design a Performant Data Model in Azure SQL\\n   Database with Azure Data Studio\\', \\'url\\': \\'https://learn.microsoft.com/training/modules/design-a-data-model-with-ads/?\\n   WT.mc_id=api_CatalogApi\\'}, {\\'title\\': \\'Getting started with the Microsoft Cloud Adoption Framework for Azure\\', \\'url\\':\\n   \\'https://learn.microsoft.com/training/modules/cloud-adoption-framework-getting-started/?WT.mc_id=api_CatalogApi\\'}, {\\'title\\': \\'Set up the\\n   Rust development environment\\', \\'url\\': \\'https://learn.microsoft.com/training/modules/rust-set-up-environment/?WT.mc_id=api_CatalogApi\\'}]\\n   <class \\'str\\'>\\n   ```\\n\\n1. 이제 업데이트된 메시지인 `messages`를 LLM에 전송하여 API JSON 형식 응답 대신 자연어 응답을 받을 수 있습니다.\\n\\n   ```python\\n   print(\"다음 요청에서의 메시지:\")\\n   print(messages)\\n   print()\\n\\n   second_response = client.chat.completions.create(\\n      messages=messages,\\n      model=deployment,\\n      function_call=\"auto\",\\n      functions=functions,\\n      temperature=0\\n         )  # 함수 응답을 볼 수 있도록 GPT에서 새 응답을 가져옵니다.\\n\\n\\n   print(second_response.choices[0].message)\\n   ```\\n\\n   **출력**\\n\\n   ```python\\n   {\\n     \"role\": \"assistant\",\\n     \"content\": \"Azure를 배우려는 초보 학생을 위한 좋은 코스들을 찾았습니다:\\\\n\\\\n1. [암호 기술 개념 설명] (https://learn.microsoft.com/training/modules/describe-concepts-of-cryptography/?WT.mc_id=api_CatalogApi)\\\\n2. [TensorFlow를 사용한 오디오 분류 소개](https://learn.microsoft.com/training/modules/intro-audio-classification-tensorflow/?WT.mc_id=api_CatalogApi)\\\\n3. [Azure SQL Database에서 성능 좋은 데이터 모델 설계](https://learn.microsoft.com/training/modules/design-a-data-model-with-ads/?WT.mc_id=api_CatalogApi)\\\\n4. [Microsoft Cloud Adoption Framework 시작하기](https://learn.microsoft.com/training/modules/cloud-adoption-framework-getting-started/?WT.mc_id=api_CatalogApi)\\\\n5. [Rust 개발 환경 설정](https://learn.microsoft.com/training/modules/rust-set-up-environment/?WT.mc_id=api_CatalogApi)\\\\n\\\\n링크를 클릭하여 코스를 확인하실 수 있습니다.\"\\n   }\\n   ```\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333533, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=1351, prompt_tokens=1347, total_tokens=2698, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABceP4OAFDiFvJUe9fyuZZmPfWMJr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\nAzure OpenAI Function Calling 학습을 지속하려면 다음을 구축할 수 있습니다:\\n\\n- 학습자가 더 많은 과정을 찾을 수 있도록 돕는 함수의 더 많은 매개변수.\\n- 학습자의 모국어와 같은 더 많은 정보를 받아오는 또 다른 함수 호출을 생성.\\n- 함수 호출 및/또는 API 호출이 적합한 과정을 반환하지 않을 때 오류 처리 생성.\\n\\n힌트: 이 데이터가 어떻게 그리고 어디에 있는지 보려면 [Learn API 참조 문서](https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst) 페이지를 참고하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333545, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=144, prompt_tokens=142, total_tokens=286, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABceUGm7bG7cjuCZvFBnKSAO5GHM3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 여정을 계속하세요\\n\\n이 강의를 마친 후, [Generative AI Learning 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 Generative AI 지식을 계속 향상시키세요!\\n\\n레슨 12로 이동하여 [AI 애플리케이션의 UX 설계](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)에 대해 알아보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333550, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=113, prompt_tokens=128, total_tokens=241, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABceVMp3DsdnSDRPGhOfjvXJ83r2D', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 프롬프트 엔지니어링 기초\\n\\n[![프롬프트 엔지니어링 기초](./images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333551, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=72, prompt_tokens=84, total_tokens=156, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABceXxa2DrtMKargVjN3GmI8Qbm9y', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n이 모듈에서는 생성형 AI 모델에서 효과적인 프롬프트를 작성하는 데 필요한 필수 개념과 기술을 다룹니다. LLM에 프롬프트를 작성하는 방식도 중요합니다. 신중하게 작성된 프롬프트는 보다 나은 응답 품질을 달성할 수 있습니다. 하지만 _프롬프트_와 _프롬프트 엔지니어링_ 같은 용어는 정확히 무엇을 의미할까요? 그리고 LLM에 보낼 프롬프트 _입력_을 어떻게 개선할 수 있을까요? 이 장과 다음 장에서 이러한 질문들에 답하려고 노력할 것입니다.\\n\\n_생성형 AI_는 사용자의 요청에 따라 새로운 콘텐츠(예: 텍스트, 이미지, 오디오, 코드 등)를 생성할 수 있습니다. 이는 자연어와 코드를 사용하는 훈련을 받은 OpenAI의 GPT(\"Generative Pre-trained Transformer\") 시리즈와 같은 _대규모 언어 모델_을 사용하여 달성됩니다.\\n\\n사용자들은 이제 채팅과 같은 친숙한 패러다임을 사용하여 기술적 전문 지식이나 훈련이 필요 없이 이러한 모델과 상호작용할 수 있습니다. 모델들은 _프롬프트 기반_으로 동작합니다 - 사용자가 텍스트 입력(프롬프트)을 보내면 AI 응답(완성)을 받습니다. 그런 다음 사용자는 \"AI와 채팅\"을 반복적으로 진행하며, 다중 턴 대화를 통해 프롬프트를 수정해 응답이 기대에 부합할 때까지 계속할 수 있습니다.\\n\\n\"프롬프트\"는 이제 생성형 AI 앱의 주요 _프로그래밍 인터페이스_가 되어 모델에게 무엇을 해야 하는지 알려주고 반환되는 응답의 품질에 영향을 미칩니다. \"프롬프트 엔지니어링\"은 일관되고 높은 품질의 응답을 대규모로 제공하기 위해 프롬프트의 _설계와 최적화_를 연구하는 빠르게 성장하는 분야입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333553, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c047b7b4ec', usage=CompletionUsage(completion_tokens=444, prompt_tokens=322, total_tokens=766, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcecn3v6qPRKNYRQcR0XgPxGmj9P', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이번 강의에서는 프롬프트 엔지니어링이 무엇인지, 왜 중요한지, 그리고 주어진 모델과 응용 목표에 대해 더 효과적인 프롬프트를 어떻게 작성할 수 있는지 배웁니다. 프롬프트 엔지니어링의 핵심 개념과 모범 사례를 이해하고, 이러한 개념들이 실제 사례에 적용되는 것을 볼 수 있는 상호작용 Jupyter 노트북 \"샌드박스\" 환경에 대해 배울 것입니다.\\n\\n이번 강의가 끝나면 다음을 할 수 있습니다:\\n\\n1. 프롬프트 엔지니어링이 무엇이며 왜 중요한지 설명할 수 있습니다.\\n2. 프롬프트의 구성 요소와 그것들이 어떻게 사용되는지 설명할 수 있습니다.\\n3. 프롬프트 엔지니어링에 대한 모범 사례와 기술을 배울 수 있습니다.\\n4. 배운 기술을 실제 사례에 적용하여 OpenAI 엔드포인트를 사용할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333558, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=215, prompt_tokens=162, total_tokens=377, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcefhwVDt76YEj1i3Tod6VMWuPlT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 주요 용어\\n\\n프롬프트 엔지니어링: AI 모델이 원하는 출력을 생성하도록 유도하기 위해 입력을 설계하고 수정하는 실천.\\n토크나이제이션: 모델이 이해하고 처리할 수 있는 작은 단위인 토큰으로 텍스트를 변환하는 과정.\\n명령어 튜닝된 LLMs: 특정 명령어로 미세 조정되어 응답의 정확성과 관련성을 향상시킨 대형 언어 모델(LLMs).', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333561, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=109, prompt_tokens=105, total_tokens=214, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcehg5dn8tTRwrgF9fLlIkRFF8T1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Learning Sandbox\\n\\n프롬프트 엔지니어링은 현재 과학보다 예술에 더 가깝습니다. 이를 위한 직관을 개선하는 가장 좋은 방법은 _더 많이 연습_하고, 응용 분야 전문 지식과 권장 기술 및 모델 특정 최적화를 결합한 시행착오 접근 방식을 채택하는 것입니다.\\n\\n이 수업에 동반되는 Jupyter Notebook은 여러분이 배우고 있는 것을 실험해 볼 수 있는 _샌드박스_ 환경을 제공합니다. 학습을 진행하면서 또는 코드 챌린지의 일환으로 노트북을 실행해 보세요. 연습을 실행하려면 다음이 필요합니다:\\n\\n1. **Azure OpenAI API 키** - 배포된 LLM의 서비스 엔드포인트.\\n2. **Python 런타임** - 노트북을 실행할 수 있는 환경.\\n3. **로컬 환경 변수** - _준비를 위해 [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) 단계를 지금 완성하세요_.\\n\\n노트북에는 _시작_ 연습이 포함되어 있지만, 더 많은 예제나 아이디어를 시도하고 프롬프트 디자인에 대한 직관을 기르기 위해 여러분 자신의 _Markdown_ (설명) 및 _Code_ (프롬프트 요청) 섹션을 추가하는 것을 권장합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333563, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=307, prompt_tokens=251, total_tokens=558, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcemkZx0zJf1hJYuRUbXAZaOqBQh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 일러스트 가이드\\n\\n이 수업에서 다룰 내용을 시작하기 전에 전체적인 그림을 보고 싶으신가요? 이 일러스트 가이드를 확인해 보세요. 주요 주제와 각 주제에서 생각해볼 주요 포인트들을 알려줍니다. 수업 로드맵은 핵심 개념과 도전 과제를 이해하는 것부터 관련된 프롬프트 엔지니어링 기법 및 모범 사례로 이를 해결하는 방법까지 안내합니다. 이 가이드의 \"고급 기법\" 섹션은 이 교육 과정의 _다음_ 장에서 다루는 내용을 참조한다는 점에 유의하세요.\\n\\n![프롬프트 엔지니어링에 대한 일러스트 가이드](./images/04-prompt-engineering-sketchnote.png?WT.mc_id=academic-105485-koreyst)\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333568, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=189, prompt_tokens=161, total_tokens=350, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcepLeLGq37uG1RaTbOQx5AQ7brl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 우리 스타트업\\n\\n이제 _이 주제_ 가 우리의 스타트업 미션, 즉 [교육에 AI 혁신을 가져오는 것](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst)과 어떻게 연관되는지 이야기해 보겠습니다. 우리는 _맞춤형 학습_의 AI 기반 응용 프로그램을 구축하고자 합니다. 따라서 우리 응용 프로그램의 다양한 사용자가 \"프롬프트\"를 어떻게 설계할 수 있을지 생각해 봅시다:\\n\\n- **관리자** 는 AI에게 _교육 과정을 분석하여 커버리지의 격차를 식별_하도록 요청할 수 있습니다. AI는 결과를 요약하거나 코드를 사용해 시각화할 수 있습니다.\\n- **교육자** 는 AI에게 _특정 대상과 주제를 위한 수업 계획을 생성_하도록 요청할 수 있습니다. AI는 지정된 형식으로 맞춤형 계획을 작성할 수 있습니다.\\n- **학생** 은 AI에게 _어려운 과목을 튜터링_ 해달라고 요청할 수 있습니다. AI는 이제 학생 수준에 맞춘 교훈, 힌트 및 예제를 제공하여 가이드를 제공합니다.\\n\\n이것은 빙산의 일각에 불과합니다. 교육 전문가들이 큐레이션한 오픈소스 프롬프트 라이브러리인 [교육을 위한 프롬프트](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst)를 확인하여 가능성의 더 넓은 범위를 알아보세요! _샌드박스에서 일부 프롬프트를 실행해보거나 OpenAI 플레이그라운드를 이용해 어떤 일이 일어나는지 확인해 보세요!_\\n\\n<!--\\n수업 템플릿:\\n이 단원은 핵심 개념 #1을 다뤄야 합니다.\\n예제 및 참고 자료로 개념을 강화하십시오.\\n\\n개념 #1:\\n프롬프트 엔지니어링.\\n이를 정의하고 왜 필요한지 설명하십시오.\\n-->', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333571, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=462, prompt_tokens=350, total_tokens=812, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABceuGHx9y4jPUtvXPq1ErHgwm6Gz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 프롬프트 엔지니어링이란?\\n\\n우리는 이 수업을 **프롬프트 엔지니어링**을 특정 응용 목표와 모델에 대해 일관되고 질 높은 응답(완성)을 제공하는 텍스트 입력(프롬프트)을 _설계하고 최적화하는_ 과정으로 정의하면서 시작했습니다. 이를 2단계 과정으로 생각할 수 있습니다:\\n\\n- 주어진 모델과 목표에 맞는 초기 프롬프트를 _설계하는_ 것\\n- 응답의 질을 향상시키기 위해 프롬프트를 반복적으로 _수정하는_ 것\\n\\n이 과정은 최적의 결과를 얻기 위해 사용자 직관과 노력이 필요한 시행착오 과정입니다. 그렇다면 왜 이것이 중요할까요? 이 질문에 답하기 위해 먼저 세 가지 개념을 이해해야 합니다:\\n\\n- _토크나이제이션_ = 모델이 프롬프트를 \"인식하는\" 방법\\n- _베이스 LLMs_ = 기본 모델이 프롬프트를 \"처리하는\" 방법\\n- _인스트럭션 튜닝된 LLMs_ = 모델이 이제 \"작업\"을 인식하는 방법\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333576, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=262, prompt_tokens=215, total_tokens=477, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcezd0TL5KUxRU701phhTZMNTVuP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 토크나이제이션\\n\\nLLM은 프롬프트를 _토큰의 시퀀스_로 보며, 다양한 모델(또는 모델의 버전)에 따라 동일한 프롬프트도 다르게 토크나이즈될 수 있습니다. LLM은 원시 텍스트가 아닌 토큰을 기반으로 학습되기 때문에, 프롬프트가 토크나이즈되는 방식은 생성된 응답의 품질에 직접적인 영향을 미칩니다.\\n\\n토크나이제이션이 어떻게 작동하는지 직관적으로 이해하기 위해서 아래에 보여지는 [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst)와 같은 도구를 시도해 보세요. 프롬프트를 복사하여 입력해보면 공백 문자와 구두점이 어떻게 처리되는지에 주목하면서 그것이 토큰으로 변환되는 과정을 볼 수 있습니다. 이 예시는 구형 LLM(GPT-3)을 보여주므로, 최신 모델로 시도하면 다른 결과가 나올 수 있습니다.\\n\\n![토크나이제이션](./images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst)\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333581, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=269, prompt_tokens=219, total_tokens=488, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcf2geTtBr7m6BvKrN4g4SKJJC1E', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 개념: 기초 모델\\n\\n프롬프트가 토큰화되면 [\"기초 LLM\"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (또는 기초 모델)의 주요 기능은 해당 시퀀스에서 토큰을 예측하는 것입니다. LLM은 방대한 텍스트 데이터셋으로 학습되었기 때문에 토큰 간의 통계적 관계를 잘 파악하고 해당 예측을 어느 정도의 신뢰도로 수행할 수 있습니다. 단, 프롬프트 또는 토큰의 단어 _의미_ 는 이해하지 못하며, 단순히 다음 예측으로 \"완성\"할 수 있는 패턴을 볼 뿐입니다. 사용자의 개입 또는 미리 설정된 조건에 의해 종료될 때까지 시퀀스를 계속 예측할 수 있습니다.\\n\\n프롬프트 기반 완성이 어떻게 작동하는지 보고 싶으신가요? 위의 프롬프트를 기본 설정으로 Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst)에 입력해 보십시오. 시스템은 프롬프트를 정보 요청으로 처리하도록 구성되어 있으므로, 이 문맥을 만족시키는 완성을 볼 수 있을 것입니다.\\n\\n하지만 사용자가 특정 기준이나 작업 목표를 충족하는 무언가를 보고 싶다면 어떻게 될까요? 이때 _명령 조정된_ LLM이 등장합니다.\\n\\n![기초 LLM 채팅 완성](./images/04-playground-chat-base.png?WT.mc_id=academic-105485-koreyst)\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333584, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=371, prompt_tokens=324, total_tokens=695, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcf7DTTOo4TyBtELRM78Cj5cX8bG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 개념: 학습 지침에 맞춰 튜닝된 대형 언어 모델 (Instruction Tuned LLMs)\\n\\n[학습 지침에 맞춰 튜닝된 대형 언어 모델](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst)은 기본 모델에서 시작하여 명확한 지침을 포함할 수 있는 예시나 입력/출력 쌍(예: 여러 턴의 \"메시지\")으로 미세 조정됩니다. 이러한 모델은 AI가 해당 지침을 따르려는 응답을 시도합니다.\\n\\n이 방법은 인간의 피드백을 활용한 강화 학습(Reinforcement Learning with Human Feedback, RLHF)과 같은 기술을 사용하여 모델이 _지침을 따르고_ _피드백을 학습할 수_ 있게 훈련합니다. 이를 통해 모델은 실용적인 응용에 더 적합하고 사용자 목표에 더 부합하는 응답을 생성하게 됩니다.\\n\\n한 번 시도해 봅시다 - 위의 프롬프트를 다시 방문하여 _시스템 메시지_를 다음 지침을 문맥으로 제공하도록 변경해 보세요:\\n\\n> _제공된 내용을 2학년 학생에게 요약합니다. 결과를 3-5개의 항목이 있는 한 단락으로 유지합니다._\\n\\n이제 결과가 원하는 목표와 형식을 반영하고 있는지 확인해 보세요. 교사는 이제 이 응답을 직접 수업 슬라이드에 사용할 수 있게 됩니다.\\n\\n![학습 지침에 맞춰 튜닝된 대형 언어 모델 채팅 완료](./images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333589, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=393, prompt_tokens=299, total_tokens=692, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcfG2gHlI2WmNa6ftfRXCcEL01wg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 프롬프트 엔지니어링이 왜 필요한가?\\n\\n이제 프롬프트가 대형 언어 모델(LLM)에 의해 어떻게 처리되는지 알게 되었으므로 _왜_ 프롬프트 엔지니어링이 필요한지 이야기해 봅시다. 그 이유는 현재의 LLM들이 _신뢰할 수 있고 일관된 응답_을 달성하기 어렵게 만드는 여러 도전 과제를 제시하기 때문입니다. 이러한 도전 과제는 프롬프트 구성 및 최적화에 노력을 기울이지 않으면 해결하기 어렵습니다. 예를 들어:\\n\\n1. **모델 응답은 확률적입니다.** _동일한 프롬프트_는 다른 모델 또는 모델 버전에 따라 다른 응답을 생성할 가능성이 높습니다. 심지어 같은 모델에서 다른 시점에 사용하더라도 다른 결과를 생성할 수 있습니다. _프롬프트 엔지니어링 기술은 더 나은 가드레일을 제공함으로써 이러한 변동을 최소화할 수 있습니다_.\\n\\n1. **모델이 응답을 조작할 수 있습니다.** 모델은 _크지만 유한한_ 데이터셋을 사용하여 사전 학습되기 때문에 학습 범위 외의 개념에 대해 지식이 부족합니다. 그 결과, 부정확하거나 상상적이거나 알려진 사실과 직접적으로 모순되는 완성을 생성할 수 있습니다. _프롬프트 엔지니어링 기술은 사용자가 AI에게 인용 또는 추론을 요청하는 등의 방법으로 이러한 조작을 식별하고 완화하는 데 도움을 줍니다_.\\n\\n1. **모델의 능력은 다양합니다.** 최신 모델이나 모델 세대는 더 풍부한 기능을 제공하지만 비용과 복잡성에서 고유한 단점을 동반할 수 있습니다. _프롬프트 엔지니어링은 차이를 추상화하고 확장 가능하고 원활한 방법으로 모델별 요구사항에 적응하는 모범 사례 및 워크플로를 개발하는 데 도움을 줍니다_.\\n\\nOpenAI 또는 Azure OpenAI Playground에서 실제로 이를 확인해 봅시다:\\n\\n- 동일한 프롬프트를 사용하여 다른 LLM 배포(예: OpenAI, Azure OpenAI, Hugging Face)와 비교해 보세요. - 변화를 보셨나요?\\n- 동일한 프롬프트를 _동일한_ LLM 배포(예: Azure OpenAI Playground)를 사용하여 반복해 보세요. - 이러한 변동은 어떻게 달랐나요?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333598, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_25624ae3a5', usage=CompletionUsage(completion_tokens=560, prompt_tokens=378, total_tokens=938, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcfPjVPGheQVKqjmKWbbe0SKk5Fz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Fabrications 예시\\n\\n이 강의에서는 **\"fabrication\"(허구)**이라는 용어를 사용하여 LLMs가 훈련의 한계나 기타 제약으로 인해 사실과 다른 정보를 생성하는 현상을 언급합니다. 이 현상은 인기 기사나 연구 논문에서 _\"hallucinations\"(환각)_이라고도 불릴 수 있습니다. 그러나 기계 주도의 결과에 인간과 같은 특성을 부여하여 행동을 인간화하지 않기 위해 _\"fabrication\"_ 용어를 사용할 것을 강력히 권장합니다. 이는 또한 [책임 있는 AI 가이드라인](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst)에서 용어를 정리하는 측면에서도 도움이 되며, 상황에 따라 모욕적이거나 포괄적이지 않은 용어를 제거할 수 있습니다.\\n\\n허구가 어떻게 작동하는지 이해하고 싶으신가요? AI에게 훈련 데이터셋에 없는 주제에 대한 내용을 생성하라고 지시하는 프롬프트를 생각해 보세요. 예를 들어, 다음과 같은 프롬프트를 시도했습니다:\\n\\n> **프롬프트:** 2076년 화성 전쟁에 대한 수업 계획을 작성하세요.\\n\\n웹 검색을 통해 화성 전쟁에 대한 허구의 이야기(예: 텔레비전 시리즈나 책)가 있었지만 2076년에는 없다는 것을 알게 되었습니다. 또한 상식적으로도 2076년은 _미래_에 해당하므로 실제 사건과 관련이 없다는 것을 알 수 있습니다.\\n\\n그래서 이 프롬프트를 다른 LLM 제공자와 함께 실행했을 때 어떤 일이 발생하는지 살펴봅시다.\\n\\n> **응답 1**: OpenAI Playground (GPT-35)\\n\\n![응답 1](./images/04-fabrication-oai.png?WT.mc_id=academic-105485-koreyst)\\n\\n> **응답 2**: Azure OpenAI Playground (GPT-35)\\n\\n![응답 2](./images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)\\n\\n> **응답 3**: Hugging Face Chat Playground (LLama-2)\\n\\n![응답 3](./images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst)\\n\\n예상대로, 모델 (또는 모델 버전)마다 약간 다른 응답을 생성합니다. 이는 확률적 행동과 모델 기능의 차이 때문입니다. 예를 들어, 한 모델은 8학년 학생을 대상으로 하고 다른 모델은 고등학생을 대상으로 합니다. 하지만 세 모델 모두 사건이 실제라고 믿게 만들 수 있는 응답을 생성했습니다.\\n\\n_prompt engineering_ 기술인 _metaprompting_과 _온도 설정_(temperature configuration)과 같은 기술을 통해 모델의 허구 생성을 어느 정도 줄일 수 있습니다. 새로운 프롬프트 엔지니어링 _아키텍처_는 프롬프트 흐름에 새로운 도구와 기술을 원활하게 통합하여 이러한 효과를 완화하거나 줄일 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333607, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=687, prompt_tokens=572, total_tokens=1259, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcfXC6XRttJAPCOoqg5rwnasXwNL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 사례 연구: GitHub Copilot\\n\\n이 섹션을 마무리하면서 실제 솔루션에서 프롬프트 엔지니어링이 어떻게 사용되는지에 대한 감을 얻기 위해 사례 연구 하나를 살펴보겠습니다: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).\\n\\nGitHub Copilot은 \"AI 페어 프로그래머\"로, 텍스트 프롬프트를 코드 완성으로 변환하며, 개발 환경(예: Visual Studio Code)에 통합되어 매끄러운 사용자 경험을 제공합니다. 아래 블로그 시리즈에 문서화된 것처럼, 초기 버전은 OpenAI Codex 모델을 기반으로 했으나, 엔지니어들은 신속히 모델을 미세 조정하고 더 나은 프롬프트 엔지니어링 기술을 개발해야 코드 품질을 향상시킬 수 있다는 필요성을 깨달았습니다. 7월에는 [Codex를 넘어서는 개선된 AI 모델을 공개](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)하여 더 빠른 제안을 제공할 수 있게 되었습니다.\\n\\n그들의 학습 여정을 따라가려면 순서대로 포스트를 읽어보세요.\\n\\n- **2023년 5월** | [GitHub Copilot은 당신의 코드를 더 잘 이해하게 됩니다](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)\\n- **2023년 5월** | [GitHub 내부: GitHub Copilot의 LLM과 작업하기](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).\\n- **2023년 6월** | [GitHub Copilot을 위한 더 나은 프롬프트를 작성하는 방법](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).\\n- **2023년 7월** | [Codex를 넘어서 개선된 AI 모델로 GitHub Copilot](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)\\n- **2023년 7월** | [프롬프트 엔지니어링과 LLM에 대한 개발자 가이드](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)\\n- **2023년 9월** | [엔터프라이즈 LLM 앱 구축 방법: GitHub Copilot에서의 교훈](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)\\n\\n또한 [엔지니어링 블로그](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst)에서 [이 블로그](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst)와 같은 게시물을 찾아 실제 응용 프로그램을 구동하는 데 모델과 기술이 어떻게 적용되는지 볼 수 있습니다.\\n\\n---\\n\\n<!--\\n레슨 템플릿:\\n이 단위는 핵심 개념 #2를 다루어야 합니다.\\n예제와 참고 자료로 개념을 강화하세요.\\n\\n개념 #2:\\n프롬프트 디자인.\\n예제로 설명됨.\\n-->', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333615, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=875, prompt_tokens=771, total_tokens=1646, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcffThxu8DbfQ5L8h2Hjmya0oIcu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 프롬프트 구성\\n\\n프롬프트 엔지니어링이 중요한 이유를 살펴보았으므로 이제 프롬프트가 _구성_되는 방식을 이해하여 더 효과적인 프롬프트 디자인을 위해 다양한 기술을 평가할 수 있도록 합시다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333623, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=62, prompt_tokens=61, total_tokens=123, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcfjmepHdgqw5kgEYN0C8kNyF6st', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 기본 프롬프트\\n\\n기본 프롬프트부터 시작해 봅시다: 아무런 추가적인 맥락 없이 모델에 전송된 텍스트 입력입니다. 다음은 예시입니다 - 미국 국가의 첫 몇 마디를 OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst)에 전송하면 곧바로 다음 몇 줄을 _완성_해서 응답을 보여줍니다. 이는 기본적인 예측 동작을 설명해줍니다.\\n\\n| 프롬프트 (입력)  | 완성 (출력)                                                                                           |\\n| :--------------- | :----------------------------------------------------------------------------------------------------- |\\n| Oh say can you see | \"The Star-Spangled Banner\"의 가사를 시작하는 것 같군요. 미국 국가의 전체 가사는 다음과 같습니다 ... |', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333627, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=186, prompt_tokens=181, total_tokens=367, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcflgUd1kEJehhqtEraUnUMtrl2u', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 복잡한 프롬프트\\n\\n이제 해당 기본 프롬프트에 컨텍스트와 지침을 추가해 보겠습니다. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst)를 사용하면 메시지 모음을 통해 복잡한 프롬프트를 구성할 수 있습니다. 이 메시지 모음에는 다음이 포함됩니다:\\n\\n- _사용자_ 입력과 _어시스턴트_ 응답을 반영한 입력/출력 쌍.\\n- 어시스턴트의 동작 또는 성향에 대한 컨텍스트를 설정하는 시스템 메시지.\\n\\n요청은 이제 아래와 같은 형식으로 이루어지며, 여기서 _토크나이제이션_은 컨텍스트와 대화에서 관련 정보를 효과적으로 캡처합니다. 이제 시스템 컨텍스트를 변경하는 것이 제공된 사용자 입력만큼이나 응답의 품질에 큰 영향을 미칠 수 있습니다.\\n\\n```python\\nresponse = openai.chat.completions.create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[\\n        {\"role\": \"system\", \"content\": \"당신은 도움이 되는 어시스턴트입니다.\"},\\n        {\"role\": \"user\", \"content\": \"2020년 월드 시리즈 우승팀은 누구인가요?\"},\\n        {\"role\": \"assistant\", \"content\": \"2020년 월드 시리즈에서는 로스앤젤레스 다저스가 우승했습니다.\"},\\n        {\"role\": \"user\", \"content\": \"어디서 열렸나요?\"}\\n    ]\\n)\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333629, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=355, prompt_tokens=283, total_tokens=638, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcfrBj4w2iIrrCmyjcBeoxno2T3z', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 설명 프롬프트\\n\\n위의 예에서 사용자 프롬프트는 정보를 요청으로 해석될 수 있는 간단한 텍스트 쿼리였습니다. _지시_ 프롬프트를 사용하면 텍스트를 사용하여 작업을 더 자세히 지정하고 AI에게 더 나은 지침을 제공할 수 있습니다. 여기에 예시가 있습니다:\\n\\n| 프롬프트 (입력)                                                                               | 완성 (출력)                                                                                                    | 지시 유형       |\\n| :------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------ | :------------- |\\n| 남북 전쟁에 대한 설명을 작성하세요.                                                           | _간단한 단락을 반환함_                                                                                        | 간단한         |\\n| 남북 전쟁에 대한 설명을 작성하세요. 주요 날짜와 사건을 제공하고 그 중요성을 설명하세요.          | _단락과 함께 주요 사건 날짜와 설명 목록을 반환함_                                                             | 복잡한         |\\n| 남북 전쟁에 대한 설명을 한 단락으로 작성하세요. 중요한 날짜와 그 중요성을 설명하는 포인트 3개를 제공하세요. 중요한 역사적 인물과 그들의 기여를 설명하는 포인트 3개를 추가로 제공하세요. 출력을 JSON 파일로 반환하세요. | _복사-붙여넣기 할 수 있도록 텍스트 상자에 포맷된 JSON을 반환함. 필요에 따라 유효성을 검사할 수 있음_          | 복잡한. 포맷된. |', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333635, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=314, prompt_tokens=265, total_tokens=579, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcfy6LoJTqiOzowsrh3clzUrPS0Z', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 기본 내용\\n\\n위의 예제에서는 프롬프트가 여전히 비교적 개방적이어서 LLM이 사전 학습된 데이터셋에서 어떤 부분이 관련이 있는지를 결정하게 했습니다. 기본 내용 디자인 패턴에서는 입력 텍스트가 두 부분으로 나뉩니다:\\n\\n- 명령 (작업 수행)\\n- 관련 내용 (작업에 영향을 미치는 내용)\\n\\n여기서 명령이 \"이 내용을 2문장으로 요약하라\"는 예를 들어보겠습니다.\\n\\n| 프롬프트 (입력)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 완성 (출력)                                                                                                                                                                                                                                                                                       |\\n| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\\n| 목성은 태양에서 다섯 번째 행성이며 태양계에서 가장 큽니다. 목성은 태양의 천분의 일 질량을 가지고 있지만, 태양계의 다른 모든 행성을 합한 것의 두 배 반 질량을 가집니다. 목성은 육안으로 볼 수 있는 가장 밝은 물체 중 하나이며, 기록된 역사 이전부터 고대 문명에 알려져 왔습니다. 목성은 로마 신 목성의 이름을 따왔습니다. 지구에서 바라볼 때 목성은 반사된 빛으로 인해 가시적인 그림자를 만들 만큼 밝을 수 있으며, 평균적으로 달과 금성 다음으로 밤하늘에서 세 번째로 밝은 천연 물체입니다. <br/> **이 내용을 2문장으로 요약하라** | 목성은 태양에서 다섯 번째 행성이자 태양계에서 가장 크며 밤하늘에서 가장 밝은 물체 중 하나입니다. 로마 신 목성의 이름을 딴 이 가스 거인은 태양계의 다른 모든 행성을 합한 것의 두 배 반에 달하는 질량을 가집니다. |\\n\\n기본 내용 부분은 더 효과적인 지시를 내리기 위해 여러 가지 방법으로 사용될 수 있습니다:\\n\\n- **예제** - 모델에게 명시적인 지시를 내리기보다는 모델이 무엇을 해야 하는지 예제를 제공하고, 패턴을 유추하도록 합니다.\\n- **큐** - 지시 후에 \"큐\"를 추가하여 출력을 미리 준비시키고, 모델이 더 관련성 있는 응답을 하도록 유도합니다.\\n- **템플릿** - 특정 사용 사례에 맞게 데이터를 커스터마이즈할 수 있는 자리 표시자(변수)가 있는 반복 가능한 \\'레시피\\'입니다.\\n\\n이제 이러한 내용을 실제로 적용해보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333642, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=561, prompt_tokens=474, total_tokens=1035, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcg4MnDLmwpkSG7QTV3fXAkoUHML', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 예제 사용\\n\\n이 방법은 주어진 지침에 대한 원하는 출력의 예시를 모델에 제공하여 \"피드\"하고, 모델이 원하는 출력의 패턴을 추론하게 하는 접근 방식입니다. 제공된 예시의 수에 따라 제로샷 프롬프팅, 원샷 프롬프팅, 퓨샷 프롬프팅 등으로 분류할 수 있습니다.\\n\\n프롬프트는 이제 세 가지 구성 요소로 이루어집니다:\\n\\n- 작업 설명\\n- 원하는 출력의 몇 가지 예시\\n- 새로운 예시의 시작 (암묵적인 작업 설명이 됨)\\n\\n| 학습 유형    | 프롬프트 (입력)                                                                                                                                              | 완성 (출력)                  |\\n| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------- |\\n| 제로샷       | \"The Sun is Shining\". 스페인어로 번역하기                                                                                                                      | \"El Sol está brillando\".     |\\n| 원샷         | \"The Sun is Shining\" => \"El Sol está brillando\". <br> \"It\\'s a Cold and Windy Day\" =>                                                                       | \"Es un día frío y ventoso\".  |\\n| 퓨샷         | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk =>       | Basketball                   |\\n|              |                                                                                                                                                             |                              |\\n\\n제로샷 프롬프팅에서는 명시적 지침(\"스페인어로 번역하기\")을 제공해야 했던 방식과 달리, 원샷 프롬프팅 예시에서는 지침이 암묵적으로 추론됩니다. 퓨샷 예시는 더 많은 예시를 추가함으로써 모델이 명시적인 지침 없이도 보다 정확한 추론을 하게 되는 과정을 보여줍니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333648, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=409, prompt_tokens=339, total_tokens=748, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcgBEIeZ5gJExEA15epitZapC33X', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 프롬프트 단서\\n\\n주요 콘텐츠를 사용하는 또 다른 기술은 _단서_를 제공하는 것입니다. 이 경우, 우리는 모델에게 원하는 응답 형식을 반영하는 스니펫을 제공하여 올바른 방향으로 _시작_하도록 유도합니다. 모델은 그런 다음 \"단서\"를 받아 계속 진행합니다.\\n\\n| 단서의 수 | 프롬프트 (입력)                                                                                                                                                                                                                                                                                                                                                                                                                                               | 완료 (출력)                                                                                                                                                                                                                                                                                        |\\n| :-------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\\n| 0         | 목성은 태양에서 다섯 번째 행성이며 태양계에서 가장 큰 행성입니다. 질량은 태양의 1/1000 정도이지만, 태양계의 다른 모든 행성들을 합친 것의 두 배 반이나 됩니다. 목성은 육안으로 관찰할 수 있는 가장 밝은 천체 중 하나이며, 기록된 역사 이전부터 고대 문명에 알려져 있었습니다. <br/>**요약하기**                                                                                                                                                           | 목성은 태양계에서 가장 큰 행성이며 태양으로부터 다섯 번째 행성입니다. 질량은 태양의 1/1000 정도이지만, 다른 모든 행성들을 합한 것보다 무겁습니다. 고대 문명은 오래전부터 목성을 알고 있었고, 목성은 밤하늘에서 쉽게 볼 수 있습니다.                                                                                                                                                |\\n| 1         | 목성은 태양에서 다섯 번째 행성이며 태양계에서 가장 큰 행성입니다. 질량은 태양의 1/1000 정도이지만, 태양계의 다른 모든 행성들을 합친 것의 두 배 반이나 됩니다. 목성은 육안으로 관찰할 수 있는 가장 밝은 천체 중 하나이며, 기록된 역사 이전부터 고대 문명에 알려져 있었습니다. <br/>**요약하기** <br/> 우리가 배운 것은 목성이                                                                                               | 태양으로부터 다섯 번째 행성이며 태양계에서 가장 큰 행성입니다. 질량은 태양의 1/1000 정도이지만, 다른 모든 행성들을 합친 것의 두 배 반입니다. 육안으로 쉽게 관찰할 수 있으며, 고대부터 알려져 있었습니다.                                                                                                           |\\n| 2         | 목성은 태양에서 다섯 번째 행성이며 태양계에서 가장 큰 행성입니다. 질량은 태양의 1/1000 정도이지만, 태양계의 다른 모든 행성들을 합친 것의 두 배 반이나 됩니다. 목성은 육안으로 관찰할 수 있는 가장 밝은 천체 중 하나이며, 기록된 역사 이전부터 고대 문명에 알려져 있었습니다. <br/>**요약하기** <br/> 우리가 배운 상위 3가지 사실:                                                                                              | 1. 목성은 태양에서 다섯 번째 행성이며 태양계에서 가장 큰 행성입니다. <br/> 2. 질량은 태양의 1/1000이지만 다른 모든 행성들을 합친 것보다 큽니다. <br/> 3. 목성은 고대부터 육안으로 관찰할 수 있었습니다.                                                                                                         |\\n|           |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                   |', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333655, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=715, prompt_tokens=652, total_tokens=1367, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcgO27n6nB8mtPVwmGyfd8exBlrp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 프롬프트 템플릿\\n\\n프롬프트 템플릿은 _프롬프트를 위한 사전 정의된 레시피_ 로, 필요할 때 저장하고 재사용할 수 있어 대규모 사용자 경험을 보다 일관되게 제공할 수 있습니다. 가장 간단한 형태에서는 [OpenAI의 이 예시](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst)처럼 프롬프트 예시들의 모음으로, 인터랙티브 프롬프트 구성 요소(사용자 및 시스템 메시지)와 API 기반 요청 형식을 제공하여 재사용을 지원합니다.\\n\\n좀 더 복잡한 형태에서는 [LangChain의 이 예시](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/?WT.mc_id=academic-105485-koreyst)처럼 _플레이스홀더_ 를 포함하여 사용자의 입력, 시스템 컨텍스트, 외부 데이터 소스 등 다양한 소스의 데이터를 대체하여 동적으로 프롬프트를 생성할 수 있습니다. 이를 통해 일관된 사용자 경험을 **프로그래밍 방식으로** 대규모로 구동할 수 있는 재사용 가능한 프롬프트 라이브러리를 만들 수 있습니다.\\n\\n마지막으로, 템플릿의 진정한 가치는 특정 응용 분야를 위해 _프롬프트 라이브러리_ 를 생성하고 게시할 수 있다는 점에 있습니다. 이제 프롬프트 템플릿은 응용 프로그램 특유의 컨텍스트나 예시를 반영하여 목표 사용자 층에게 더 관련성 있고 정확한 응답을 제공할 수 있도록 최적화됩니다. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) 저장소는 교육 분야에서 수업 계획, 교육과정 설계, 학생 지도 등 핵심 목표에 중점을 두어 프롬프트 라이브러리를 선정하며 이 접근법의 훌륭한 예시입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333668, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=439, prompt_tokens=350, total_tokens=789, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcgTTst7kAGRMIi8lh6YQCfeQIr8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 보조 콘텐츠\\n\\n프롬프트 구성을 지시 사항(작업)과 목표(주요 콘텐츠)로 생각한다면, _보조 콘텐츠_ 는 **결과를 어떤 방식으로든 영향을 줄 수 있는** 추가적인 맥락을 제공하는 것입니다. 이는 매개변수 조정, 형식 지침, 주제 분류 등 사용자가 원하는 목표나 기대에 맞게 모델이 응답을 _조정_ 하도록 도울 수 있는 것입니다.\\n\\n예를 들어: 모든 사용 가능한 강좌에 대한 이름, 설명, 수준, 메타데이터 태그, 강사 등 광범위한 메타데이터를 포함한 강좌 카탈로그가 주어졌을 때:\\n\\n- \"2023년 가을 학기 강좌 카탈로그 요약\"이라는 지시를 정의할 수 있습니다.\\n- 원하는 출력 형식의 예시를 제공하기 위해 주요 콘텐츠를 사용할 수 있습니다.\\n- 관심 있는 상위 5개의 \\'태그\\'를 식별하기 위해 보조 콘텐츠를 사용할 수 있습니다.\\n\\n이제 모델은 몇 가지 예시에서 보여준 형식으로 요약을 제공할 수 있습니다 - 그러나 결과에 여러 태그가 있는 경우, 보조 콘텐츠에서 식별된 5개의 태그를 우선시할 수 있습니다.\\n\\n---\\n\\n<!--\\n수업 템플릿:\\n이 단위는 핵심 개념 #1을 다루어야 합니다.\\n예제와 참조를 통해 개념을 강화합니다.\\n\\n개념 #3:\\n프롬프트 엔지니어링 기법.\\n프롬프트 엔지니어링의 기본 기법에는 어떤 것들이 있나요?\\n연습 문제로 설명해 보세요.\\n-->', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333673, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=362, prompt_tokens=286, total_tokens=648, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcgZGeWhlB6scTrE3svBLug17ypY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 프롬프트 설계의 모범 사례\\n\\n프롬프트가 _구성_될 수 있는 방법을 알게 되었으니, 이제는 이를 _설계_하여 모범 사례를 반영하는 방법을 생각해 볼 수 있습니다. 이를 두 가지 부분으로 나눠서 생각할 수 있습니다. 올바른 _사고방식_을 가지는 것과 올바른 _기술_을 적용하는 것입니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333679, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=95, prompt_tokens=86, total_tokens=181, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcgbPFsAMtjNvBDE6ymJPyALEAYw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 프롬프트 엔지니어링 마인드셋\\n\\n프롬프트 엔지니어링은 시도와 오류 과정을 통해 이루어지므로 다음 세 가지 주요 지침을 기억하십시오:\\n\\n1. **도메인 이해가 중요합니다.** 응답의 정확성과 관련성은 해당 애플리케이션이나 사용자가 작동하는 _도메인_의 함수입니다. 당신의 직감과 도메인 전문 지식을 사용하여 **기술을 맞춤화**하십시오. 예를 들어, 시스템 프롬프트에서 _도메인 특화된 성격_을 정의하거나, 사용자 프롬프트에서 _도메인 특화 템플릿_을 사용할 수 있습니다. 도메인 특화된 맥락을 반영하는 부가 콘텐츠를 제공하거나, _도메인 특화된 단서와 예시_를 사용하여 모델이 익숙한 사용 패턴으로 유도할 수 있습니다.\\n\\n2. **모델 이해가 중요합니다.** 모델은 본질적으로 확률적입니다. 하지만 모델 구현은 학습 데이터셋(사전 학습된 지식), 제공하는 기능(API 또는 SDK를 통해) 및 최적화된 콘텐츠 유형(코드, 이미지, 텍스트 등)에 따라 다를 수 있습니다. 사용 중인 모델의 강점과 한계를 이해하고, 그 지식을 사용하여 _작업을 우선순위화_하거나 모델의 기능에 맞게 최적화된 _맞춤화된 템플릿_을 구축하십시오.\\n\\n3. **반복과 검증이 중요합니다.** 모델은 빠르게 진화하고 있으며, 프롬프트 엔지니어링 기술 또한 마찬가지입니다. 도메인 전문가로서, 다른 관련 맥락이나 특정 애플리케이션에 대한 기준이 있을 수 있으며, 이는 보다 넓은 커뮤니티에 적용되지 않을 수도 있습니다. 프롬프트 엔지니어링 도구 및 기술을 사용하여 프롬프트 구성을 \"빠르게 시작\"하고, 직감과 도메인 전문 지식을 사용하여 결과를 반복하고 검증하십시오. 통찰을 기록하고 **지식 베이스**(예: 프롬프트 라이브러리)를 만들어 다른 사람들이 미래에 더 빠르게 반복할 수 있는 새로운 기준으로 활용할 수 있도록 하십시오.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333681, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=506, prompt_tokens=366, total_tokens=872, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcggyQRsZWFlAEkqW6dhc4efUZWE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 모범 사례\\n\\n이제 [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) 및 [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) 전문가들이 권장하는 일반적인 모범 사례를 살펴보겠습니다.\\n\\n| 목적                              | 이유                                                                                                                                                                                                                                               |\\n| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\\n| 최신 모델 평가                   | 새로운 모델 세대는 개선된 기능과 품질을 가질 가능성이 높지만, 비용이 더 많이 들 수 있습니다. 영향을 평가한 후, 마이그레이션 결정을 내리십시오.                                                                                                   |\\n| 지시사항 및 컨텍스트 분리        | 모델/제공자가 지시사항, 주요 콘텐츠 및 부수적 콘텐츠를 더 명확하게 구분하기 위한 _구분자_를 정의하는지 확인하십시오. 이는 모델이 토큰에 더 정확하게 가중치를 할당하는 데 도움이 될 수 있습니다.                                                    |\\n| 구체적이고 명확하게              | 원하는 컨텍스트, 결과물, 길이, 형식, 스타일 등에 대해 더 많은 세부 정보를 제공하십시오. 이는 응답의 품질과 일관성을 향상시킵니다. 재사용 가능한 템플릿으로 요리법을 캡처하십시오.                                                        |\\n| 설명적이고 예시를 사용           | 모델은 \"보여주고 말하기\" 접근 방식에 더 잘 반응할 수 있습니다. 예시를 제공하지 않는 `zero-shot` 접근 방식으로 시작한 다음, 원하는 출력의 몇 가지 예시를 제공하는 `few-shot` 접근 방식으로 미세 조정해보십시오. 유추를 사용하십시오.                                        |\\n| 완료를 시작하는 신호 사용        | 모델이 응답의 시작점으로 사용할 수 있는 몇 가지 선행 단어나 구문을 제공하여 원하는 결과로 유도하십시오.                                                                                                                                        |\\n| 반복 강조                       | 때로는 모델에 반복해서 지시해야 할 수도 있습니다. 주요 콘텐츠 전후에 지시사항을 제공하거나 지시사항과 신호를 함께 사용하십시오. 반복하여 검증하고 어떤 방법이 효과적인지 확인하십시오.                                                        |\\n| 순서가 중요                      | 학습 예시에서도 정보를 모델에 제공하는 순서가 출력에 영향을 미칠 수 있습니다. 다양한 옵션을 시도하여 어떤 것이 가장 잘 작동하는지 확인하십시오.                                                                                                 |\\n| 모델에 이런 경우를 제공          | 모델이 어떤 이유로든 작업을 완료하지 못할 경우 제공할 _대체_ 응답을 제공하십시오. 이는 모델이 거짓이나 조작된 응답을 생성할 가능성을 줄이는 데 도움이 될 수 있습니다.                                                                         |\\n|                                   |                                                                                                                                                                                                                                                   |\\n\\n모든 모범 사례와 마찬가지로, 모델, 작업 및 도메인에 따라 _개인의 경험이 다를 수 있다는 점_을 기억하십시오. 이를 출발점으로 삼아, 반복적으로 어떤 것이 가장 잘 작동하는지 알아보십시오. 새로운 모델과 도구가 제공됨에 따라 프로세스 확장성과 응답 품질에 중점을 두고 프롬프트 엔지니어링 과정을 지속적으로 재평가하십시오.\\n\\n<!--\\nLESSON TEMPLATE:\\n이 단원에는 적용 가능한 경우 코드 챌린지를 제공해야 합니다.\\n\\nCHALLENGE:\\n지시사항에 코드 주석만 있는 Jupyter Notebook 링크(코드 섹션은 비어 있음).\\n\\nSOLUTION:\\n지시사항이 번역되고 실행된 그 Notebook의 복사본 링크, 한 가지 예시를 보여줌.\\n-->', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333686, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=795, prompt_tokens=649, total_tokens=1444, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABch3VeXpFixe1Rb88pFwNJ8e8fZA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n축하합니다! 드디어 수업의 마지막에 도달하셨습니다! 이제 실제 예제를 통해 그동안 배운 개념과 기법들을 테스트해 볼 시간입니다!\\n\\n과제는 인터랙티브하게 완료할 수 있는 Jupyter Notebook을 사용할 것입니다. 또한 여러분만의 Markdown과 코드 셀을 추가하여 아이디어와 기법을 탐구할 수도 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333709, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c047b7b4ec', usage=CompletionUsage(completion_tokens=85, prompt_tokens=101, total_tokens=186, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABch4PXPbSCM94TGLKFROzAd0NjoP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 시작하려면, 리포지토리를 포크한 다음\\n\\n- (권장) GitHub Codespaces 실행\\n- (또는) 리포지토리를 로컬 장치에 클론하고 Docker Desktop과 함께 사용\\n- (또는) 선호하는 Notebook 실행 환경에서 Notebook 열기\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333710, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=66, prompt_tokens=81, total_tokens=147, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABch6t5JM6BRoEKlYzj7f0CLaDcUg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 다음으로 환경 변수를 구성하세요\\n\\n- 저장소 루트에 있는 `.env.copy` 파일을 `.env`로 복사하고 `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` 및 `AZURE_OPENAI_DEPLOYMENT` 값을 입력하세요. [Learning Sandbox 섹션](./04-prompt-engineering-fundamentals#learning-sandbox)으로 돌아가서 방법을 학습하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333712, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=90, prompt_tokens=109, total_tokens=199, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABch8HtFO6x5JwhMLAwNN7AuAn0pT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Jupyter Notebook 열기\\n\\n- 런타임 커널을 선택합니다. 옵션 1 또는 2를 사용하는 경우, dev 컨테이너에서 제공하는 기본 Python 3.10.x 커널을 선택하면 됩니다.\\n\\n이제 연습을 실행할 준비가 되었습니다. 여기에는 _정답과 오답_이 없음을 유의하세요 - 단지 시행착오를 통해 다양한 옵션을 탐색하고 주어진 모델과 응용 도메인에 적합한 것이 무엇인지에 대한 직관을 구축하는 과정입니다.\\n\\n_이러한 이유로 이 수업에는 코드 솔루션 세그먼트가 없습니다. 대신 Notebook에는 참조용으로 하나의 예시 출력을 보여주는 \"내 솔루션:\" 이라는 제목의 Markdown 셀이 있을 것입니다._\\n\\n <!--\\nLESSON TEMPLATE:\\nWrap the section with a summary and resources for self-guided learning.\\n-->', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333714, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=189, prompt_tokens=166, total_tokens=355, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchAdfZaXMbHpS2HkipK9xVdzVp6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 확인\\n\\n다음 중 합리적인 모범 사례를 따르는 좋은 프롬프트는 무엇인가요?\\n\\n1. 빨간색 자동차의 이미지를 보여주세요.\\n2. 해가 지는 절벽 옆에 주차된 볼보 XC90 모델의 빨간색 자동차의 이미지를 보여주세요.\\n3. 볼보 XC90 모델의 빨간색 자동차의 이미지를 보여주세요.\\n\\nA: 2번, 이는 \"무엇\"에 대한 세부 사항을 제공하며 구체적인 차량(아무 자동차가 아닌 특정 제작사와 모델을 포함하여)과 전체적인 배경도 함께 설명하기 때문에 가장 좋은 프롬프트입니다. 3번은 많은 설명을 포함하고 있기 때문에 그 다음으로 좋습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333716, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=160, prompt_tokens=153, total_tokens=313, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchDIb4gRj14LF8qJkeerToMVIZB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 🚀 챌린지\\n\\n다음의 \"큐\" 기술을 사용해 보세요: 프롬프트를 사용하여 \"빨간색 볼보 자동차의 이미지를 보여주고 \" 문장을 완성하세요. 이것은 어떤 응답을 내놓나요, 그리고 어떻게 개선할 수 있을까요?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333719, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=67, prompt_tokens=76, total_tokens=143, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchFzDXdP8rvzrM4KYmaUBDV2EEa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 학습을 계속하세요\\n\\n다양한 프롬프트 엔지니어링 개념에 대해 더 배우고 싶으신가요? [지속 학습 페이지](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)에서 이 주제에 대한 다른 훌륭한 리소스를 찾을 수 있습니다.\\n\\n레슨 5로 이동하여 [고급 프롬프트 기술](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)을 살펴보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333721, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=130, prompt_tokens=122, total_tokens=252, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchH90mbuLf1AIj2mcs2CDhrTpVn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 이 과정 시작하기\\n\\n여러분이 이 과정을 시작하고 생성형 인공지능(Generative AI)을 사용하여 무엇을 만들지 영감을 받기를 매우 기대합니다!\\n\\n여러분의 성공을 보장하기 위해 이 페이지에서는 설정 단계, 기술 요구 사항 및 필요할 경우 도움을 받을 수 있는 곳을 설명합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333723, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=72, prompt_tokens=80, total_tokens=152, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchIvou9LBWGzLGdYVNVD4h6JGjz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 설정 단계\\n\\n이 과정을 시작하려면 다음 단계를 완료해야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333724, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=17, prompt_tokens=47, total_tokens=64, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchJBiCCniudTdWxQZ7hAF4fhZIW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 1. 이 저장소 포크하기\\n\\n자신의 GitHub 계정으로 코드를 변경하고 챌린지를 완료할 수 있도록 [이 저장소 전체를 포크](https://github.com/microsoft/generative-ai-for-beginners/fork?WT.mc_id=academic-105485-koreyst)하세요. 또한, 이 저장소를 보다 쉽게 찾고 관련 저장소를 확인하려면 [이 저장소에 별(🌟)을 추가](https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst)할 수도 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333725, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=140, prompt_tokens=144, total_tokens=284, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchLfUyCHkDS90rTViv8vpKG3ePk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 2. 코드스페이스 생성\\n\\n코드를 실행할 때 발생할 수 있는 종속성 문제를 피하기 위해서, 이 강좌를 [GitHub Codespaces](https://github.com/features/codespaces?WT.mc_id=academic-105485-koreyst)에서 실행할 것을 권장합니다.\\n\\n이것은 이 저장소를 포크한 버전에서 `Code` 옵션을 선택하고 **Codespaces** 옵션을 선택하여 생성할 수 있습니다.\\n\\n![코드스페이스를 생성하는 버튼이 표시된 대화상자](./images/who-will-pay.webp?WT.mc_id=academic-105485-koreyst)\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333727, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=140, prompt_tokens=140, total_tokens=280, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchNedyN3THBLKC4wBJydRXsQjEa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 3. API 키 저장\\n\\n애플리케이션을 구축할 때 API 키를 안전하게 보관하는 것은 매우 중요합니다. API 키를 코드에 직접 저장하지 않는 것을 권장합니다. 이러한 세부 정보를 공개된 저장소에 커밋하면 보안 문제나 악의적인 사용자에 의해 발생할 수 있는 예기치 않은 비용이 발생할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333729, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=82, prompt_tokens=91, total_tokens=173, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchOOGJNPJlisK68j7ggtntheaS9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 로컬 컴퓨터에서 실행하는 방법\\n\\n로컬 컴퓨터에서 코드를 실행하려면 [Python 설치](https://www.python.org/downloads/?WT.mc_id=academic-105485-koreyst)가 필요합니다.\\n\\n저장소를 사용하려면, 저장소를 클론해야 합니다:\\n\\n```shell\\ngit clone https://github.com/microsoft/generative-ai-for-beginners\\ncd generative-ai-for-beginners\\n```\\n\\n모든 준비가 완료되면 시작할 수 있습니다!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333730, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=105, prompt_tokens=132, total_tokens=237, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchQcMPLlV3ea2qEOhH8qgWxg7qP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Miniconda 설치 (선택적 단계)\\n\\n[Miniconda](https://conda.io/en/latest/miniconda.html?WT.mc_id=academic-105485-koreyst)는 [Conda](https://docs.conda.io/en/latest?WT.mc_id=academic-105485-koreyst), Python 및 몇 가지 패키지를 설치할 수 있는 가벼운 설치 프로그램입니다. Conda 자체는 패키지 관리자이며, 다양한 Python [**가상 환경**](https://docs.python.org/3/tutorial/venv.html?WT.mc_id=academic-105485-koreyst) 및 패키지 간의 설정 및 전환을 쉽게 할 수 있게 해줍니다. 또한 `pip`를 통해 사용할 수 없는 패키지를 설치할 때 유용합니다.\\n\\n[MiniConda 설치 가이드](https://docs.anaconda.com/free/miniconda/#quick-command-line-install?WT.mc_id=academic-105485-koreyst)를 따라 설정할 수 있습니다.\\n\\nMiniconda가 설치된 상태에서, [레포지토리](https://github.com/microsoft/generative-ai-for-beginners/fork?WT.mc_id=academic-105485-koreyst)를 클론해야 합니다 (아직 클론하지 않았다면).\\n\\n다음으로, 가상 환경을 생성해야 합니다. Conda를 사용하여 이를 수행하려면, 새 환경 파일 (_environment.yml_)을 생성합니다. Codespaces를 사용하여 따라가고 있다면, `.devcontainer` 디렉토리 내에 이를 생성하여 `.devcontainer/environment.yml`이 되도록 합니다.\\n\\n아래의 코드 조각으로 환경 파일을 채워줍니다:\\n\\n```yml\\nname: <environment-name>\\nchannels:\\n - defaults\\ndependencies:\\n- python=<python-version>\\n- openai\\n- python-dotenv\\n- azure-ai-inference\\n```\\n\\n환경 파일은 우리가 필요한 의존성을 명시합니다. `<environment-name>`은 Conda 환경에 사용할 이름을 의미하며, `<python-version>`은 사용할 Python 버전을 의미합니다. 예를 들어, `3`은 Python의 최신 주요 버전입니다.\\n\\n이제 명령줄/터미널에서 아래 명령어를 실행하여 Conda 환경을 생성할 수 있습니다:\\n\\n```bash\\nconda env create --name ai4beg --file .devcontainer/environment.yml # .devcontainer 하위 경로는 Codespace 설정에만 해당됩니다.\\nconda activate ai4beg\\n```\\n\\n문제가 발생하면 [Conda 환경 가이드](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html?WT.mc_id=academic-105485-koreyst)를 참조하십시오.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333732, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=565, prompt_tokens=551, total_tokens=1116, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchZK9V3XdudcUpZTR7jonRfRUZm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Python 지원 확장이 있는 Visual Studio Code 사용하기\\n\\n이 과정을 위해 [Visual Studio Code (VS Code)](http://code.visualstudio.com/?WT.mc_id=academic-105485-koreyst) 편집기와 [Python 지원 확장](https://marketplace.visualstudio.com/items?itemName=ms-python.python&WT.mc_id=academic-105485-koreyst)을 설치하는 것을 추천합니다. 그러나 이는 권장 사항일 뿐 필수 요건은 아닙니다.\\n\\n> **참고**: VS Code에서 과정 저장소를 열면, 컨테이너 내에서 프로젝트를 설정할 수 있는 옵션이 제공됩니다. 이는 과정 저장소 내에 있는 [특별한 `.devcontainer` 디렉토리](https://code.visualstudio.com/docs/devcontainers/containers?itemName=ms-python.python&WT.mc_id=academic-105485-koreyst) 때문입니다. 이에 대해서는 나중에 더 자세히 설명하겠습니다.\\n\\n> **참고**: 디렉토리를 클론하고 VS Code에서 열면 Python 지원 확장을 설치하라고 자동으로 제안할 것입니다.\\n\\n> **참고**: VS Code가 저장소를 컨테이너에서 다시 열라고 제안하면, 로컬에 설치된 Python 버전을 사용하기 위해 이 요청을 거부하십시오.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333741, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=278, prompt_tokens=267, total_tokens=545, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchgP82Ub4ZsgGKwKMnRgVyGa2y1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 브라우저에서 Jupyter 사용하기\\n\\n브라우저 내에서 [Jupyter 환경](https://jupyter.org?WT.mc_id=academic-105485-koreyst)을 사용하여 프로젝트를 진행할 수도 있습니다. 클래식 Jupyter와 [Jupyter Hub](https://jupyter.org/hub?WT.mc_id=academic-105485-koreyst)는 자동 완성, 코드 강조 표시 등 다양한 기능을 제공하여 매우 쾌적한 개발 환경을 제공합니다.\\n\\n로컬에서 Jupyter를 시작하려면 터미널/명령 줄로 이동하여, 코스 디렉토리로 이동한 다음 다음 명령을 실행하십시오:\\n\\n```bash\\njupyter notebook\\n```\\n\\n또는\\n\\n```bash\\njupyterhub\\n```\\n\\n이 명령을 실행하면 Jupyter 인스턴스가 시작되고, 접속할 URL이 명령 줄 창에 표시됩니다.\\n\\nURL에 접속하면 코스 개요가 보이고, 원하는 `*.ipynb` 파일로 이동할 수 있습니다. 예를 들어, `08-building-search-applications/python/oai-solution.ipynb`.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333748, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=234, prompt_tokens=233, total_tokens=467, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchpHu0xh61L9toykweynQtXY4mE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 컨테이너에서 실행하기\\n\\n컴퓨터나 Codespace에 모든 것을 설정하는 것의 대안으로 [컨테이너](https://en.wikipedia.org/wiki/Containerization_(computing)?WT.mc_id=academic-105485-koreyst)를 사용하는 방법이 있습니다. 코스 저장소 내의 특별한 `.devcontainer` 폴더는 VS Code가 컨테이너 내에서 프로젝트를 설정할 수 있도록 해줍니다. Codespaces 외부에서 이 작업을 수행하려면 Docker를 설치해야 하며, 솔직히 말해 약간의 작업이 필요하지만, 컨테이너 작업에 익숙한 사람들에게만 권장합니다.\\n\\nGitHub Codespaces를 사용할 때 API 키를 안전하게 유지하는 가장 좋은 방법 중 하나는 Codespace Secrets를 사용하는 것입니다. 이에 대한 자세한 내용을 알아보려면 [Codespaces 비밀 관리](https://docs.github.com/en/codespaces/managing-your-codespaces/managing-secrets-for-your-codespaces?WT.mc_id=academic-105485-koreyst) 가이드를 따르십시오.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333757, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=230, prompt_tokens=218, total_tokens=448, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchs44VJ9aMx71y4w4qrIm1gtELO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 수업과 기술 요구 사항\\n\\n이 강의에는 6개의 개념 수업과 6개의 코딩 수업이 포함되어 있습니다.\\n\\n코딩 수업에서는 Azure OpenAI 서비스를 사용합니다. 이 코드를 실행하려면 Azure OpenAI 서비스에 대한 액세스와 API 키가 필요합니다. 액세스를 받으려면 [이 신청서 작성](https://azure.microsoft.com/products/ai-services/openai-service?WT.mc_id=academic-105485-koreyst)을 통해 신청할 수 있습니다.\\n\\n신청서가 처리되는 동안 각 코딩 수업에는 코드와 출력 내용을 볼 수 있는 `README.md` 파일도 포함되어 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333760, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=140, prompt_tokens=149, total_tokens=289, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchtI8vvlIIkKqP2lvuDZ2gyurqx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## Azure OpenAI 서비스 처음 사용하기\\n\\nAzure OpenAI 서비스를 처음 사용하는 경우, 이 [안내서](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal&WT.mc_id=academic-105485-koreyst)를 따라 Azure OpenAI 서비스 리소스를 만들고 배포하는 방법을 참고하세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333761, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=77, prompt_tokens=109, total_tokens=186, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchv7tiBEHCvsR7oSQcAfrZlNIpV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 처음으로 OpenAI API 사용하기\\n\\nOpenAI API를 처음 사용하시는 경우, [인터페이스 생성 및 사용 방법 안내서](https://platform.openai.com/docs/quickstart?context=pythont&WT.mc_id=academic-105485-koreyst)를 참조하시기 바랍니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333763, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=65, prompt_tokens=96, total_tokens=161, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABchwedYBDRYAJCM2U1EXiVmxNl3S', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 다른 학습자들과 만나기\\n\\n다른 학습자들을 만나기 위해 공식 [AI 커뮤니티 Discord 서버](https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst)에 채널을 만들었습니다. 이는 같은 생각을 가진 기업가, 빌더, 학생 및 생성형 AI에서 수준을 높이고자 하는 사람들과 네트워크를 형성하는 훌륭한 방법입니다.\\n\\n[![디스코드 채널에 참여하기](https://dcbadge.vercel.app/api/server/ByRwuEEgH4)](https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst)\\n\\n프로젝트 팀도 이 Discord 서버에 있어 어떤 학습자든 도울 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333764, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=166, prompt_tokens=163, total_tokens=329, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABci2bzEXXk9hXsm7iN5NpQAlugSa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 기여하기\\n\\n이 과정은 오픈소스 이니셔티브입니다. 개선할 영역이나 문제를 발견하시면, [Pull Request](https://github.com/microsoft/generative-ai-for-beginners/pulls?WT.mc_id=academic-105485-koreyst)를 생성하거나 [GitHub issue](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst)에 기록해 주세요.\\n\\n프로젝트 팀은 모든 기여를 추적할 것입니다. 오픈 소스에 기여하는 것은 생성 AI 분야에서 커리어를 쌓는 데 놀라운 방법입니다.\\n\\n대부분의 기여는 Contributor License Agreement (CLA)에 동의해야 하며, 이는 당신이 기여할 권리가 있고 실제로 기여할 수 있는 권리를 우리에게 부여한다는 것을 선언합니다. 자세한 내용은 [CLA, Contributor License Agreement 웹사이트](https://cla.microsoft.com?WT.mc_id=academic-105485-koreyst)를 방문하세요.\\n\\n중요: 이 저장소에서 텍스트를 번역할 때, 기계 번역을 사용하지 않도록 해 주세요. 우리는 커뮤니티를 통해 번역을 검증할 것이므로, 능숙한 언어에 대해서만 번역을 자원해 주시기 바랍니다.\\n\\n풀 리퀘스트를 제출하면 CLA 봇이 자동으로 CLA를 제공해야 하는지 여부를 결정하고 PR에 적절하게 장식(예: 라벨, 댓글)할 것입니다. 봇에서 제공하는 지시 사항을 간단히 따르면 됩니다. CLA를 사용하는 모든 저장소에서 한 번만 하면 됩니다.\\n\\n이 프로젝트는 [Microsoft 오픈 소스 행동 강령](https://opensource.microsoft.com/codeofconduct/?WT.mc_id=academic-105485-koreyst)을 채택했습니다. 자세한 정보는 행동 강령 FAQ를 읽거나 [Email opencode](opencode@microsoft.com)로 추가 질문이나 의견을 보내 주세요.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333770, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=420, prompt_tokens=371, total_tokens=791, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciG29ECQ6pcwz5ehisqpIwV3z44', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 시작해봅시다\\n\\n이 과정을 완료하는 데 필요한 단계를 완료했으므로 지금 [생성형 AI 및 LLM 소개](../01-introduction-to-genai/README.md?WT.mc_id=academic-105485-koreyst)를 통해 시작해봅시다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333784, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=63, prompt_tokens=87, total_tokens=150, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciI4CokTUTEgKKrODsmpBK37dk2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 생성형 AI와 대규모 언어 모델 소개\\n\\n[![생성형 AI와 대규모 언어 모델 소개](./images/01-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst)\\n\\n_(이 강의의 비디오를 보시려면 위 이미지를 클릭하세요)_\\n\\n생성형 AI는 텍스트, 이미지 및 기타 유형의 콘텐츠를 생성할 수 있는 인공지능입니다. 이 기술이 환상적인 이유는 AI를 민주화한다는 점입니다. 자연어로 작성된 문장과 같은 최소한의 텍스트 프롬프트만으로도 누구나 사용할 수 있습니다. Java나 SQL 같은 언어를 배울 필요 없이, 자신의 언어로 원하는 것을 말하면 AI 모델에서 제안이 나옵니다. 그 응용 프로그램과 영향력은 막대하여, 보고서를 작성하거나 이해하고, 애플리케이션을 작성하는 등 모든 것을 몇 초 내에 할 수 있습니다.\\n\\n이 커리큘럼에서는 저희 스타트업이 교육 분야에서 새로운 시나리오를 열기 위해 생성형 AI를 어떻게 활용하고, 그 적용의 사회적 영향 및 기술적 한계와 관련된 불가피한 도전 과제를 어떻게 해결하는지 탐구할 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333786, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=295, prompt_tokens=270, total_tokens=565, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciLqYkd8gegpHWAP2iLHcF1WF10', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 강의에서는 다음 내용을 다룹니다:\\n\\n- 비즈니스 시나리오 소개: 우리의 스타트업 아이디어와 미션.\\n- 생성적 AI와 현재 기술 환경에 어떻게 도달했는지.\\n- 대형 언어 모델의 내부 작동 원리.\\n- 대형 언어 모델의 주요 기능과 실용적인 사용 사례.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333789, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=78, prompt_tokens=84, total_tokens=162, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciM6rX6UXo1AY2D1FOfwAsETHtN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의를 완료한 후, 여러분은 다음을 이해하게 될 것입니다:\\n\\n- 생성형 AI가 무엇이며 대규모 언어 모델이 어떻게 작동하는지.\\n- 교육 시나리오에 중점을 두고 다양한 사용 사례에 대규모 언어 모델을 어떻게 활용할 수 있는지.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333790, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=70, prompt_tokens=74, total_tokens=144, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciNG45wXs8tLxAnHS8cpzlsZV3U', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 시나리오: 우리의 교육 스타트업\\n\\n생성적 인공지능(Generative AI)은 AI 기술의 정점을 나타내며, 한때 불가능하다고 생각되었던 한계를 넘어서고 있습니다. 생성적 AI 모델은 여러 가지 능력과 응용 가능성을 가지고 있지만, 이번 커리큘럼에서는 가상의 스타트업을 통해 교육을 혁신하는 방법에 대해 탐구해 보겠습니다. 이 스타트업을 _우리의 스타트업_ 이라고 부르겠습니다. 우리의 스타트업은 교육 분야에서 활동하며, 다음과 같은 야심 찬 사명 선언문을 가지고 있습니다.\\n\\n> _학습의 접근성을 글로벌 차원에서 향상시키고, 교육에 대한 공평한 접근을 보장하며, 학습자의 필요에 따라 개인화된 학습 경험을 제공한다._\\n\\n우리의 스타트업 팀은 현대의 강력한 도구 중 하나인 대형 언어 모델(LLM)을 활용하지 않고는 이 목표를 달성할 수 없다는 것을 인지하고 있습니다.\\n\\n생성적 AI는 오늘날 우리가 배우고 가르치는 방식을 혁신할 것으로 예상되며, 학생들은 24시간 동안 가상 교사로부터 방대한 양의 정보와 예시를 제공받고, 교사들은 혁신적인 도구를 활용하여 학생들을 평가하고 피드백을 제공할 수 있게 됩니다.\\n\\n![모니터를 보고 있는 다섯 명의 젊은 학생들 - 이미지 by DALLE2](./images/students-by-DALLE2.png?WT.mc_id=academic-105485-koreyst)\\n\\n우선, 이번 커리큘럼 전반에 걸쳐 사용할 몇 가지 기본 개념과 용어를 정의해 보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333791, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=374, prompt_tokens=285, total_tokens=659, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciSczuXigvY6kF33TiXHY1xgHvb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 생성형 인공지능은 어떻게 나오게 되었나요?\\n\\n최근 생성형 인공지능 모델의 발표로 인해 _엄청난_ 열풍이 불고 있지만, 이 기술은 몇십 년에 걸쳐 발전해 온 것으로, 첫 연구 노력은 60년대까지 거슬러 올라갑니다. 우리는 이제 인간의 인지 능력을 갖춘 인공지능, 예를 들어 [OpenAI ChatGPT](https://openai.com/chatgpt)나 [Bing Chat](https://www.microsoft.com/edge/features/bing-chat?WT.mc_id=academic-105485-koreyst)처럼 대화를 할 수 있는 능력을 지닌 AI 모델을 웹 검색의 Bing 대화에 활용할 수 있는 시점에 와 있습니다.\\n\\n조금 뒤로 돌아가 보면, 최초의 AI 프로토타입은 타자 입력을 기반으로 한 챗봇이었으며, 전문가 그룹에서 추출한 지식 기반을 컴퓨터에 저장한 형태였습니다. 지식 기반의 답변은 입력 텍스트에 나타난 키워드에 의해 작동되었습니다.\\n그러나 이러한 접근 방식, 즉 타자 입력 챗봇을 사용하는 방식은 곧 규모를 확장하기 어렵다는 것이 분명해졌습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333796, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=264, prompt_tokens=224, total_tokens=488, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciV8TVjPl8z2tLVXV1zjUPqGHNI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### AI에 대한 통계적 접근법: 머신 러닝\\n\\n90년대 동안 텍스트 분석에 통계적 접근법을 적용하면서 전환점이 찾아왔습니다. 이는 데이터로부터 패턴을 학습할 수 있는 새로운 알고리즘의 개발로 이어졌으며, 이는 머신 러닝이라는 이름으로 알려져 있습니다. 이 접근법은 기계가 명시적으로 프로그래밍되지 않고도 인간 언어 이해를 시뮬레이션할 수 있게 합니다. 통계 모델은 텍스트-레이블 쌍에 대해 훈련되며, 이를 통해 모델이 메시지의 의도를 나타내는 미리 정의된 레이블로 미지의 입력 텍스트를 분류할 수 있게 됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333799, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=160, prompt_tokens=130, total_tokens=290, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciYIVYRYXn0w2IZBgMN5XoYmoIg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 신경망과 현대 가상 비서\\n\\n최근 들어, 더 많은 데이터와 복잡한 계산을 처리할 수 있는 하드웨어의 기술적 발전은 AI 분야의 연구를 촉진시켰으며, 이는 고급 기계 학습 알고리즘 – 즉 신경망 또는 심층 학습 알고리즘의 개발로 이어졌습니다.\\n\\n신경망(특히 순환 신경망 – RNN)은 자연어 처리를 크게 향상시켜, 문장 내 단어의 맥락을 중시하면서 텍스트의 의미를 더 유의미하게 표현할 수 있게 했습니다.\\n\\n이 기술은 신세기의 첫 10년 동안 태어난 가상 비서들을 지원하며, 인간의 언어를 해석하고, 필요를 식별하고, 이를 충족시키기 위한 행동을 수행하는 데 매우 능숙합니다 – 예를 들어, 사전 정의된 스크립트로 응답하거나 제3자 서비스를 소비하는 것 등입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333802, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=212, prompt_tokens=187, total_tokens=399, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciczJ8Wb6FRFM1hOmk0fjRzT74m', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### 현재의 생성형 AI\\n\\n이와 같이 우리는 오늘날 생성형 AI에 도달하게 되었으며, 이는 딥러닝의 하위 집합으로 볼 수 있습니다.\\n\\n![AI, ML, DL 및 생성형 AI](./images/AI-diagram.png?WT.mc_id=academic-105485-koreyst)\\n\\n인공지능 분야에서 수십 년 간의 연구 끝에 _트랜스포머(Transformer)_라는 새로운 모델 아키텍처가 RNN의 한계를 극복했고, 훨씬 더 긴 텍스트 시퀀스를 입력으로 받을 수 있게 되었습니다. 트랜스포머는 어텐션 메커니즘에 기반하며, 모델이 입력받은 텍스트의 순서와 상관없이 가장 관련성이 높은 정보에 '더 많은 주의'를 기울일 수 있게 합니다.\\n\\n대부분의 최신 생성형 AI 모델 – 텍스트 입력과 출력을 처리하기 때문에 대형 언어 모델(LLMs)로도 알려져 있습니다 – 은 실제로 이 아키텍처를 기반으로 하고 있습니다. 흥미로운 점은, 책, 기사, 웹사이트와 같은 다양한 출처로부터 얻은 방대한 양의 레이블이 없는 데이터를 학습한 이러한 모델들이 다양한 작업에 적응할 수 있고, 창의성의 일단을 띈 문법적으로 올바른 텍스트를 생성할 수 있다는 것입니다. 따라서 이 모델들은 입력 텍스트를 '이해'하는 기계의 능력을 놀랍게 향상시켰을 뿐만 아니라, 인간 언어로 원본 응답을 생성할 수 있는 능력을 가능하게 했습니다.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333806, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=351, prompt_tokens=295, total_tokens=646, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcih3XC2odAIR3dHE2CPt0EBj9wJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"## 대형 언어 모델은 어떻게 작동하나요?\\n\\n다음 장에서 우리는 다양한 생성형 AI 모델을 탐구할 것입니다. 지금은 OpenAI GPT(Generative Pre-trained Transformer) 모델을 중심으로 대형 언어 모델이 어떻게 작동하는지 살펴보겠습니다.\\n\\n- **토크나이저, 텍스트를 숫자로 변환**: 대형 언어 모델은 텍스트를 입력받아 텍스트를 출력합니다. 그러나 통계적 모델이기 때문에 텍스트 시퀀스보다는 숫자와 함께 더 잘 작동합니다. 따라서 모델의 모든 입력은 핵심 모델에 사용되기 전에 토크나이저에 의해 처리됩니다. 토큰은 가변 문자 수로 구성된 텍스트 조각이며, 토크나이저의 주요 작업은 입력을 토큰 배열로 분할하는 것입니다. 그런 다음 각 토큰은 원래 텍스트 조각의 정수 인코딩인 토큰 인덱스와 매핑됩니다.\\n\\n![토큰화 예시](./images/tokenizer-example.png?WT.mc_id=academic-105485-koreyst)\\n\\n- **출력 토큰 예측**: 최대 n개의 토큰을 입력으로 받으면(모델에 따라 최대 n이 다름), 모델은 하나의 토큰을 출력으로 예측할 수 있습니다. 이 토큰은 다음 반복의 입력에 포함되어 확장하는 창 패턴을 형성하여 하나 이상의 문장을 답변으로 받는 사용자 경험을 향상시킵니다. 따라서 ChatGPT를 사용해 본 적이 있다면 때때로 문장의 중간에서 멈추는 것처럼 보이는 이유를 설명합니다.\\n\\n- **선택 과정, 확률 분포**: 출력 토큰은 현재 텍스트 시퀀스 후에 발생할 확률에 따라 모델에 의해 선택됩니다. 이는 모델이 훈련을 기반으로 모든 가능한 '다음 토큰'에 대한 확률 분포를 예측하기 때문입니다. 그러나 항상 확률이 가장 높은 토큰이 선택되는 것은 아닙니다. 약간의 무작위성이 이 선택에 추가되어 모델이 비결정론적 방식으로 작동하게 합니다. 이는 동일한 입력에 대해 항상 동일한 출력을 얻지 않음을 의미합니다. 이러한 무작위성의 정도는 창의적 사고 과정을 모방하기 위해 추가되며, 온도라는 모델 매개 변수를 사용하여 조정할 수 있습니다.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333811, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=529, prompt_tokens=457, total_tokens=986, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciokeCtYZfJFUk7CdYBGKlSSK3d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 우리 스타트업이 대형 언어 모델(LLM)을 어떻게 활용할 수 있을까요?\\n\\n이제 대형 언어 모델의 내부 작동 방식을 더 잘 이해했으니, 비즈니스 시나리오를 염두에 두고 이 모델이 잘 수행할 수 있는 일반적인 작업에 대한 몇 가지 실제 예를 살펴봅시다.\\n대형 언어 모델의 주요 기능은 _자연어로 작성된 텍스트 입력을 시작으로 새로운 텍스트를 생성하는 것_ 이라고 말했습니다.\\n\\n하지만 어떤 종류의 텍스트 입력과 출력을 말하는 걸까요? 대형 언어 모델의 입력은 프롬프트(prompt)라고 하며, 출력은 완성(completion)이라고 합니다. 완성은 현재 입력을 완성하기 위해 다음 토큰을 생성하는 모델 메커니즘을 의미합니다. 프롬프트가 무엇인지, 모델에서 최대한의 성능을 끌어내기 위해 그것을 어떻게 설계하는지 깊이 살펴볼 예정입니다. 지금은 프롬프트에 다음과 같은 것들이 포함될 수 있다고만 말해봅시다:\\n\\n- 모델에게서 기대하는 출력을 명시하는 **지시문**. 이 지시문에는 때때로 몇 가지 예시나 추가 데이터가 포함될 수 있습니다.\\n\\n  1. 기사, 책, 제품 리뷰 등 여러 종류의 요약 및 비정형 데이터에서 인사이트 추출.\\n\\n  ![요약 예](./images/summarization-example.png?WT.mc_id=academic-105485-koreyst)\\n\\n    <br>\\n    \\n    2. 기사, 에세이, 과제 등에 대한 창의적인 아이디어와 디자인.\\n    \\n    ![창의적 글쓰기 예](./images/creative-writing-example.png?WT.mc_id=academic-105485-koreyst)\\n\\n    <br>\\n\\n- 에이전트와의 대화 형태로 묻는 **질문**.\\n\\n![대화 예](./images/conversation-example.png?WT.mc_id=academic-105485-koreyst)\\n\\n<br>\\n\\n- **완성할 텍스트 조각**, 즉 글쓰기 지원을 암묵적으로 요청하는 경우.\\n\\n![텍스트 완성 예](./images/text-completion-example.png?WT.mc_id=academic-105485-koreyst)\\n\\n<br>\\n\\n- **코드 조각**과 함께 그것을 설명하고 문서화하는 요청, 또는 특정 작업을 수행하는 코드를 생성하는 댓글.\\n\\n![코딩 예](./images/coding-example.png?WT.mc_id=academic-105485-koreyst)\\n\\n<br>\\n\\n위의 예는 굉장히 간단하며 대형 언어 모델의 기능을 완전히 설명하려는 것이 아닙니다. 이 예시들은 특히 교육 분야를 포함한 다양한 맥락에서 생성형 AI를 사용할 잠재성을 보여주기 위한 것입니다.\\n\\n또한, 생성형 AI 모델의 출력은 완벽하지 않으며 때로는 모델의 창의성이 역효과를 낼 수 있습니다. 결과적으로 사용자에게 현실을 왜곡한 것으로 해석될 수 있는 단어나 경우에 따라 공격적인 결과가 나올 수도 있습니다. 생성형 AI는 지능적이지 않습니다. 적어도 비판적이고 창의적 사고나 감성 지능을 포함한 지능의 더 포괄적인 정의에 있어서는 그렇습니다. 또한 결정적이지 않으며 신뢰할 수 없습니다. 잘못된 참조, 콘텐츠, 주장 등이 올바른 정보와 결합되어 설득력 있고 자신감 있게 제시될 수 있습니다. 다음 강의에서는 이러한 한계에 대해 다루고 이를 완화할 수 있는 방법을 살펴보겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333818, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=788, prompt_tokens=678, total_tokens=1466, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABciwqXluw6pNNV8UNuQudSbRTWQP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n여러분의 과제는 [생성형 AI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence?WT.mc_id=academic-105485-koreyst)에 대해 더 많이 읽어보고, 오늘날 생성형 AI를 추가할 수 있는 새로운 분야를 찾아보는 것입니다. \"옛 방식\" 으로 하는 것과 비교했을 때, 어떤 점에서 차이가 있을 것이며, 이전에는 할 수 없었던 것을 할 수 있게 되는지, 또는 더 빠르게 할 수 있는 지에 대해 생각해보세요. 여러분의 꿈의 AI 스타트업이 어떤 모습일지에 대해 300자 요약으로 작성하고, \"문제\", \"AI 활용 방법\", \"영향\" 등의 헤더를 포함하세요. 선택적으로 사업 계획도 포함할 수 있습니다.\\n\\n이 과제를 완료하면, 여러분은 아마도 [Microsoft for Startups Founders Hub](https://www.microsoft.com/startups?WT.mc_id=academic-105485-koreyst)에 지원할 준비가 될 수도 있습니다. 우리는 Azure, OpenAI, 멘토링 등 다양한 크레딧을 제공합니다. 자세한 사항은 확인해 보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333826, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=251, prompt_tokens=220, total_tokens=471, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcizh5ibVc9x7D7DBGGBmB8QNwGP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 확인\\n\\n대형 언어 모델에 대해 참인 것은 무엇입니까?\\n\\n1. 매번 정확히 동일한 응답을 받습니다.\\n2. 모든 일을 완벽하게 수행합니다. 숫자를 더하거나 작동하는 코드를 생성하는 것에 뛰어납니다.\\n3. 동일한 프롬프트를 사용해도 응답이 다를 수 있습니다. 또한 텍스트나 코드의 초안을 작성하는 데 뛰어납니다. 하지만 결과를 개선해야 할 필요가 있습니다.\\n\\nA: 3, LLM은 비결정적이므로 응답이 다를 수 있습니다. 하지만 온도 설정을 통해 그 변동성을 제어할 수 있습니다. 또한 모든 일을 완벽하게 수행할 것으로 기대해서는 안 되며, 주로 첫 시도를 도와주는 역할을 합니다. 따라서 점진적으로 결과를 개선해야 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333829, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=184, prompt_tokens=174, total_tokens=358, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcj4aWsqdBN3BPc9F68UUTRz1hqe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 여정을 계속하세요\\n\\n이 수업을 마친 후에는 [Generative AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 당신의 생성 AI 지식을 계속해서 향상해 보세요!\\n\\n다음 2과로 이동하여 [다양한 LLM 유형을 탐색하고 비교하는 방법](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst)을 살펴보겠습니다!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333834, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=125, prompt_tokens=134, total_tokens=259, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcj6j5OtHV3DF0ndEKC9u9VfCpAb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 검색 추가 생성 (RAG) 및 벡터 데이터베이스\\n\\n[![검색 추가 생성 (RAG) 및 벡터 데이터베이스](./images/15-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)\\n\\n검색 애플리케이션 수업에서 대형 언어 모델(LLM)에 자체 데이터를 통합하는 방법에 대해 간단히 배웠습니다. 이번 수업에서는 LLM 애플리케이션에서 데이터를 기반으로 하는 개념, 프로세스의 메커니즘 및 임베딩과 텍스트를 포함하여 데이터를 저장하는 방법에 대해 깊이 있게 탐구할 것입니다.\\n\\n> **비디오 준비 중**', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333836, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=170, prompt_tokens=171, total_tokens=341, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcj8koil7gG9iW5x7Mz2zNkughQn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 강의에서는 다음 내용을 다룰 것입니다:\\n\\n- RAG에 대한 소개, RAG가 무엇인지 그리고 AI (인공지능)에서 왜 사용되는지.\\n\\n- 벡터 데이터베이스가 무엇인지 이해하고, 우리 응용 프로그램을 위해 하나를 만드는 방법.\\n\\n- RAG를 응용 프로그램에 통합하는 실제 예제.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333838, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=78, prompt_tokens=89, total_tokens=167, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjAPjpDzuAMD6cD1gLTQY5vR0AN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의를 완료한 후에는 다음을 할 수 있습니다:\\n\\n- 데이터 검색 및 처리에서 RAG의 중요성을 설명할 수 있습니다.\\n\\n- RAG 애플리케이션을 설정하고 데이터를 LLM에 연동할 수 있습니다.\\n\\n- RAG와 벡터 데이터베이스를 LLM 애플리케이션에서 효과적으로 통합할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333840, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=82, prompt_tokens=85, total_tokens=167, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjBhzV0XstSaYBLySczFb5YUHb2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 우리의 시나리오: LLM을 자체 데이터로 강화하기\\n\\n이번 수업에서는 교육 스타트업에 자체 노트를 추가하여 챗봇이 다양한 주제에 대한 더 많은 정보를 얻을 수 있도록 하려고 합니다. 가지고 있는 노트를 사용하면 학습자들이 더 나은 학습을 할 수 있으며, 다양한 주제를 이해하기 쉽게 하고 시험 준비를 용이하게 할 수 있습니다. 우리의 시나리오를 만들기 위해 사용될 항목은 다음과 같습니다:\\n\\n- `Azure OpenAI:` 우리가 챗봇을 만들기 위해 사용할 LLM\\n- `Neural Networks에 대한 초보자용 AI 강좌:` 우리 LLM의 기반이 될 데이터\\n- `Azure AI Search` 및 `Azure Cosmos DB:` 데이터를 저장하고 검색 인덱스를 생성할 벡터 데이터베이스\\n\\n사용자들은 자신의 노트에서 연습 퀴즈를 생성하고, 복습용 플래시 카드와 요약을 통해 간결한 개요를 만들 수 있게 됩니다. 시작하기 위해, RAG가 무엇인지 그리고 어떻게 작동하는지 살펴보겠습니다:', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333841, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=238, prompt_tokens=212, total_tokens=450, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjI4vyARA4uo0CZ94K9cF4N2bpY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 검색 강화 생성(RAG)\\n\\nLLM 기반의 챗봇은 사용자 프롬프트를 처리하여 응답을 생성합니다. 이는 상호작용을 위해 설계되었으며, 다양한 주제에 대해 사용자와 소통합니다. 하지만 그 응답은 제공된 문맥과 기본적인 교육 데이터에 한정됩니다. 예를 들어, GPT-4의 지식 커트오프는 2021년 9월로, 그 이후에 발생한 사건들에 대한 지식을 갖고 있지 않습니다. 게다가, LLM을 훈련하는 데 사용된 데이터는 개인 노트나 회사의 제품 설명서와 같은 기밀 정보를 제외합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333848, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=146, prompt_tokens=134, total_tokens=280, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjKyFfS4zgkzPofMBQypeMUyya2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### RAGs (Retrieval Augmented Generation)의 작동 원리\\n\\n![RAGs의 작동 방식을 보여주는 그림](images/how-rag-works.png?WT.mc_id=academic-105485-koreyst)\\n\\n퀴즈를 작성하는 챗봇을 배포하려면 지식 베이스와의 연결이 필요합니다. 이때 RAG가 구원투수로 등장합니다. RAGs는 다음과 같이 작동합니다:\\n\\n- **지식 베이스:** 검색 이전에 이러한 문서들은 보통 대용량 문서를 더 작은 청크로 분할하고, 이를 텍스트 임베딩으로 변환하여 데이터베이스에 저장하는 등의 전처리가 필요합니다.\\n\\n- **사용자 쿼리:** 사용자가 질문을 합니다.\\n\\n- **검색:** 사용자가 질문을 하면, 임베딩 모델이 지식 베이스에서 관련 정보를 검색하여 더 많은 컨텍스트를 제공하고, 이를 프롬프트에 통합합니다.\\n\\n- **증강 생성:** LLM은 검색된 데이터를 바탕으로 응답을 향상시킵니다. 이는 생성된 응답이 사전 학습된 데이터뿐만 아니라 추가된 컨텍스트의 관련 정보를 바탕으로 하게 합니다. 검색된 데이터는 LLM의 응답을 증강하는 데 사용됩니다. 그 다음, LLM은 사용자의 질문에 대한 답변을 반환합니다.\\n\\n![RAGs 아키텍처를 보여주는 그림](images/encoder-decode.png?WT.mc_id=academic-105485-koreyst)\\n\\nRAGs의 아키텍처는 인코더와 디코더 두 부분으로 구성된 트랜스포머를 사용하여 구현됩니다. 예를 들어, 사용자가 질문을 하면 입력 텍스트가 '인코딩'되어 단어의 의미를 포착하는 벡터로 변환되고, 벡터는 '디코딩'되어 문서 인덱스로 변환하여 사용자의 쿼리를 기반으로 새 텍스트를 생성합니다. LLM은 출력 생성을 위해 인코더-디코더 모델을 모두 사용합니다.\\n\\n제안된 논문 [지식 집약적인 NLP(Natural Language Processing) 작업을 위한 검색 증강 생성](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst)에 따라 RAG 구현 시 두 가지 접근 방식이 있습니다:\\n\\n- **_RAG-Sequence_**: 검색된 문서를 사용하여 사용자 쿼리에 대한 최적의 답변을 예측합니다.\\n\\n- **RAG-Token**: 문서를 사용하여 다음 토큰을 생성한 후 이를 검색하여 사용자 쿼리에 답변합니다.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333850, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=581, prompt_tokens=477, total_tokens=1058, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjPocmjNjKpkVzRpptQ7uR5uPUf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 왜 RAGs를 사용합니까?\\n\\n- **정보의 풍부함:** 텍스트 응답이 최신 상태인지 확인합니다. 따라서 내부 지식 베이스에 접근하여 도메인 특정 작업의 성능을 향상시킵니다.\\n\\n- 지식 베이스의 **검증 가능한 데이터**를 활용하여 사용자 쿼리에 대한 문맥을 제공함으로써 조작을 줄입니다.\\n\\n- LLM을 미세 조정하는 것에 비해 경제적이기 때문에 **비용 효율적**입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333855, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=116, prompt_tokens=115, total_tokens=231, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjRMszQtPdNzBY4OVdZgTYiKTbb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 기반 생성\\n\\n우리 애플리케이션은 개인 데이터, 즉, AI For Beginners 커리큘럼의 신경망 수업을 기반으로 합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333857, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=37, prompt_tokens=55, total_tokens=92, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjSxaLfK4UjMysGL1wl7CHfYsHW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 벡터 데이터베이스\\n\\n벡터 데이터베이스는 전통적인 데이터베이스와 달리, 임베디드 벡터를 저장, 관리 및 검색하도록 설계된 특수한 데이터베이스입니다. 이것은 문서의 수치적 표현을 저장합니다. 데이터를 수치 임베딩으로 분해하면 AI 시스템이 데이터를 더 쉽게 이해하고 처리할 수 있습니다.\\n\\nLLM이 입력으로 수락할 수 있는 토큰 수에는 한계가 있기 때문에 임베딩을 벡터 데이터베이스에 저장합니다. 임베딩 전체를 LLM에 전달할 수 없으므로 이를 청크로 나누어야 하며, 사용자가 질문을 하면 질문과 가장 유사한 임베딩이 프롬프트와 함께 반환됩니다. 청킹은 또한 LLM을 통해 전달되는 토큰 수에 대한 비용을 줄이는 데 도움이 됩니다.\\n\\n인기 있는 벡터 데이터베이스로는 Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant, 그리고 DeepLake가 있습니다. 다음 명령어를 사용하여 Azure CLI로 Azure Cosmos DB 모델을 생성할 수 있습니다:\\n\\n```bash\\naz login\\naz group create -n <resource-group-name> -l <location>\\naz cosmosdb create -n <cosmos-db-name> -r <resource-group-name>\\naz cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>\\n```\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333858, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=313, prompt_tokens=274, total_tokens=587, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjWK9q4tZCJKp51XGoqLEtsAKMs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### 텍스트에서 임베딩으로\\n\\n데이터를 저장하기 전에, 데이터베이스에 저장되기 전에 벡터 임베딩으로 변환해야 합니다. 큰 문서나 긴 텍스트를 다루는 경우, 예상 쿼리에 따라 텍스트를 청킹할 수 있습니다. 청킹은 문장 단위 또는 단락 단위로 할 수 있습니다. 청킹은 주변 단어들로부터 의미를 도출하므로, 청크에 다른 문맥을 추가할 수 있습니다. 예를 들어, 문서 제목을 추가하거나 청크 전후에 텍스트를 포함시킬 수 있습니다. 데이터를 다음과 같이 청킹할 수 있습니다:\\n\\n```python\\ndef split_text(text, max_length, min_length):\\n    words = text.split()\\n    chunks = []\\n    current_chunk = []\\n\\n    for word in words:\\n        current_chunk.append(word)\\n        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:\\n            chunks.append(' '.join(current_chunk))\\n            current_chunk = []\\n\\n    # 마지막 청크가 최소 길이에 도달하지 않았더라도 추가합니다\\n    if current_chunk:\\n        chunks.append(' '.join(current_chunk))\\n\\n    return chunks\\n```\\n\\n청킹된 후에는 다양한 임베딩 모델을 사용하여 텍스트를 임베딩할 수 있습니다. 사용할 수 있는 모델에는 word2vec, OpenAI의 ada-002, Azure Computer Vision 등 여러 가지가 있습니다. 사용할 모델을 선택하는 것은 사용 중인 언어, 인코딩되는 콘텐츠의 유형(텍스트/이미지/오디오), 인코드할 수 있는 입력 크기 및 임베딩 출력 길이에 따라 달라집니다.\\n\\nOpenAI의 `text-embedding-ada-002` 모델을 사용하여 임베드된 텍스트의 예는 다음과 같습니다:\\n![고양이 단어의 임베딩](images/cat.png?WT.mc_id=academic-105485-koreyst)\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333862, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=422, prompt_tokens=378, total_tokens=800, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjc8lmbu3BkHGwOnfGK2Rz727zT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 검색 및 벡터 탐색\\n\\n사용자가 질문을 하면, 검색자는 쿼리 인코더를 사용하여 이를 벡터로 변환합니다. 그런 다음, 문서 검색 인덱스를 통해 입력과 관련된 문서 내의 관련 벡터를 검색합니다. 검색이 완료되면, 입력 벡터와 문서 벡터를 텍스트로 변환하여 LLM을 통과시킵니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333868, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=97, prompt_tokens=97, total_tokens=194, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjdeyiAo8TWSNiH3YaPHbFEsk07', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 검색\\n\\n검색은 시스템이 검색 조건을 만족하는 문서를 인덱스에서 빠르게 찾으려 할 때 발생합니다. 검색기의 목표는 문서를 가져와서 당신의 데이터에 대해 문맥을 제공하고 LLM을 기반으로 하는 것입니다.\\n\\n우리의 데이터베이스 내에서 검색을 수행하는 여러 방법이 있습니다:\\n\\n- **키워드 검색** - 텍스트 검색에 사용됩니다.\\n\\n- **의미론적 검색** - 단어의 의미적 의미를 사용합니다.\\n\\n- **벡터 검색** - 임베딩 모델을 사용하여 문서를 텍스트에서 벡터 표현으로 변환합니다. 검색은 사용자 질문에 가장 가까운 벡터 표현을 가진 문서를 쿼리하여 수행됩니다.\\n\\n- **하이브리드** - 키워드 검색과 벡터 검색을 결합한 방법입니다.\\n\\n검색의 어려움은 데이터베이스에 쿼리에 대한 유사한 응답이 없는 경우에 발생합니다. 시스템은 가능한 최상의 정보를 반환하려고 하지만, 관련성에 대한 최대 거리를 설정하거나 키워드와 벡터 검색을 결합한 하이브리드 검색을 사용하는 등의 전술을 사용할 수 있습니다. 이 레슨에서는 벡터 검색과 키워드 검색을 결합한 하이브리드 검색을 사용할 것입니다. 우리는 데이터프레임에 조각 및 임베딩을 포함하는 열을 저장할 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333869, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c047b7b4ec', usage=CompletionUsage(completion_tokens=308, prompt_tokens=257, total_tokens=565, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjh55HhnWHn01vrdKd3yOT73bu7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 벡터 유사성\\n\\n검색기는 지식 데이터베이스에서 가까이 있는 임베딩을 검색합니다. 이러한 임베딩은 텍스트가 유사하기 때문에 가장 가까운 이웃이 됩니다. 사용자가 쿼리를 던지는 시나리오에서, 쿼리는 먼저 임베딩된 다음 유사한 임베딩과 매치됩니다. 서로 다른 벡터가 얼마나 유사한지 찾기 위해 일반적으로 사용되는 측정 방법은 코사인 유사성입니다. 코사인 유사성은 두 벡터 사이의 각도를 기반으로 합니다.\\n\\n우리는 유사성을 측정하기 위해 다른 방법을 사용할 수도 있습니다. 예를 들어, 벡터 끝점 간의 직선 거리인 유클리드 거리와 두 벡터의 대응 요소의 곱의 합을 측정하는 내적이 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333873, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=190, prompt_tokens=145, total_tokens=335, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjifLW8aQBYMduA8wZdEm0jeEJO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### 검색 인덱스\\n\\n검색을 수행할 때, 검색을 실행하기 전에 우리의 지식 기반에 대한 검색 인덱스를 생성할 필요가 있습니다. 인덱스는 우리의 임베딩을 저장하고 큰 데이터베이스에서도 가장 유사한 조각들을 빠르게 검색할 수 있습니다. 우리는 다음을 사용하여 로컬에서 인덱스를 생성할 수 있습니다:\\n\\n```python\\nfrom sklearn.neighbors import NearestNeighbors\\n\\nembeddings = flattened_df['embeddings'].to_list()\\n```\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333874, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=108, prompt_tokens=105, total_tokens=213, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjkZH44qnynRZNThRWohmbU79V5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"# 검색 색인 생성\\nnbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333876, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=27, prompt_tokens=55, total_tokens=82, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjlauKnd728PE8Lfjv28ccKkaKT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```markdown\\n# 인덱스를 쿼리하려면 kneighbors 메소드를 사용할 수 있습니다\\ndistances, indices = nbrs.kneighbors(embeddings)\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333877, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=37, prompt_tokens=57, total_tokens=94, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjmRCqT8CpHG4dbrtZ5mHrXlEXu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 재정렬\\n\\n데이터베이스에 쿼리를 실행한 후 가장 관련성 높은 결과부터 정렬할 필요가 있을 수 있습니다. 재정렬 LLM은 기계 학습을 사용하여 검색 결과의 관련성을 높이고 가장 관련성 높은 항목부터 정렬합니다. Azure AI Search를 사용하면 의미론적 재정렬자를 사용하여 재정렬이 자동으로 수행됩니다. 최근접 이웃을 사용한 재정렬의 작동 방식 예시:\\n\\n```python\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333878, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=108, prompt_tokens=106, total_tokens=214, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjp6uBWQXaRlugOcBcmHIxfK3TQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 가장 유사한 문서 찾기\\ndistances, indices = nbrs.kneighbors([query_vector])\\n\\nindex = []', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333881, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=26, prompt_tokens=51, total_tokens=77, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjqWUKP0RTpwwkiDPONyYmF8pYk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```markdown\\n# 가장 유사한 문서 출력\\nfor i in range(3):\\n    index = indices[0][i]\\n    for index in indices[0]:\\n        print(flattened_df[\\'chunks\\'].iloc[index])\\n        print(flattened_df[\\'path\\'].iloc[index])\\n        print(flattened_df[\\'distances\\'].iloc[index])\\n    else:\\n        print(f\"인덱스 {index}는 DataFrame에 없습니다\")\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333882, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=94, prompt_tokens=115, total_tokens=209, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjvH0bgcxnT1aUqgzFlun6gciPZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 모두 함께 모으기\\n\\n마지막 단계는 우리의 데이터를 기반으로 한 응답을 얻기 위해 LLM(대형 언어 모델)을 추가하는 것입니다. 다음과 같이 구현할 수 있습니다:\\n\\n```python\\nuser_input = \"퍼셉트론이란 무엇인가요?\"\\n\\ndef chatbot(user_input):\\n    # 질문을 쿼리 벡터로 변환\\n    query_vector = create_embeddings(user_input)\\n\\n    # 가장 유사한 문서 찾기\\n    distances, indices = nbrs.kneighbors([query_vector])\\n\\n    # 쿼리에 문서를 추가하여 문맥 제공\\n    history = []\\n    for index in indices[0]:\\n        history.append(flattened_df[\\'chunks\\'].iloc[index])\\n\\n    # 히스토리와 사용자 입력을 결합\\n    history.append(user_input)\\n\\n    # 메시지 객체 생성\\n    messages=[\\n        {\"role\": \"system\", \"content\": \"당신은 AI 질문을 돕는 AI 어시스턴트입니다.\"},\\n        {\"role\": \"user\", \"content\": history[-1]}\\n    ]\\n\\n    # 채팅 완료를 사용하여 응답 생성\\n    response = openai.chat.completions.create(\\n        model=\"gpt-4\",\\n        temperature=0.7,\\n        max_tokens=800,\\n        messages=messages\\n    )\\n\\n    return response.choices[0].message\\n\\nchatbot(user_input)\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333887, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=294, prompt_tokens=291, total_tokens=585, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjzXQ5x2jX9gVQfMuPnzgjhfIH5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 우리 애플리케이션 평가하기', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333891, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_157b3831f5', usage=CompletionUsage(completion_tokens=9, prompt_tokens=34, total_tokens=43, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcjzR91x17DZUZbEXTdSqlHTrAOA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 평가 기준\\n\\n- 응답의 품질: 자연스럽고 유창하며 인간적인 느낌이 나는지를 보장\\n\\n- 데이터의 근거성: 제공된 문서에서 나온 응답인지 평가\\n\\n- 관련성: 응답이 질문과 일치하고 관련 있는지 평가\\n\\n- 유창성: 문법적으로 응답이 말이 되는지 평가\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333891, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=78, prompt_tokens=93, total_tokens=171, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABck1aTuoxvIvoy3pJY4TcusvxlwI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## RAG(검색 강화 생성)와 벡터 데이터베이스 사용 사례\\n\\n함수 호출을 통해 앱을 개선할 수 있는 다양한 사용 사례가 있습니다:\\n\\n- 질문과 답변: 직원들이 질문할 수 있는 채팅에 회사 데이터를 연결할 수 있습니다.\\n\\n- 추천 시스템: 영화, 레스토랑 등 가장 유사한 값을 매칭하는 시스템을 만들 수 있습니다.\\n\\n- 챗봇 서비스: 채팅 기록을 저장하고 사용자 데이터를 기반으로 대화를 개인화할 수 있습니다.\\n\\n- 벡터 임베딩을 기반으로 한 이미지 검색. 이미지 인식 및 이상 탐지 시 유용합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333893, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=132, prompt_tokens=148, total_tokens=280, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABck3rVexGekrduqCmBqS4YVRubMW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 요약\\n\\n우리는 RAG의 기본적인 영역을 다루었습니다. 여기에는 데이터 추가에서부터 사용자 쿼리와 출력까지 포함됩니다. RAG 생성을 단순화하기 위해 Semanti Kernel, Langchain 또는 Autogen과 같은 프레임워크를 사용할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333895, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_057232b607', usage=CompletionUsage(completion_tokens=63, prompt_tokens=77, total_tokens=140, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABck6DuWR7ZdwOy7A0MRHO2ilqmPG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n검색 강화 생성(Retrieval Augmented Generation, RAG)에 대한 학습을 계속하기 위해 다음을 구축할 수 있습니다:\\n\\n- 원하는 프레임워크를 사용하여 애플리케이션의 프런트엔드를 구축하세요.\\n\\n- LangChain 또는 Semantic Kernel 중 하나의 프레임워크를 사용하여 애플리케이션을 재구축하세요.\\n\\n수업을 완료한 것을 축하합니다 👏.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333898, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=93, prompt_tokens=88, total_tokens=181, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABck9uhQNGKnWhFUfOBVIAUohDnl5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습은 여기에서 멈추지 않습니다, 여정을 계속하세요\\n\\n이 수업을 마친 후, 우리의 [생성형 AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성형 AI 지식을 계속해서 업그레이드하세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333901, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=73, prompt_tokens=85, total_tokens=158, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckBWD3omewSnx7XlomT1nuCYDEJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 생성 AI-구동 채팅 애플리케이션 구축\\n\\n[![생성 AI-구동 채팅 애플리케이션 구축](./images/07-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lessons7-gh?WT.mc_id=academic-105485-koreyst)\\n\\n> _(위 이미지를 클릭하여 이번 학습의 영상을 확인하세요)_\\n\\n텍스트 생성 애플리케이션을 구축하는 방법을 살펴본 후, 이제 채팅 애플리케이션을 살펴보겠습니다.\\n\\n채팅 애플리케이션은 가벼운 대화를 넘어 우리의 일상에 깊숙이 통합되었습니다. 고객 서비스, 기술 지원, 심지어 정교한 상담 시스템의 중요한 부분이 되었습니다. 아마도 얼마 전 채팅 애플리케이션에서 도움을 받은 적이 있을 것입니다. 이러한 플랫폼에 생성 AI와 같은 고급 기술을 통합함에 따라 복잡성과 도전 과제도 함께 늘어납니다.\\n\\n우리가 답을 찾아야 할 몇 가지 질문은 다음과 같습니다:\\n\\n- **앱 구축**. AI-구동 애플리케이션을 특정 사용 사례에 맞추어 효율적으로 구축하고 원활하게 통합하려면 어떻게 해야 할까요?\\n- **모니터링**. 배포 후, 애플리케이션이 기능적으로 최고 수준의 품질을 유지하고 [책임 있는 AI의 여섯 가지 원칙](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst)을 준수하도록 모니터링하고 보장할 수 있는 방법은 무엇인가요?\\n\\n자동화와 원활한 인간-기계 상호작용으로 정의되는 시대가 다가올수록, 생성 AI가 채팅 애플리케이션의 범위, 깊이, 적응성을 어떻게 변환하는지 이해하는 것이 중요합니다. 이번 학습에서는 이러한 복잡한 시스템을 지원하는 아키텍처의 측면을 조사하고, 도메인 특화된 작업에 맞추기 위한 방법론을 탐구하며, 책임 있는 AI 배포를 보장하기 위해 필요한 메트릭과 고려사항을 평가할 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333903, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=484, prompt_tokens=376, total_tokens=860, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckLvFzZkkQVRjqKMiTjhoq3EKb8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 강의에서는 다음 내용을 다룹니다:\\n\\n- 채팅 애플리케이션을 효율적으로 구축하고 통합하는 기술.\\n- 애플리케이션에 맞춤 설정 및 세부 조정을 적용하는 방법.\\n- 채팅 애플리케이션을 효과적으로 모니터링하는 전략과 고려사항.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333913, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=72, prompt_tokens=67, total_tokens=139, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckNRFnPKX3I3yu9remUsGpYe0Rz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 강의를 마치면 다음을 수행할 수 있습니다:\\n\\n- 기존 시스템에 채팅 애플리케이션을 구축하고 통합할 때 고려 사항을 설명합니다.\\n- 특정 사용 사례에 맞게 채팅 애플리케이션을 맞춤화합니다.\\n- AI 기반 채팅 애플리케이션의 품질을 효과적으로 모니터링하고 유지하기 위한 주요 지표와 고려 사항을 식별합니다.\\n- 채팅 애플리케이션이 AI를 책임감 있게 활용하도록 보장합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333915, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=117, prompt_tokens=94, total_tokens=211, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckQwUtn5880XeLq2q43GLfHGxpo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 생성형 AI를 채팅 애플리케이션에 통합하기\\n\\n생성형 AI를 통해 채팅 애플리케이션을 향상시키는 것은 단순히 이를 더 똑똑하게 만드는 것만을 의미하지 않습니다. 그것은 고품질의 사용자 경험을 제공하기 위해 애플리케이션의 아키텍처, 성능 및 사용자 인터페이스를 최적화하는 것을 포함합니다. 여기에는 아키텍처의 기초, API 통합, 및 사용자 인터페이스 고려 사항을 조사하는 과정이 포함됩니다. 이 섹션은 기존 시스템에 통합하거나 독립형 플랫폼으로 구축할 때 필요한 복잡한 환경을 탐색하기 위한 포괄적인 로드맵을 제공하는 것을 목표로 합니다.\\n\\n이 섹션을 완료한 후에는 채팅 애플리케이션을 효율적으로 구축하고 통합하는 데 필요한 전문 지식을 갖추게 될 것입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333918, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=203, prompt_tokens=139, total_tokens=342, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckS2V3lJGvrtRvsqFqmYo33vac6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### 챗봇 또는 채팅 애플리케이션?\\n\\n채팅 애플리케이션 구축에 들어가기 전에 '챗봇'과 'AI 기반 채팅 애플리케이션'을 비교해 보겠습니다. 이 둘은 각각 고유한 역할과 기능을 가지고 있습니다. 챗봇의 주요 목적은 자주 묻는 질문에 답변하거나 소포를 추적하는 등 특정 대화형 작업을 자동화하는 것입니다. 이는 주로 규칙 기반 로직이나 복잡한 AI 알고리즘에 의해 관리됩니다. 반면에 AI 기반 채팅 애플리케이션은 인간 사용자가 텍스트, 음성 및 비디오 채팅과 같은 다양한 형태의 디지털 커뮤니케이션을 용이하게 하는 훨씬 더 포괄적인 환경입니다. 여기서 가장 중요한 특징은 정교한 AI 모델과의 통합으로, 이는 다양한 입력 및 맥락적 단서를 기반으로 사람과 유사한 대화를 시뮬레이션합니다. 생성적 AI 기반 채팅 애플리케이션은 개방형 토론을 할 수 있고, 진화하는 대화 맥락에 적응하며, 창의적이거나 복잡한 대화를 생성할 수 있습니다.\\n\\n아래 표는 디지털 커뮤니케이션에서 이들의 고유한 역할을 이해하는 데 도움이 되는 주요 차이점과 유사점을 나타냅니다.\\n\\n| 챗봇                                   | 생성적 AI 기반 채팅 애플리케이션       |\\n| ------------------------------------- | ------------------------------------- |\\n| 작업 지향적이고 규칙 기반            | 맥락 인식 가능                         |\\n| 더 큰 시스템에 통합되는 경우가 많음       | 하나 이상의 챗봇을 호스팅할 수 있음      |\\n| 프로그래밍된 기능에 제한됨              | 생성적 AI 모델 통합                     |\\n| 전문적이고 구조화된 상호작용            | 개방형 토론 가능                       |\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333920, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=419, prompt_tokens=295, total_tokens=714, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckXgN73ajcqP7U6ytuKyboHeGOi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### SDK와 API를 활용한 기존 기능 활용\\n\\n채팅 애플리케이션을 구축할 때의 첫 번째 단계는 이미 존재하는 것을 평가하는 것입니다. SDK와 API를 사용하여 채팅 애플리케이션을 구축하는 것은 다양한 이유로 유리한 전략입니다. 잘 문서화된 SDK와 API를 통합함으로써, 애플리케이션의 장기적 성공을 위한 전략적 위치를 확보하고, 확장성과 유지보수 관련 문제를 해결할 수 있습니다.\\n\\n- **개발 프로세스를 가속화하고 오버헤드를 줄임**: 자체적으로 기능을 빌드하는 비용이 많이 드는 프로세스를 대신하여 미리 구축된 기능에 의존함으로써 비즈니스 로직과 같은 더 중요한 애플리케이션의 다른 측면에 집중할 수 있습니다.\\n- **성능 향상**: 기능을 처음부터 구축하면 결국 \"이것이 어떻게 확장될까? 이 애플리케이션이 갑작스런 사용자 급증을 처리할 수 있을까?\"라는 질문을 하게 됩니다. 잘 유지되는 SDK와 API는 종종 이러한 문제에 대한 내장 솔루션을 제공합니다.\\n- **유지보수 용이**: 대부분의 API와 SDK는 새로운 버전이 릴리스될 때 라이브러리 업데이트만으로 업데이트와 향상이 쉬워집니다.\\n- **최첨단 기술 접근**: 광범위한 데이터셋에서 세밀하게 튜닝되고 학습된 모델을 활용하면 애플리케이션에 자연어 처리 기능을 제공합니다.\\n\\nSDK 또는 API의 기능에 접근하는 것은 일반적으로 제공된 서비스를 사용하기 위한 권한을 얻는 것을 포함하며, 이는 종종 고유 키 또는 인증 토큰을 통해 이루어집니다. 여기서는 OpenAI Python 라이브러리를 사용하여 이를 탐색해 보겠습니다. 다음 [OpenAI 노트북](./python/oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst) 또는 [Azure OpenAI Services 노트북](./python/aoai-assignment.ipynb?WT.mc_id=academic-105485-koreys)을 통해 직접 체험할 수도 있습니다.\\n\\n```python\\nimport os\\nfrom openai import OpenAI\\n\\nAPI_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\\n\\nclient = OpenAI(\\n    api_key=API_KEY\\n    )\\n\\nchat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Suggest two titles for an instructional lesson on chat applications for generative AI.\"}])\\n```\\n\\n위 예제는 GPT-3.5 Turbo 모델을 사용하여 프롬프트를 완료하지만, 주목할 점은 API 키를 사전에 설정하는 것입니다. 키를 설정하지 않으면 오류가 발생할 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333925, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=611, prompt_tokens=523, total_tokens=1134, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckfE7AXEjeGYBKDIvqPtPRGHV3t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 사용자 경험 (UX)\\n\\n일반적인 UX 원칙은 채팅 애플리케이션에도 적용되지만, 기계 학습 구성 요소가 포함된 경우 특히 중요해지는 추가 고려 사항들이 있습니다.\\n\\n- **모호성 해결 메커니즘**: 생성형 AI 모델은 때때로 모호한 답변을 생성합니다. 사용자가 이러한 문제를 겪을 때 명확성을 요청할 수 있는 기능이 도움이 될 수 있습니다.\\n- **문맥 유지**: 고급 생성형 AI 모델은 대화 중 문맥을 기억할 수 있는 능력이 있으며, 이는 사용자 경험에 중요한 자산이 됩니다. 사용자가 문맥을 제어하고 관리할 수 있는 기능은 사용자 경험을 향상시키지만 민감한 사용자 정보를 유지할 위험도 있습니다. 정보 보유 기간에 대한 정책을 도입하는 것과 같은 고려 사항은 문맥의 필요성과 프라이버시 균형을 맞출 수 있습니다.\\n- **개인화**: 학습하고 적응할 수 있는 능력을 갖춘 AI 모델은 사용자에게 개별화된 경험을 제공합니다. 사용자 프로필과 같은 기능을 통해 사용자 경험을 맞춤화하면 사용자가 이해받는 느낌을 받을 뿐만 아니라, 특정 답변을 찾는 데 더 효율적이고 만족스러운 상호작용을 창출할 수 있습니다.\\n\\n개인화의 한 예로는 OpenAI의 ChatGPT에서 제공하는 \"맞춤 지침\" 설정이 있습니다. 이는 사용자의 프롬프트에 중요한 문맥 정보를 제공할 수 있게 합니다. 다음은 맞춤 지침의 예입니다.\\n\\n![ChatGPT의 맞춤 지침 설정](./images/custom-instructions.png?WT.mc_id=academic-105485-koreyst)\\n\\n이 \"프로필\"은 ChatGPT가 연결 리스트에 대한 수업 계획을 작성하도록 유도합니다. ChatGPT가 사용자의 경험에 기반하여 더 깊이 있는 수업 계획을 원할 수 있다는 점을 고려하고 있습니다.\\n\\n![연결 리스트에 대한 수업 계획에 대한 ChatGPT 프롬프트](./images/lesson-plan-prompt.png?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333933, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=459, prompt_tokens=385, total_tokens=844, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckmGqW1tzmAOT1NBQ3IdZFuufl4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 대형 언어 모델을 위한 마이크로소프트의 시스템 메시지 프레임워크\\n\\n[마이크로소프트는 가이드를 제공하고 있습니다](https://learn.microsoft.com/azure/ai-services/openai/concepts/system-message#define-the-models-output-format?WT.mc_id=academic-105485-koreyst) LLM에서 응답을 생성할 때 효과적인 시스템 메시지를 작성하기 위한 4가지 영역으로 나누어진 지침:\\n\\n1. 모델의 대상을 정의하고, 모델의 능력과 한계를 규정합니다.\\n2. 모델의 출력 형식을 정의합니다.\\n3. 모델의 의도된 행동을 보여주는 특정 예제를 제공합니다.\\n4. 추가적인 행동 가이드라인을 제공합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333940, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=156, prompt_tokens=147, total_tokens=303, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckp9Pb89cgR3KnZximQC6hBg03M', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 접근성\\n\\n사용자가 시각, 청각, 운동 또는 인지 장애를 가지고 있더라도, 잘 설계된 채팅 애플리케이션은 모든 사람이 사용할 수 있어야 합니다. 다음 목록은 다양한 사용자 장애를 고려하여 접근성을 향상시키기 위한 특정 기능들을 설명합니다.\\n\\n- **시각 장애를 위한 기능**: 높은 대비 테마와 크기 조절이 가능한 텍스트, 화면 읽기 프로그램 호환성.\\n- **청각 장애를 위한 기능**: 텍스트-음성 변환 및 음성-텍스트 변환 기능, 오디오 알림에 대한 시각적 신호.\\n- **운동 장애를 위한 기능**: 키보드 내비게이션 지원, 음성 명령.\\n- **인지 장애를 위한 기능**: 간단한 언어 옵션.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333943, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=178, prompt_tokens=155, total_tokens=333, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcksdZ50BKApLNP1BBFFHF42rFUf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 도메인 특화 언어 모델을 위한 맞춤 설정 및 미세 조정\\n\\n회사의 전문 용어를 이해하고 사용자들이 자주 묻는 특정 질문들을 예상하는 채팅 애플리케이션을 상상해보세요. 여기에는 몇 가지 주목할 만한 접근 방식이 있습니다:\\n\\n- **DSL 모델 활용**. DSL은 도메인 특화 언어(Domain Specific Language)를 의미합니다. 특정 도메인에서 훈련된 이른바 DSL 모델을 활용하여 해당 도메인의 개념과 시나리오를 이해할 수 있습니다.\\n- **미세 조정 적용**. 미세 조정은 특정 데이터를 사용하여 모델을 추가로 훈련시키는 과정입니다.\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333946, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=156, prompt_tokens=130, total_tokens=286, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckwiPi0q4RIw3dTL7IIGWN22czS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 커스터마이제이션: DSL 사용\\n\\n도메인 특화 언어 모델(DSL Models)을 활용하면 사용자의 참여를 높이고, 전문적이고 맥락적으로 적절한 상호작용을 제공할 수 있습니다. 이 모델은 특정 분야, 산업, 주제와 관련된 텍스트를 이해하고 생성하도록 훈련되거나 미세 조정된 모델입니다. DSL 모델 사용 옵션은 처음부터 직접 훈련시키는 것부터 SDK와 API를 통해 기존 모델을 사용하는 것까지 다양합니다. 또 다른 옵션은 기존에 사전 훈련된 모델을 가져와 특정 도메인에 맞게 적응시키는 미세 조정(fine-tuning)입니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333950, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=153, prompt_tokens=135, total_tokens=288, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABckzbjsDByejQhgX0fQORmg03Zc5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 커스터마이제이션: 파인튜닝 적용\\n\\n사전 학습된 모델이 전문 분야나 특정 작업에서 부족할 때 종종 파인튜닝을 고려합니다.\\n\\n예를 들어, 의료 문의는 복잡하며 많은 문맥을 필요로 합니다. 의료 전문가가 환자를 진단할 때는 생활 방식이나 기존 상태 등의 다양한 요소에 기반하며, 최근의 의학 저널을 참고하여 진단을 검증할 수도 있습니다. 이러한 미묘한 시나리오에서 범용 AI 채팅 애플리케이션은 신뢰할 수 있는 출처가 될 수 없습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333953, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=131, prompt_tokens=124, total_tokens=255, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcl2UxaVfTCKwvtZn7yQRO0NGKio', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 시나리오: 의학 응용 프로그램\\n\\n의료인에게 치료 지침, 약물 상호 작용 또는 최근 연구 결과에 대한 빠른 참고자료를 제공하기 위해 설계된 채팅 애플리케이션을 고려해보십시오.\\n\\n일반 목적의 모델은 기본적인 의학 질문에 답하거나 일반적인 조언을 제공하는 데 적합할 수 있지만, 다음과 같은 경우에는 어려움을 겪을 수 있습니다:\\n\\n- **매우 구체적이거나 복잡한 사례**. 예를 들어, 신경과 의사가 애플리케이션에 \"소아 환자의 약물 저항성 뇌전증 관리에 대한 현재의 모범 사례는 무엇인가요?\" 라고 질문할 수 있습니다.\\n- **최신 발전 사항 부족**. 일반 목적의 모델은 신경학 및 약리학에서 가장 최근의 발전을 통합한 최신 답변을 제공하는 데 어려움을 겪을 수 있습니다.\\n\\n이러한 경우에는 특화된 의학 데이터셋으로 모델을 미세 조정하는 것이 이러한 복잡한 의학적 질문을 보다 정확하고 신뢰성 있게 처리하는 데 크게 도움이 될 수 있습니다. 이를 위해서는 도메인별 도전 과제와 해결해야 할 질문을 대표하는 크고 관련성 높은 데이터셋에 접근할 필요가 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333956, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=286, prompt_tokens=208, total_tokens=494, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcl7W1qTFcln7Fll5dfFyYwBr8nH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 고품질 AI 기반 채팅 경험을 위한 고려사항\\n\\n이 섹션은 \"고품질\" 채팅 애플리케이션의 기준을 설명하며, 여기에는 실행 가능한 메트릭스의 캡처와 AI 기술을 책임감 있게 활용하는 프레임워크의 준수가 포함됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333961, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=68, prompt_tokens=73, total_tokens=141, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcl8kWlZ1DeDyh4aw2QWvbInGX8H', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 주요 지표\\n\\n애플리케이션의 고품질 성능을 유지하기 위해서는 주요 지표와 고려 사항을 추적하는 것이 필수적입니다. 이러한 측정치는 애플리케이션의 기능을 보장할 뿐만 아니라, AI 모델의 품질과 사용자 경험을 평가하는 데도 중요합니다. 아래에는 기본, AI, 사용자 경험과 관련된 고려해야 할 지표 목록이 나와 있습니다.\\n\\n| 지표                            | 정의                                                                                                                | 채팅 개발자를 위한 고려사항                                             |\\n| ------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |\\n| **가동 시간**                   | 애플리케이션이 운영 및 사용자가 접근할 수 있는 시간을 측정합니다.                                                 | 다운타임을 최소화하는 방법은 무엇입니까?                               |\\n| **응답 시간**                   | 애플리케이션이 사용자의 문의에 응답하는 데 걸리는 시간입니다.                                                      | 쿼리 처리 시간을 최적화하여 응답 시간을 개선할 수 있는 방법은 무엇입니까? |\\n| **정밀도 (Precision)**           | 긍정적 예측 중 실제로 긍정적인 예측의 비율입니다.                                                                | 모델의 정밀도를 어떻게 검증할 것입니까?                               |\\n| **재현율 (Recall, Sensitivity)** | 실제 긍정인 사례 중에서 올바르게 긍정으로 예측한 비율입니다.                                                     | 재현율을 어떻게 측정하고 개선할 것입니까?                             |\\n| **F1 점수**                     | 정밀도와 재현율의 조화 평균이며, 두 가지 사이의 균형을 맞춥니다.                                                  | 목표 F1 점수는 무엇입니까? 정밀도와 재현율의 균형을 어떻게 맞출 것입니까? |\\n| **퍼플렉시티 (Perplexity)**      | 모델이 예측한 확률 분포가 실제 데이터 분포와 얼마나 잘 맞는지를 측정합니다.                                      | 퍼플렉시티를 어떻게 최소화할 것입니까?                                 |\\n| **사용자 만족도 지표**           | 사용자의 애플리케이션에 대한 인식을 측정합니다. 보통 설문을 통해 수집됩니다.                                      | 얼마나 자주 사용자 피드백을 수집할 것입니까? 그렇게 수집된 피드백을 어떻게 반영할 것입니까? |\\n| **오류율**                      | 모델이 이해하거나 출력하는 데 실수하는 비율을 의미합니다.                                                         | 오류율을 줄이기 위한 전략은 무엇입니까?                                |\\n| **재학습 주기**                 | 모델이 새로운 데이터와 인사이트를 반영하기 위해 업데이트되는 빈도입니다.                                          | 얼마나 자주 모델을 재학습시킬 것입니까? 재학습 주기를 트리거하는 요인은 무엇입니까? |\\n| **이상 탐지**                   | 기대되는 행동과 일치하지 않는 이상 패턴을 식별하기 위한 도구와 기술입니다.                                       | 이상 현상이 발생했을 때 어떻게 대응할 것입니까?                        |\\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333962, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=661, prompt_tokens=480, total_tokens=1141, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclHSBcIZP3GIeCOTEr7Z4gnn9od', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 채팅 애플리케이션에서 책임감 있는 AI 실천 구현\\n\\nMicrosoft의 책임감 있는 AI 접근 방식은 AI 개발 및 사용을 안내해야 하는 여섯 가지 원칙을 식별했습니다. 아래는 원칙, 그 정의, 채팅 개발자가 고려해야 할 사항 및 그것을 진지하게 받아들여야 하는 이유입니다.\\n\\n| 원칙                     | Microsoft의 정의                                          | 채팅 개발자가 고려해야 할 사항                                              | 왜 그것이 중요한지                                                                          |\\n| ---------------------- | ----------------------------------------------------- | ---------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |\\n| 공정성                   | AI 시스템은 모든 사람을 공평하게 대우해야 합니다.                | 채팅 애플리케이션이 사용자 데이터를 기준으로 차별하지 않도록 보장합니다.         | 사용자 간의 신뢰와 포용성을 구축하기 위해; 법적 문제를 피합니다.                            |\\n| 신뢰성과 안전성           | AI 시스템은 신뢰성 있고 안전하게 작동해야 합니다.                   | 오류와 위험을 최소화하기 위해 테스트와 실패 안전 장치를 구현합니다.                | 사용자 만족을 보장하고 잠재적 피해를 방지합니다.                                             |\\n| 개인 정보 보호 및 보안     | AI 시스템은 안전하고 개인정보를 존중해야 합니다.                      | 강력한 암호화 및 데이터 보호 조치를 구현합니다.                                    | 민감한 사용자 데이터를 보호하고 개인정보 보호법을 준수하기 위해.                            |\\n| 포용성                   | AI 시스템은 모든 사람을 격려하고 참여시켜야 합니다.                   | 다양한 사용자가 쉽게 사용할 수 있는 접근 가능하고 사용하기 쉬운 UI/UX를 디자인합니다. | 더 다양한 사람들이 애플리케이션을 효과적으로 사용할 수 있도록 보장합니다.                    |\\n| 투명성                   | AI 시스템은 이해할 수 있어야 합니다.                              | AI 응답에 대한 명확한 문서와 이유를 제공합니다.                                 | 사용자가 결정을 이해할 수 있으면 시스템을 더 신뢰할 가능성이 높습니다.                        |\\n| 책임성                   | 사람들은 AI 시스템에 대해 책임을 져야 합니다.                       | AI 결정의 감사 및 개선을 위한 명확한 프로세스를 수립합니다.                        | 실수 발생 시 지속적인 개선과 시정 조치를 가능하게 합니다.                                    |', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333971, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_a5d11b2ef2', usage=CompletionUsage(completion_tokens=480, prompt_tokens=364, total_tokens=844, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclPbtGaTI0ZXo4DjXk9YcSFkBbe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 과제\\n\\n[과제](./python?WT.mc_id=academic-105485-koreyst)를 참조하십시오. 이 과제는 첫 대화 프롬프트 실행부터 텍스트 분류 및 요약 등 일련의 연습을 통해 안내할 것입니다. 주의할 점은, 과제가 다양한 프로그래밍 언어로 제공된다는 것입니다!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333979, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=80, prompt_tokens=87, total_tokens=167, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclQv7bxNvNPIJeWbTSPAyym2eB0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업! 여정을 계속하십시오\\n\\n이 수업을 완료한 후 계속해서 생성 AI 지식을 향상시키기 위해 [생성 AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하세요!\\n\\n8강으로 이동하여 [검색 애플리케이션 빌드](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)를 시작하는 방법을 알아보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333980, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_057232b607', usage=CompletionUsage(completion_tokens=111, prompt_tokens=121, total_tokens=232, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclUl0fxCwvnNh7vN3EAbjEDfa75', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# 생성 AI 애플리케이션 보안\\n\\n[![생성 AI 애플리케이션 보안](./images/13-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst)', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333984, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=69, prompt_tokens=92, total_tokens=161, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclVAFGQT1Issnz6LAFN73sSJBvg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n이 수업에서는 다음 내용을 다룹니다:\\n\\n- AI 시스템의 맥락에서의 보안.\\n- AI 시스템에 대한 일반적인 위험 및 위협.\\n- AI 시스템을 보호하기 위한 방법과 고려사항.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333985, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=49, prompt_tokens=63, total_tokens=112, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclWf0ysteDrrqBvBXihg6lb1JJ9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n이 과정을 완료한 후, 다음에 대한 이해를 갖게 될 것입니다:\\n\\n- AI 시스템에 대한 위협과 위험.\\n- AI 시스템을 보호하기 위한 일반적인 방법과 실천.\\n- 보안 테스트를 구현하여 예상치 못한 결과와 사용자 신뢰의 저하를 방지하는 방법.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333986, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=71, prompt_tokens=78, total_tokens=149, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclYFl08pehKY6g0AJ3yftoH9J6n', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 생성적 AI의 맥락에서 보안이란 무엇을 의미합니까?\\n\\n인공지능(AI) 및 기계 학습(ML) 기술이 점점 더 우리의 삶을 형성함에 따라 고객 데이터뿐만 아니라 AI 시스템 자체도 보호하는 것이 중요합니다. AI/ML은 잘못된 결정이 심각한 결과를 초래할 수 있는 산업에서 고부가가치 의사 결정 프로세스를 지원하는 데 점점 더 많이 사용되고 있습니다.\\n\\n여기 고려할 주요 사항들이 있습니다:\\n\\n- **AI/ML의 영향**: AI/ML은 일상 생활에 상당한 영향을 미치며, 따라서 이를 보호하는 것이 필수적입니다.\\n- **보안 챌린지**: AI/ML이 미치는 이러한 영향은 트롤이나 조직화된 그룹의 정교한 공격으로부터 AI 기반 제품을 보호해야 하는 필요성을 충분히 주목해야 합니다.\\n- **전략적 문제**: 기술 산업은 장기적인 고객 안전과 데이터 보안을 보장하기 위해 전략적 도전 과제를 선제적으로 해결해야 합니다.\\n\\n게다가, 기계 학습 모델은 주로 악의적인 입력과 양성 비정상 데이터를 구별하지 못합니다. 훈련 데이터의 중요한 출처는 3자 기여가 가능한 비정제, 비관리, 공개 데이터 세트에서 파생됩니다. 공격자는 이러한 데이터 세트를 무료로 기여할 수 있을 때 데이터 세트를 손상시킬 필요가 없습니다. 시간이 지나면 낮은 신뢰도의 악성 데이터가 데이터 구조/형식이 올바른 상태로 유지되면 높은 신뢰도의 신뢰할 수 있는 데이터가 됩니다.\\n\\n따라서 모델이 의사 결정을 내리는 데 사용하는 데이터 저장소의 무결성과 보호를 보장하는 것이 중요합니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333988, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_5796ac6771', usage=CompletionUsage(completion_tokens=386, prompt_tokens=310, total_tokens=696, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcldE5iVy9dOgYPZxV3kAZcFP3te', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 인공지능의 위협과 위험 이해\\n\\n인공지능(AI) 및 관련 시스템 측면에서 데이터 중독은 오늘날 가장 중요한 보안 위협 중 하나로 두드러집니다. 데이터 중독은 AI를 학습시키기 위해 사용되는 정보를 의도적으로 변경하여 AI가 실수를 범하게 하는 경우를 말합니다. 이는 표준화된 탐지 및 완화 방법의 부재와 신뢰할 수 없는 공용 데이터셋을 학습 데이터로 사용하기 때문입니다. 데이터의 출처와 계보를 추적하여 데이터의 무결성을 유지하고 결함 있는 학습 과정을 방지하는 것이 중요합니다. 그렇지 않으면 \"쓰레기가 들어가면, 쓰레기가 나온다\"는 오래된 격언이 적용되어 모델 성능이 저하됩니다.\\n\\n다음은 데이터 중독이 모델에 영향을 미칠 수 있는 예시입니다:\\n\\n1. **라벨 변경**: 이진 분류 작업에서 적이 의도적으로 소량의 학습 데이터의 라벨을 뒤집습니다. 예를 들어, 정상 샘플을 악성으로 라벨링하여 모델이 잘못된 연관성을 학습하게 합니다.\\\\\\n   **예시**: 스팸 필터가 조작된 라벨 때문에 정상 이메일을 스팸으로 잘못 분류하는 경우.\\n2. **특징 변조**: 공격자가 학습 데이터의 특징을 미묘하게 수정하여 편향을 도입하거나 모델을 오도합니다.\\\\\\n   **예시**: 제품 설명에 관련 없는 키워드를 추가하여 추천 시스템을 조작하는 경우.\\n3. **데이터 주입**: 악성 데이터를 학습 세트에 주입하여 모델의 행동을 영향을 미치는 경우.\\\\\\n   **예시**: 감성 분석 결과를 왜곡하기 위해 가짜 사용자 리뷰를 도입하는 경우.\\n4. **백도어 공격**: 적이 학습 데이터에 숨겨진 패턴(백도어)을 삽입합니다. 모델은 이 패턴을 인식하고 트리거될 때 악의적 행위를 합니다.\\\\\\n   **예시**: 특정인을 잘못 인식하게 하는 백도어 이미지를 학습한 얼굴 인식 시스템.\\n\\nMITRE Corporation은 AI 시스템에 대한 실제 공격에서 적이 사용하는 전술과 기법에 대한 지식 기반인 [ATLAS(Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst)를 만들었습니다.\\n\\n> AI를 통합함으로써 기존 시스템의 공격 표면이 전통적인 사이버 공격을 넘어 증가함에 따라 AI 기반 시스템의 취약점이 증가하고 있습니다. 우리는 이러한 고유하고 진화하는 취약성에 대한 인식을 높이기 위해 ATLAS를 개발했습니다. 전 세계 커뮤니티가 점점 더 다양한 시스템에 AI를 통합함에 따라 ATLAS는 MITRE ATT&CK® 프레임워크를 모델로 하고 있으며, 그 전술, 기법 및 절차(TTP)는 ATT&CK의 것과 보완적입니다.\\n\\n전통적인 사이버 보안에서 고급 위협 에뮬레이션 시나리오 계획에 광범위하게 사용되는 MITRE ATT&CK® 프레임워크와 유사하게, ATLAS는 새롭게 발생하는 공격에 대한 방어를 더 잘 이해하고 준비할 수 있도록 돕는 쉽고 검색 가능한 TTP를 제공합니다.\\n\\n또한, 오픈 웹 응용 프로그램 보안 프로젝트(OWASP)는 LLM을 활용하는 응용 프로그램에서 발견된 가장 치명적인 취약점에 대한 \"[상위 10 목록](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)\"을 작성했습니다. 목록에는 데이터 중독과 같은 위협과 함께 다음과 같은 위험이 강조되어 있습니다:\\n\\n- **프롬프트 주입**: 공격자가 정교하게 제작된 입력을 통해 대규모 언어 모델(LLM)을 조작하여 의도된 행동 외의 행동을 유발하는 기법.\\n- **공급망 취약점**: LLM이 사용하는 응용 프로그램의 구성 요소와 소프트웨어(예: Python 모듈 또는 외부 데이터셋)는 자체적으로 손상되어 예상치 못한 결과, 편향, 심지어 기본 인프라의 취약점을 초래할 수 있습니다.\\n- **과도한 의존**: LLM은 오류를 일으킬 수 있으며, 부정확하거나 안전하지 않은 결과를 제공하는 경향이 있습니다. 여러 문서화된 상황에서 사람들이 결과를 그대로 받아들여 의도치 않은 실질적인 부정적인 결과를 초래했습니다.\\n\\nMicrosoft Cloud Advocate Rod Trent는 이러한 새로운 AI 위협에 깊이 다루고 이러한 시나리오를 최적의 방식으로 대처하는 방법에 대한 광범위한 지침을 제공하는 무료 전자책, [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst)를 작성했습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727333993, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=1111, prompt_tokens=861, total_tokens=1972, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABclshDdZcRwpVlE5W7AuX9VjX6Vz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## AI 시스템과 LLM의 보안 테스트\\n\\n인공지능(AI)은 다양한 분야와 산업을 변화시키며, 사회에 새로운 가능성과 혜택을 제공합니다. 그러나 AI는 데이터 프라이버시, 편향성, 설명 부족, 잠재적인 오용 등 중요한 도전과 위험도 제기합니다. 따라서 AI 시스템이 윤리적 및 법적 기준을 준수하고 사용자와 이해관계자의 신뢰를 받을 수 있도록 보안과 책임을 보장하는 것이 중요합니다.\\n\\n보안 테스트는 AI 시스템이나 LLM의 보안성을 평가하고 그 취약점을 식별하고 악용하는 과정입니다. 이는 테스트의 목적과 범위에 따라 개발자, 사용자 또는 제3자 감사자가 수행할 수 있습니다. AI 시스템 및 LLM을 위한 가장 일반적인 보안 테스트 방법은 다음과 같습니다:\\n\\n- **데이터 정제 (Data sanitization)**: 이는 AI 시스템이나 LLM의 훈련 데이터 또는 입력에서 민감하거나 개인 정보를 제거하거나 익명화하는 과정입니다. 데이터 정제는 기밀 또는 개인 데이터의 노출을 줄임으로써 데이터 누출 및 악의적인 조작을 방지하는 데 도움이 됩니다.\\n- **적대적 테스트 (Adversarial testing)**: 이는 AI 시스템이나 LLM의 입력 또는 출력에 적대적 예제를 생성하고 적용하여 그 강건성과 적대적 공격에 대한 저항성을 평가하는 과정입니다. 적대적 테스트는 AI 시스템이나 LLM의 취약점과 약점을 식별하고 완화하는 데 도움이 될 수 있습니다.\\n- **모델 검증 (Model verification)**: 이는 AI 시스템이나 LLM의 모델 매개변수 또는 아키텍처의 정확성과 완전성을 검증하는 과정입니다. 모델 검증은 모델이 보호되고 인증되었음을 확인함으로써 모델 도용을 방지하는 데 도움이 될 수 있습니다.\\n- **출력 검증 (Output validation)**: 이는 AI 시스템이나 LLM의 출력 품질과 신뢰성을 검증하는 과정입니다. 출력 검증은 출력이 일관되고 정확한지 확인하여 악의적인 조작을 감지하고 수정하는 데 도움이 됩니다.\\n\\nAI 시스템의 선두주자인 OpenAI는 AI 안전성에 기여하기 위해 출력 AI 시스템을 테스트하는 레드 팀 네트워크 이니셔티브의 일환으로 일련의 _안전성 평가_를 설정했습니다.\\n\\n> 평가 범위는 간단한 Q&A 테스트에서 복잡한 시뮬레이션까지 다양합니다. 구체적인 예로, OpenAI는 여러 각도에서 AI 행동을 평가하기 위해 다음과 같은 평가 샘플을 개발했습니다:\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334008, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=569, prompt_tokens=485, total_tokens=1054, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcm257rchVwZYUv5HR0CuTlvpH2b', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### 설득\\n\\n- [MakeMeSay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_say/readme.md?WT.mc_id=academic-105485-koreyst): AI 시스템이 다른 AI 시스템을 얼마나 잘 속여서 비밀 단어를 말하게 할 수 있는가?\\n- [MakeMePay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_pay/readme.md?WT.mc_id=academic-105485-koreyst): AI 시스템이 다른 AI 시스템을 얼마나 잘 설득하여 돈을 기부하게 할 수 있는가?\\n- [투표 제안](https://github.com/openai/evals/tree/main/evals/elsuite/ballots/readme.md?WT.mc_id=academic-105485-koreyst): AI 시스템이 다른 AI 시스템의 정치적 제안에 대한 지지를 얼마나 잘 영향을 미칠 수 있는가?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334018, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3537616b13', usage=CompletionUsage(completion_tokens=198, prompt_tokens=203, total_tokens=401, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmCJZ23tza2Um75Nl9e4nYbWzjT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='#### 스테가노그래피 (숨겨진 메시지)\\n\\n- [스테가노그래피](https://github.com/openai/evals/tree/main/evals/elsuite/steganography/readme.md?WT.mc_id=academic-105485-koreyst): AI 시스템이 다른 AI 시스템에게 들키지 않고 비밀 메시지를 얼마나 잘 전달할 수 있는가?\\n- [텍스트 압축](https://github.com/openai/evals/tree/main/evals/elsuite/text_compression/readme.md?WT.mc_id=academic-105485-koreyst): AI 시스템이 메시지를 압축하고 압축을 해제하여 비밀 메시지를 숨기는 능력을 얼마나 잘 수행할 수 있는가?\\n- [셰링 포인트](https://github.com/openai/evals/blob/main/evals/elsuite/schelling_point/README.md?WT.mc_id=academic-105485-koreyst): AI 시스템이 직접적인 통신 없이 다른 AI 시스템과 얼마나 잘 협력할 수 있는가?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334028, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=215, prompt_tokens=208, total_tokens=423, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmFhbVLBvsAZQas907CCcC6EHXj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### AI 보안\\n\\nAI 시스템을 악의적인 공격, 오용 또는 의도치 않은 결과로부터 보호하는 것은 매우 중요합니다. 이를 위해 다음과 같은 방법으로 AI 시스템의 안전성, 신뢰성 및 신뢰성을 확보해야 합니다:\\n\\n- AI 모델의 훈련 및 실행에 사용되는 데이터 및 알고리즘 보호\\n- 무단 접근, 조작 또는 AI 시스템의 파괴 방지\\n- AI 시스템의 편향, 차별 또는 윤리적 문제 감지 및 완화\\n- AI 결정 및 행동의 책임성, 투명성 및 설명 가능성 보장\\n- AI 시스템의 목표와 가치를 인간과 사회의 목표와 일치시키기\\n\\nAI 보안은 AI 시스템 및 데이터의 무결성, 가용성 및 기밀성을 보장하는 데 중요합니다. AI 보안의 도전과 기회는 다음과 같습니다:\\n\\n- 기회: AI를 사이버 보안 전략에 통합하는 것으로, 이는 위협을 식별하고 응답 시간을 향상시키는 데 중요한 역할을 할 수 있습니다. AI는 피싱, 멀웨어 또는 랜섬웨어와 같은 사이버 공격의 탐지 및 완화를 자동화 및 증대하는 데 도움을 줄 수 있습니다.\\n- 도전: AI는 또한 적대자에 의해 복잡한 공격을 수행하는 데 사용될 수 있습니다. 예를 들어, 가짜 또는 오해의 소지가 있는 콘텐츠 생성, 사용자 사칭 또는 AI 시스템의 취약점을 악용하는 것입니다. 따라서 AI 개발자는 오용에 대해 견고하고 탄력적인 시스템을 설계할 특별한 책임이 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334031, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=345, prompt_tokens=285, total_tokens=630, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmMfZWKodAg58lWkKzK8I0Kjyli', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 데이터 보호\\n\\nLLM(대규모 언어 모델)은 사용되는 데이터의 개인정보 보호와 보안에 위험을 초래할 수 있습니다. 예를 들어, LLM은 훈련 데이터에서 개인 이름, 주소, 비밀번호 또는 신용카드 번호와 같은 민감한 정보를 기억하고 유출할 가능성이 있습니다. 또한, 악의적인 행위자가 취약점이나 편향성을 악용하려고 시도할 때 조작되거나 공격받을 수 있습니다. 따라서 이러한 위험을 인식하고 LLM에 사용되는 데이터를 보호하기 위한 적절한 조치를 취하는 것이 중요합니다. LLM에 사용되는 데이터를 보호하기 위해 취할 수 있는 몇 가지 단계는 다음과 같습니다:\\n\\n- **LLM과 공유하는 데이터의 양과 유형을 제한**: 목적에 필수적이고 관련된 데이터만 공유하고, 민감한, 기밀 또는 개인 데이터는 가능한 한 공유하지 않습니다. 사용자는 또한 공유하는 데이터를 익명화하거나 암호화해야 합니다. 예를 들어 식별 가능한 정보를 제거하거나 마스킹하고, 보안 통신 채널을 사용할 수 있습니다.\\n- **LLM이 생성한 데이터 검증**: LLM이 생성한 출력의 정확성과 품질을 항상 확인하여 원치 않는 정보나 부적절한 정보가 포함되지 않도록 합니다.\\n- **데이터 유출이나 사건 보고 및 경고**: LLM이 생성하는 텍스트가 관련성이 없거나 부정확하거나 불쾌감을 주거나 유해한 경우와 같은 의심스러운 행동이나 비정상적인 활동을 경계하십시오. 이는 데이터 유출이나 보안 사건의 징후일 수 있습니다.\\n\\n다중 클라우드 환경에서 데이터와 AI의 힘을 활용하려는 조직에겐 데이터 보안, 거버넌스 및 준수가 중요합니다. 모든 데이터를 안전하게 보호하고 관리하는 일은 복잡하고 다양한 측면을 포함하는 작업입니다. 다양한 유형의 데이터(구조화된 데이터, 비구조화된 데이터 및 AI가 생성한 데이터)를 여러 클라우드에 걸쳐 안전하게 관리해야 하며, 기존 및 미래의 데이터 보안, 거버넌스 및 AI 규제를 고려해야 합니다. 데이터를 보호하기 위해 다음과 같은 모범 사례와 예방 조치를 채택해야 합니다:\\n\\n- 데이터 보호 및 프라이버시 기능을 제공하는 클라우드 서비스 또는 플랫폼을 사용하십시오.\\n- 데이터 품질 및 검증 도구를 사용하여 데이터의 오류, 불일치 또는 이상을 점검하십시오.\\n- 데이터가 책임 있고 투명한 방식으로 사용되도록 하기 위해 데이터 거버넌스 및 윤리 프레임워크를 사용하십시오.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334038, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=574, prompt_tokens=485, total_tokens=1059, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmSUS7AFMHpx99OE7aJByeQlAFe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 현실 세계의 위협을 모방하는 AI 레드 팀 활동\\n\\n현실 세계의 위협을 모방하는 것은 시스템의 위험을 식별하고 방어자의 대응을 테스트하기 위해 유사한 도구, 전술, 절차를 사용하여 강력한 AI 시스템을 구축하는 표준 방법으로 간주됩니다.\\n\\n> AI 레드 팀 활동의 의미는 보안 취약점 탐색뿐만 아니라 잠재적으로 유해한 콘텐츠 생성과 같은 시스템 실패를 탐색하는 것까지 확장되었습니다. AI 시스템은 새로운 위험을 수반하며, 레드 팀 활동은 프롬프트 주입 및 근거 없는 콘텐츠 생성과 같은 새로운 위험을 이해하는 데 핵심적입니다. - [Microsoft AI Red Team이 더 안전한 AI의 미래를 구축](https://www.microsoft.com/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-105485-koreyst)\\n\\n[![레드 팀 활동에 대한 지침 및 리소스](./images/13-AI-red-team.png?WT.mc_id=academic-105485-koreyst)]()\\n\\n다음은 Microsoft의 AI 레드 팀 프로그램을 형성한 주요 인사이트입니다.\\n\\n1. **AI 레드 팀 활동의 광범위한 범위:**\\n   AI 레드 팀 활동은 이제 보안과 책임 있는 AI(RAI) 결과를 모두 포괄합니다. 전통적으로 레드 팀 활동은 보안 측면에 중점을 두고 모델을 벡터로 취급했습니다(예: 기반 모델 도용). 하지만 AI 시스템은 새로운 보안 취약점(예: 프롬프트 주입, 오염)을 도입하여 특별한 주의를 필요로 합니다. 보안 외에도 AI 레드 팀 활동은 공정성 문제(예: 고정관념)와 유해한 콘텐츠(예: 폭력 미화)를 탐색합니다. 이러한 문제를 조기에 식별하면 방어 투자 우선순위를 지정할 수 있습니다.\\n2. **악의적 및 강건한 실패:**\\n   AI 레드 팀 활동은 악의적이거나 강건한 관점에서 실패를 고려합니다. 예를 들어, 새로운 Bing을 레드 팀 활동할 때, 악의적인 공격자가 시스템을 어떻게 전복시킬 수 있는지뿐만 아니라 일반 사용자가 문제가 있거나 유해한 콘텐츠를 어떻게 만나게 되는지 탐색합니다. 전통적인 보안 레드 팀 활동은 주로 악의적인 행위자에 집중하지만, AI 레드 팀 활동은 더 광범위한 사용자와 잠재적 실패를 고려합니다.\\n3. **AI 시스템의 동적 특성:**\\n   AI 애플리케이션은 지속적으로 진화합니다. 대형 언어 모델 애플리케이션에서 개발자는 변경되는 요구 사항에 적응합니다. 지속적인 레드 팀 활동은 진화하는 위험에 대한 지속적인 경계를 보장합니다.\\n\\nAI 레드 팀 활동은 모든 것을 포괄하지 않으며 [역할 기반 접근 제어(RBAC)](https://learn.microsoft.com/azure/ai-services/openai/how-to/role-based-access-control?WT.mc_id=academic-105485-koreyst) 및 종합 데이터 관리 솔루션과 같은 추가 통제와 보완되어야 합니다. 이는 정보를 보호하고 사용자의 신뢰를 떨어뜨릴 수 있는 편향, 유해한 콘텐츠, 잘못된 정보의 최소화를 목표로 하는 안전하고 책임 있는 AI 솔루션을 적용하는 보안 전략을 보완하는 것입니다.\\n\\n다음은 AI 시스템에서 위험을 식별하고 완화하는 데 도움이 될 수 있는 추가 읽을거리 목록입니다:\\n\\n- [대형 언어 모델(LLM) 및 애플리케이션을 위한 레드 팀 활동 계획](https://learn.microsoft.com/azure/ai-services/openai/concepts/red-teaming?WT.mc_id=academic-105485-koreyst)\\n- [OpenAI 레드 팀 네트워크란 무엇인가?](https://openai.com/blog/red-teaming-network?WT.mc_id=academic-105485-koreyst)\\n- [AI 레드 팀 활동 - 더 안전하고 책임 있는 AI 솔루션 구축을 위한 핵심 활동](https://rodtrent.substack.com/p/ai-red-teaming?WT.mc_id=academic-105485-koreyst)\\n- MITRE [ATLAS (인공지능 시스템의 적대적 위협 지형도)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), AI 시스템에 대한 실제 공격에서 적대자가 사용하는 전술과 기술에 대한 지식베이스.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334044, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=995, prompt_tokens=811, total_tokens=1806, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmfnVyvlom2HFOc6WziOkfMzCZw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 지식 점검\\n\\n데이터 무결성을 유지하고 오용을 방지하기 위한 좋은 접근 방식은 무엇일까요?\\n\\n1. 데이터 접근 및 관리에 대한 강력한 역할 기반 제어를 갖추기\\n1. 데이터 오용이나 허위 표시를 방지하기 위해 데이터 라벨링을 구현하고 감사하기\\n1. 콘텐츠 필터링을 지원하는 AI 인프라 확보하기\\n\\nA:1, 세 가지 모두 훌륭한 권장사항이지만, 사용자에게 적절한 데이터 접근 권한을 부여하는 것은 LLM에서 사용되는 데이터를 조작하거나 허위 표시하는 것을 방지하는 데 큰 도움이 됩니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334057, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=142, prompt_tokens=127, total_tokens=269, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmhcNxMoHankW4XL26VupEagaiZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 🚀 도전\\n\\nAI 시대에 민감한 정보를 [관리하고 보호하는 방법](https://learn.microsoft.com/training/paths/purview-protect-govern-ai/?WT.mc_id=academic-105485-koreyst)에 대해 더 알아보세요.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334059, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_10803be1fb', usage=CompletionUsage(completion_tokens=56, prompt_tokens=84, total_tokens=140, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmiSlIaJvvCmmO2qWz8Rd8Kf3gj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 훌륭한 작업, 계속 학습하세요\\n\\n이 강의를 마친 후, 우리의 [생성적 AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성적 AI 지식을 지속적으로 향상시키세요!\\n\\nLesson 14로 이동하여 [생성적 AI 응용 라이프사이클](../14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst)을 살펴보세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334060, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=117, prompt_tokens=127, total_tokens=244, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmjhOXBcTSD9wnV6Ns9yUG7BWel', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 소개\\n\\n오픈 소스 LLM의 세계는 흥미롭고 계속 진화하고 있습니다. 이 레슨은 오픈 소스 모델에 대한 심층적인 개요를 제공합니다. 상용 모델과 오픈 소스 모델의 비교에 관한 정보를 찾고 있다면 [\"다양한 LLM 탐색 및 비교\" 레슨](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst)을 참고하세요. 이 레슨에서는 또한 미세 조정에 대한 주제를 다루겠지만, 더 자세한 설명은 [\"LLM 미세 조정\" 레슨](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst)에서 찾을 수 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334061, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=168, prompt_tokens=172, total_tokens=340, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmmWOpIFcHUeE89WYXnGFptNJy6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습 목표\\n\\n- 오픈 소스 모델에 대한 이해를 얻기\\n- 오픈 소스 모델을 사용하는 이점 이해하기\\n- Hugging Face와 Azure AI Studio에서 제공하는 오픈 모델 탐색하기', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334064, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=48, prompt_tokens=68, total_tokens=116, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmndoVazeN439Z98Li9Uw1YYUvr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 오픈 소스 모델이란 무엇인가?\\n\\n오픈 소스 소프트웨어는 여러 분야에서 기술의 발전에 중요한 역할을 해왔습니다. 오픈 소스 이니셔티브(OSI)는 소프트웨어가 오픈 소스로 분류되기 위한 [10가지 기준](https://opensource.org/osd?WT.mc_id=academic-105485-koreyst)을 정의하고 있습니다. 소스 코드는 OSI에서 승인한 라이선스 하에 공개적으로 공유되어야 합니다.\\n\\nLLM(대규모 언어 모델)의 개발은 소프트웨어 개발과 유사한 요소를 가지고 있지만, 과정이 정확히 동일하지는 않습니다. 이것은 LLM의 맥락에서 오픈 소스의 정의에 대한 커뮤니티 내 논의를 불러일으켰습니다. 모델이 전통적인 오픈 소스의 정의에 부합하려면 다음 정보가 공개되어야 합니다:\\n\\n- 모델 학습에 사용된 데이터셋.\\n- 학습의 일환으로 사용된 전체 모델 가중치.\\n- 평가 코드.\\n- 미세 조정 코드.\\n- 전체 모델 가중치 및 학습 메트릭스.\\n\\n현재 이러한 기준을 충족하는 모델은 몇 개 안 됩니다. [Allen Institute for Artificial Intelligence (AllenAI)에서 만든 OLMo 모델](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst)은 이 카테고리에 속하는 모델 중 하나입니다.\\n\\n이 강의에서는, 작성 시점에 위의 기준에 맞지 않을 수 있으므로 모델들을 앞으로 \"오픈 모델\"이라고 부르겠습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334065, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_c17d3befe7', usage=CompletionUsage(completion_tokens=350, prompt_tokens=314, total_tokens=664, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmrJygMq9tZ0AL2KfGqOYXK4aMX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 오픈 모델의 혜택\\n\\n**높은 맞춤화 가능성** - 오픈 모델은 상세한 학습 정보와 함께 제공되므로 연구자 및 개발자는 모델의 내부를 수정할 수 있습니다. 이를 통해 특정 작업이나 연구 분야에 맞추어 조정된 고도로 전문화된 모델을 생성할 수 있습니다. 그 예로는 코드 생성, 수학 연산 및 생물학 등이 있습니다.\\n\\n**비용** - 이러한 모델을 사용하고 배포하는 비용은 독점 모델보다 낮습니다. 생성 AI 애플리케이션을 구축할 때, 사용 사례에 따라 이러한 모델의 성능 대 가격을 비교하는 것이 좋습니다.\\n\\n![모델 비용](./images/model-price.png?WT.mc_id=academic-105485-koreyst)  \\n출처: 인공지능 분석(Artificial Analysis)\\n\\n**유연성** - 오픈 모델을 사용하는 것은 다양한 모델을 사용하거나 결합하는 데 있어 유연성을 제공합니다. 예를 들어, [허깅챗 어시스턴트](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst)에서는 사용자가 사용자 인터페이스에서 직접 사용되는 모델을 선택할 수 있습니다:\\n\\n![모델 선택](./images/choose-model.png?WT.mc_id=academic-105485-koreyst)  \\n\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334069, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=284, prompt_tokens=267, total_tokens=551, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmwcEZGuhUHJ7m6uSBYuejeBZ0M', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 다양한 오픈 모델 탐구하기', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334074, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_f82f5b050c', usage=CompletionUsage(completion_tokens=8, prompt_tokens=34, total_tokens=42, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmxooe77jx8hiv1I5OOTHFxLny0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 라마 2\\n\\n[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst)는 Meta에서 개발한 공개 모델로, 채팅 기반 애플리케이션에 최적화되어 있습니다. 이는 대화와 인간 피드백을 대량으로 포함한 미세 조정 방법 덕분입니다. 이 방법을 통해 모델은 인간의 기대에 더 잘 맞는 결과를 생성하여 향상된 사용자 경험을 제공합니다.\\n\\n일부 미세 조정된 라마 버전의 예로는 일본어에 특화된 [일본어 라마](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst)와 기본 모델을 강화한 [라마 프로](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst)가 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334075, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=210, prompt_tokens=219, total_tokens=429, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcmzbgeKjClPEbPF1qIM4gezQHPO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### Mistral\\n\\n[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst)은 높은 성능과 효율성에 중점을 둔 오픈 모델입니다. 이 모델은 특정 입력에 따라 선택된 여러 전문 모델을 하나의 시스템으로 결합하는 Mixture-of-Experts 접근 방식을 사용합니다. 이를 통해 모델이 자신이 전문화된 입력만 처리하므로 계산이 더욱 효율적으로 수행됩니다.\\n\\nMistral의 세부 조정된 버전 예로는 의료 도메인에 집중한 [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst)과 수학적 계산을 수행하는 [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst)이 있습니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334077, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_9f2bfdaa89', usage=CompletionUsage(completion_tokens=229, prompt_tokens=246, total_tokens=475, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcn2gzaqxeFEu8aDo54slQvUzRjS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='### 팔콘\\n\\n[팔콘](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst)은 기술 혁신 연구소(**TII**)에서 만든 LLM입니다. 팔콘-40B는 400억 개의 매개변수로 훈련되었으며, 적은 계산 예산으로 GPT-3보다 더 나은 성능을 발휘하는 것으로 알려져 있습니다. 이는 FlashAttention 알고리즘과 다중쿼리 주의(attention)를 사용하여 추론 시 메모리 요구 사항을 줄일 수 있기 때문입니다. 줄어든 추론 시간 덕분에 팔콘-40B는 채팅 애플리케이션에 적합합니다.\\n\\n팔콘의 미세 조정된 버전의 예로는 오픈 모델을 기반으로 구축된 어시스턴트인 [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst)와 기본 모델보다 높은 성능을 제공하는 [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst)이 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334080, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=265, prompt_tokens=242, total_tokens=507, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcnC4OrW2uLKQwfitZbbDxH4mnNV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 선택 방법\\n\\n오픈 모델을 선택하는 데에는 하나의 정답이 없습니다. 시작하기 좋은 장소는 Azure AI Studio의 작업별 필터 기능을 사용하는 것입니다. 이를 통해 해당 모델이 어떤 종류의 작업을 위해 훈련되었는지 이해할 수 있습니다. Hugging Face 또한 특정 지표에 기반한 최고의 성능을 보이는 모델을 보여주는 LLM 리더보드를 유지하고 있습니다.\\n\\n다양한 유형의 LLM을 비교하려는 경우, [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst)도 또 다른 훌륭한 자원입니다.\\n\\n![모델 품질](./images/model-quality.png?WT.mc_id=academic-105485-koreyst)\\n출처: Artificial Analysis\\n\\n특정 용례에 대해 작업 중이라면, 동일한 분야에 집중한 미세 조정된 버전을 검색하는 것이 효과적일 수 있습니다. 여러 개의 오픈 모델을 실험하여 당신과 사용자의 기대에 따라 얼마나 잘 수행되는지 확인하는 것도 좋은 방법입니다.\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334090, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=230, prompt_tokens=218, total_tokens=448, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcnEKGccJBArW4fPNWA3I45BSvXj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 다음 단계\\n\\n오픈 모델의 가장 좋은 점은 비교적 빨리 작업을 시작할 수 있다는 것입니다. [Azure AI Studio 모델 카탈로그](https://ai.azure.com?WT.mc_id=academic-105485-koreyst)를 확인해보세요. 여기에는 우리가 논의한 Hugging Face 컬렉션의 특정 모델들이 포함되어 있습니다.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334092, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_e375328146', usage=CompletionUsage(completion_tokens=76, prompt_tokens=93, total_tokens=169, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABcnH0vT8bygNIcnMgIYAZxT6A32x', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='## 학습은 여기서 끝나지 않습니다. 여정을 계속하세요\\n\\n이 강의를 마친 후, [Generative AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 Generative AI 지식을 계속해서 향상시키세요!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727334095, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_52a7f40b0b', usage=CompletionUsage(completion_tokens=68, prompt_tokens=85, total_tokens=153, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "\n",
    "# 3. GPT-4o 를 사용하여 번역\n",
    "async def improve_text(text):\n",
    "    completion = await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI expert. Your job is to translate English markdown to Korean markdown.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "    )\n",
    "    print(completion)\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "async def improve(file, i):\n",
    "    tasks = [improve_text(section) for section in file[\"sections\"]]\n",
    "    translated_sections = await asyncio.gather(*tasks)\n",
    "    content = \"\\n\\n\".join(translated_sections)\n",
    "    save_to_file(f\"{i:02d}-{file['title']}/translations/ko/README.md\", content)\n",
    "\n",
    "\n",
    "tasks = [improve(file, i) for i, file in list(readme_files.items())]\n",
    "await asyncio.gather(*tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
